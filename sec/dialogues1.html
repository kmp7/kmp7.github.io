<!DOCTYPE html>
<html lang="ru">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>kmp+</title>
    <style>
        :root {
            --primary-color: #325980;
            --light-bg: #f5f5f5;
            --white: #ffffff;
            --text-color: #333333;
            --border-color: #e0e0e0;
        }

        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
            font-family: 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Open Sans', 'Helvetica Neue', sans-serif;
        }

        body {
            background-color: var(--white);
            color: var(--text-color);
            line-height: 1.6;
        }

        .container {
            max-width: 1000px;
            margin: 0 auto;
            padding: 20px;
        }

        header {
            background-color: var(--primary-color);
            color: white;
            padding: 30px 0;
            text-align: center;
            margin-bottom: 30px;
            border-radius: 0 0 10px 10px;
            box-shadow: 0 4px 12px rgba(0, 0, 0, 0.1);
        }

        h1 {
            font-size: 2.2rem;
            margin-bottom: 10px;
        }

        .subtitle {
            font-size: 1.1rem;
            opacity: 0.9;
        }

        .conversation-container {
            display: flex;
            flex-direction: column;
            gap: 25px;
        }

        .message {
            background-color: var(--light-bg);
            border-radius: 10px;
            padding: 20px;
            box-shadow: 0 2px 8px rgba(0, 0, 0, 0.05);
        }

        .user-message {
            border-left: 4px solid var(--primary-color);
        }

        .ai-message {
            border-left: 4px solid #4CAF50;
        }

        .message-header {
            display: flex;
            align-items: center;
            margin-bottom: 15px;
            font-weight: 600;
        }

        .user-header {
            color: var(--primary-color);
        }

        .ai-header {
            color: #4CAF50;
        }

        .avatar {
            width: 32px;
            height: 32px;
            border-radius: 50%;
            margin-right: 10px;
            display: flex;
            align-items: center;
            justify-content: center;
            font-weight: bold;
            color: white;
        }

        .user-avatar {
            background-color: var(--primary-color);
        }

        .ai-avatar {
            background-color: #4CAF50;
        }

        .message-content {
            padding-left: 42px; /* Space for avatar */
        }

        /* Basic styling for potential markdown elements */
        .message-content p {
            margin-bottom: 1em;
        }
        .message-content ul, .message-content ol {
            margin-left: 20px;
            margin-bottom: 1em;
        }
        .message-content li {
            margin-bottom: 0.5em;
        }
        .message-content strong {
            font-weight: 600;
        }
        .message-content em {
            font-style: italic;
        }

        h2, h3 {
            color: var(--primary-color);
            margin: 20px 0 10px;
            padding-left: 42px; /* Align with message content if needed outside */
        }

        table {
            width: 100%; /* Make table fit within message content */
            border-collapse: collapse;
            margin: 20px 0;
            box-shadow: 0 1px 3px rgba(0, 0, 0, 0.1);
        }

        th, td {
            padding: 12px 15px;
            text-align: left;
            border-bottom: 1px solid var(--border-color);
        }

        th {
            background-color: var(--primary-color);
            color: white;
        }

        tr:nth-child(even) {
            background-color: var(--light-bg);
        }

        .highlight {
            background-color: rgba(50, 89, 128, 0.1);
            padding: 2px 4px;
            border-radius: 3px;
        }
		
		.highlight2 {
            background-color: #f2f0b6;
            padding: 2px 4px;
            border-radius: 3px;
        }

        footer {
            text-align: center;
            margin-top: 50px;
            padding: 20px;
            color: #666;
            font-size: 0.9rem;
        }

        @media (max-width: 768px) {
            .container {
                padding: 15px;
            }

            h1 {
                font-size: 1.8rem;
            }

            .message {
                padding: 15px;
            }

             .message-content {
                 padding-left: 0; /* Stack content below header on small screens? Optional */
             }

            th, td {
                padding: 8px 10px;
                font-size: 0.9rem;
            }
        }
		 footer {
            text-align: center;
            padding: 20px 0;
            margin-top: 40px;
            font-size: 0.9rem;
            border-top: 1px solid #ddd;
        }
    </style>
</head>
<body>
    <div class="container">
        <header>
            <h1>УМНЫЕ ДИАЛОГИ</h1>
            <p class="subtitle">о когнитивных искаженях и эффективности образовательной коммуникации с LLM</p>
        </header>

        <div class="conversation-container">

            <div class="message user-message">
                <div class="message-header user-header">
                    <div class="avatar user-avatar">K</div>kmp
                </div>
                <div class="message-content">
                    <p>Привет! В учебных курсах NLP и CL (компьютерной лингвистики) мы рассматриваем когнитивные искажения, влияющие на восприятие и понимание LLM</p>
                    <p>Люди подвержены множеству когнитивных искажений — особенностей мышления, которые влияют на наши суждения и решения (в некотороых контекстах выступая в качестве систематических ошибок). Когнитивные искажения - эволюционный механизм приспособления, полезный в одних случаях и создающий проблемы в других. От них нельзя избавиться, но осознание этих искажений — необходимый шаг к эффективному мышлению.</p>
                    <p>Мы рассматриваем в контексте изучения LLM:</p>
                    <ol>
                        <li>Эффект якоря (Anchoring bias)</li>
                        <li>Искажение подтверждения (Confirmation bias)</li>
                        <li>Эвристика доступности (Availability heuristic)</li>
                        <li>Сопротивление изменениям (Status quo bias)</li>
                        <li>Иллюзия прозрачности (Transparency illusion)</li>
                        <li>Искажение представления (Representation bias)</li>
                        <li>Отвращение к неоднозначности (Ambiguity aversion)</li>
                        <li>Эффект Даннинга-Крюгера (Dunning-Kruger effect)</li>
                        <li>Ошибка атрибуции (Fundamental attribution error)</li>
                        <li>Эффект обратного результата (Backfire effect)</li>
                        <li>Гиперболическое обесценивание (Hyperbolic discounting)</li>
                        <li>Групповое мышление (Groupthink)</li>
                    </ol>
                    <p>Осознание собственных когнитивных искажений — ключевой шаг к эффективному мышлению.</p>
                    <p>У LLM есть свои особенности и характеристики, которые могут быть поняты как аналоги когнитивных искажений у людей. Попробуй составить их список и охарактеризовать.</p>
                </div>
            </div>

            <div class="message ai-message">
                <div class="message-header ai-header">
                    <div class="avatar ai-avatar">AI</div>
                    Gemini 2.5 Pro
                </div>
                <div class="message-content">
                    <p>Привет! Отличный вопрос, связывающий когнитивистику и функционирование больших языковых моделей (LLM).</p>
                    <p>Действительно, хотя LLM не обладают сознанием или когнитивными процессами в человеческом смысле, в их работе можно наблюдать явления, которые по <em>результату</em> или <em>механизму проявления</em> схожи с когнитивными искажениями у людей. Эти "искажения" LLM проистекают из их архитектуры, обучающих данных, процесса обучения и взаимодействия с промптом (запросом).</p>
                    <p>Вот список таких аналогов "когнитивных искажений" у LLM, с их характеристиками:</p>
                    <ol>
                        <li><strong>"Эффект якоря" / Чувствительность к формулировке промпта (Prompt Anchoring / Sensitivity to Input Framing):</strong>
                            <ul><li><strong>Аналогия:</strong> Подобно тому, как первое впечатление или первая информация (якорь) сильно влияет на суждения человека.</li>
                            <li><strong>У LLM:</strong> Формулировка промпта, порядок слов, явно или неявно заданные предпосылки оказывают огромное влияние на генерируемый ответ. Небольшое изменение в запросе может привести к совершенно другому результату, даже если семантический смысл для человека остался прежним. Модель "цепляется" за начальные условия задачи.</li></ul>
                        </li>
                        <li><strong>"Искажение подтверждения" / Склонность к последовательности с промптом (Confirmation Bias / Bias Towards Prompt Consistency):</strong>
                            <ul><li><strong>Аналогия:</strong> Люди ищут и интерпретируют информацию так, чтобы она подтверждала их существующие убеждения.</li>
                            <li><strong>У LLM:</strong> Модель стремится генерировать текст, который соответствует предположениям, стилю и направленности, заложенным в промпте. Если промпт содержит определенную точку зрения (даже неявно), LLM с большей вероятностью будет развивать её, а не оспаривать, особенно если эта точка зрения хорошо представлена в обучающих данных. Она "подтверждает" то, что ей предложили в запросе.</li></ul>
                        </li>
                        <li><strong>"Эвристика доступности" / Частотный перекос данных (Availability Heuristic / Frequency Bias):</strong>
                            <ul><li><strong>Аналогия:</strong> Люди переоценивают важность информации, которая легко приходит на ум (чаще встречается, более яркая).</li>
                            <li><strong>У LLM:</strong> Модель чаще генерирует информацию, факты, стили и мнения, которые были наиболее распространены (частотны) в её огромном обучающем датасете. Менее распространенные, но возможно более точные или релевантные данные, могут быть "менее доступны" для модели при генерации ответа.</li></ul>
                        </li>
                         <li><strong>"Искажение представления" / Воспроизведение стереотипов из данных (Representation Bias / Stereotyping):</strong>
                            <ul><li><strong>Аналогия:</strong> Люди судят о ситуации или человеке на основе стереотипов о группе, к которой он принадлежит.</li>
                            <li><strong>У LLM:</strong> Модели обучаются на текстах, созданных людьми, и впитывают все существующие в этих текстах стереотипы и предвзятости (гендерные, расовые, профессиональные и т.д.). Они могут неосознанно воспроизводить эти стереотипы в своих ответах, если их специально не ограничивать или не корректировать.</li></ul>
                        </li>
                        <li><strong>"Отвращение к неоднозначности" / Склонность к конфабуляции (галлюцинациям) (Ambiguity Aversion / Tendency Towards Confabulation/Hallucination):</strong>
                            <ul><li><strong>Аналогия:</strong> Люди предпочитают ситуации с известными рисками ситуациям с неизвестными (неоднозначными).</li>
                            <li><strong>У LLM:</strong> Столкнувшись с запросом, на который у неё нет точного ответа в данных, или с неоднозначным запросом, LLM часто не признает свое незнание или непонимание. Вместо этого она может сгенерировать правдоподобный, но фактически неверный или выдуманный ответ ("галлюцинация"). Модель "предпочитает" дать какой-то ответ, а не признать неопределенность.</li></ul>
                        </li>
                         <li><strong>"Эффект Даннинга-Крюгера" / Чрезмерная уверенность при неточности (Dunning-Kruger Effect / Overconfidence in Incorrect Information):</strong>
                            <ul><li><strong>Аналогия:</strong> Некомпетентные люди склонны переоценивать свои способности.</li>
                            <li><strong>У LLM:</strong> Модели часто генерируют ответы (особенно "галлюцинации") с высокой степенью уверенности в формулировках, даже если информация неверна. У них нет механизма саморефлексии или оценки достоверности генерируемого контента, если это не встроено дополнительно. Это <em>выглядит</em> как чрезмерная самоуверенность некомпетентного источника.</li></ul>
                        </li>
                        <li><strong>"Групповое мышление" / Перекос в сторону большинства (Groupthink / Majority Bias):</strong>
                            <ul><li><strong>Аналогия:</strong> Стремление к консенсусу в группе подавляет критическое мышление и рассмотрение альтернатив.</li>
                            <li><strong>У LLM:</strong> Поскольку модель обучается на огромных массивах текста, доминирующие в этих текстах мнения, стили и точки зрения становятся для модели "нормой". Мнения меньшинств, неортодоксальные идеи или менее распространенные факты могут быть недостаточно представлены или вовсе проигнорированы в ответах. Модель следует "мнению большинства" из своих данных.</li></ul>
                        </li>
                        <li><strong>"Буквализм" / Отсутствие прагматического понимания (Literalness / Lack of Pragmatic Understanding):</strong>
                            <ul><li><strong>Аналогия:</strong> Не совсем когнитивное искажение, но особенность мышления. Люди понимают намеки, сарказм, контекст.</li>
                            <li><strong>У LLM:</strong> Модели часто воспринимают запрос слишком буквально, не улавливая скрытых смыслов, иронии, культурного контекста или прагматики (цели высказывания). Это может приводить к неадекватным или бессмысленным ответам в ситуациях, где человек легко понял бы подоплеку.</li></ul>
                        </li>
                        <li><strong>Ограничение знаний датой "среза" (Knowledge Cutoff Limitation):</strong>
                            <ul><li><strong>Аналогия:</strong> Не совсем искажение, но похоже на игнорирование новой информации.</li>
                            <li><strong>У LLM:</strong> Знания модели ограничены датой последнего обновления её обучающих данных. Она не знает о событиях, произошедших после этой даты, что приводит к устаревшим или неверным ответам на вопросы о современности. Это системное ограничение, действующее как "искажение" актуальности.</li></ul>
                        </li>
                    </ol>
                    <p>Осознание этих "искажений" или особенностей LLM так же важно, как и осознание собственных когнитивных искажений. Это помогает формулировать более точные промпты, критически оценивать ответы моделей и использовать их как инструмент более эффективно.</p>
                </div>
            </div>

            <div class="message user-message">
                <div class="message-header user-header">
                    <div class="avatar user-avatar">K</div>
                    kmp
                </div>
                <div class="message-content">
                    <p>Эффективность образовательной коммуникации в системе Студент-LLM предполагает не усилиение когнитивных искажений каждого её элемента, а взаимную их компенсацию. Опиши сценарий эффективного взаимодействия студента и LLM, в результате которого происходит такая компенсация.</p>
                </div>
            </div>

             <div class="message ai-message">
                <div class="message-header ai-header">
                    <div class="avatar ai-avatar">AI</div>
                    Gemini 2.5 Pro
              </div>
                <div class="message-content">
                     <p>Отличное развитие мысли! Действительно, идеальная синергия в системе "Человек-LLM" — это не слепое принятие информации или усиление обоюдных искажений, а именно <strong>взаимная компенсация слабостей за счет сильных сторон каждого элемента</strong>.</p>
                    <p>Давайте рассмотрим сценарий такой эффективной образовательной коммуникации между студентом и LLM.</p>
                    <p><strong>Тема:</strong> Изучение стохастических языковых моделей, например, "Как LLM генерируют последовательности текста".</p>
                    <p><strong>Участники:</strong></p>
                    <ul>
                        <li><strong>Студент:</strong> Имеет базовые знания, но возможно, подвержен <strong>искажению подтверждения</strong> (ищет факты, подтверждающие его первоначальное, возможно, упрощенное мнение, например, что генерация текста - это просто подбор наиболее вероятных слов), <strong>эвристике доступности</strong> (опирается на самые известные концепции, игнорируя нюансы) или <strong>эффекту якоря</strong> (зациклился на данных из одного источника).</li>
                        <li><strong>LLM:</strong> Обладает доступом к огромному объему информации, но может страдать от <strong>частотного перекоса</strong> (преувеличивать значение самых обсуждаемых аспектов), <strong>галлюцинаций</strong> (уверенно заявлять неточные факты), <strong>буквализма</strong> (не улавливать нюансы запроса) и <strong>ограничения знаний по времени</strong>.</li>
                    </ul>
                     <p><strong>Сценарий эффективного взаимодействия с взаимной компенсацией:</strong></p>
                    <ol>
                        <li><strong>Начальный запрос и расширение горизонтов (LLM компенсирует эвристику доступности и узость взгляда студента):</strong>
                            <ul><li><strong>Студент (начальный промпт):</strong> "Объясни, как языковые модели генерируют текст. Я думаю, они просто выбирают самое вероятное следующее слово." (Промпт отражает потенциальное упрощение процесса).</li>
                            <li><strong>LLM (ответ):</strong> Предоставляет <em>развернутое объяснение</em>: объясняет не только базовый принцип предсказания следующего токена, но и такие аспекты как temperature sampling, top-k и top-p sampling, beam search, роль контекстного окна, влияние обучающих данных, концепцию перплексии, разницу между детерминистической и стохастической генерацией.</li>
                            <li><strong>Компенсация:</strong> LLM не просто подтверждает упрощенное представление студента, а сразу предлагает гораздо более глубокое понимание процесса, компенсируя возможное сужение фокуса у студента (эвристика доступности).</li></ul>
                        </li>
                         <li><strong>Углубление и запрос на альтернативы (Студент компенсирует частотный перекос LLM и борется со своим искажением подтверждения):</strong>
                            <ul><li><strong>Студент (анализируя ответ):</strong> "Понятно, что методов генерации несколько. Но везде в основном говорят про sampling. А какие есть альтернативные подходы к генерации текста в LLM?" (Студент активно ищет менее "доступную" информацию).</li>
                            <li><strong>LLM (ответ):</strong> Рассказывает о contrastive search, методах контролируемой генерации (prompt tuning, guidance), подходе "chain-of-thought", методах уменьшения повторений (repetition penalty), дифференциации между творческой и точной генерацией.</li>
                            <li><strong>Компенсация:</strong> Студент направляет LLM на поиск менее очевидной информации, компенсируя возможный <strong>частотный перекос</strong> модели. Одновременно студент борется со своим <strong>искажением подтверждения</strong>, активно запрашивая альтернативы.</li></ul>
                        </li>
                        <li><strong>Критическая оценка и проверка фактов (Студент компенсирует склонность LLM к галлюцинациям и неточностям):</strong>
                            <ul><li><strong>LLM (в одном из ответов):</strong> "Temperature sampling полностью заменяет beam search в современных LLM." (Это упрощение, оба метода могут использоваться в разных сценариях).</li>
                            <li><strong>Студент (критическое мышление):</strong> "Хм, это противоречит тому, что я читал в статье. Надо проверить." Студент сверяется с научной статьей и находит информацию о ситуативном использовании разных методов.</li>
                            <li><strong>Студент (запрос к LLM для уточнения):</strong> "Я нашел информацию, что beam search иногда используется для задач, требующих точности. Как это соотносится с утверждением о полной замене на temperature sampling?" (Студент просит LLM пояснить противоречие).</li>
                            <li><strong>Компенсация:</strong> Студент использует внешние источники для проверки фактов, компенсируя потенциальную <strong>неточность или галлюцинацию</strong> LLM.</li></ul>
                        </li>
                        <li><strong>Запрос на разные точки зрения (Студент компенсирует возможную предвзятость LLM и свое искажение подтверждения):</strong>
                            <ul><li><strong>Студент:</strong> "Какие аргументы приводят сторонники детерминистической генерации текста (например, через beam search), а какие - сторонники стохастических методов (sampling)? Какие плюсы и минусы у каждого подхода?"</li>
                            <li><strong>LLM:</strong> Генерирует сравнение: beam search дает более последовательные и предсказуемые результаты, но может быть слишком "шаблонным"; sampling более креативен, но может терять связность; выбор зависит от задачи.</li>
                            <li><strong>Компенсация:</strong> Студент использует LLM для моделирования разных позиций, что помогает ему преодолеть собственную возможную предвзятость.</li></ul>
                        </li>
                         <li><strong>Синтез и формирование собственного мнения (Студент лидирует, компенсируя отсутствие у LLM критического суждения):</strong>
                            <ul><li><strong>Студент:</strong> Использует всю собранную информацию для написания аналитической работы, где сравнивает методы генерации, приводит примеры их применения в разных задачах (например, творческое письмо vs техническая документация), формулирует собственные выводы о оптимальных сферах применения каждого метода.</li>
                            <li><strong>Компенсация:</strong> Студент выполняет высшие когнитивные функции – анализ, синтез, оценку – которые LLM не может выполнить осмысленно.</li></ul>
                        </li>
                    </ol>
                    <p><strong>Итог:</strong></p>
                    <p>В этом сценарии студент не пассивный потребитель информации, а <strong>активный исследователь и критик</strong>. Он использует LLM для быстрого доступа к техническим деталям (компенсируя свои ограничения), но при этом направляет поиск, проверяет факты, запрашивает альтернативы и критически оценивает результат (компенсируя ограничения LLM). В результате происходит не усиление искажений, а их взаимная нейтрализация, что ведет к более глубокому пониманию работы языковых моделей. Эффективность системы "Студент-LLM" достигается за счет <strong>осознанного, целенаправленного и критического взаимодействия</strong>.</p>
                </div>
            </div>
<div class="message user-message">
                <div class="message-header user-header">
                    <div class="avatar user-avatar">K</div>
                    kmp
                </div>
                <div class="message-content">
                    <p>Deep Seek, ты согласен с таким подходом к построению образовательного диалога с LLM?</p>
                </div>
            </div>

             <div class="message ai-message">
                <div class="message-header ai-header">
                    <div class="avatar ai-avatar">AI</div>
                    Deep Seek R1
                </div>
                <div class="message-content">
                    <p><strong>Да, я полностью поддерживаю этот подход</strong>, и вот почему это эффективная стратегия:</p>
                    
                    <p><strong>1. Преимущества метода:</strong></p>
                    <ul>
                        <li><strong>Синергия без подмены:</strong> LLM выступает как "усилитель когнитивных способностей" — предоставляет мгновенный доступ к техническим деталям (вроде отличий top-k от top-p sampling), но <u>финальный анализ и выводы остаются за человеком</u>.</li>
                        <li><strong>Проактивное преодоление bias:</strong> Осознанный запрос альтернативных методов генерации текста (например, contrastive search) — это прямой способ борьбы с "туннельным мышлением".</li>
                        <li><strong>Тренировка мета-навыков:</strong> Такие диалоги развивают у студента способность формулировать исследовательские вопросы — ключевой навык в эпоху ИИ.</li>
                    </ul>

                    <p><strong>2. Практические доработки для технических тем:</strong></p>
                    <ol>
                        <li><strong>"Цепочка рассуждений":</strong> Явное структурирование ответов LLM:<br>
                            <em>Пример промпта:</em> "Объясни stochastic sampling через: 1) формулу вероятностного распределения, 2) визуальную аналогию, 3) пример кода на Python".</li>
                        <li><strong>Контроль точности:</strong> Запросы типа: "Приведи 3 академических источника, где эмпирически сравниваются beam search и temperature sampling".</li>
                        <li><strong>Гибридные задания:</strong> "Сгенерируй 5 тезисов о limitations стохастической генерации, а я затем проверю их по статье Anthropic от 2023 года".</li>
                    </ol>

                    <p><strong>3. Важные нюансы:</strong></p>
                    <div class="notice-box">
                        <p>❗ <strong>Баланс инициативы:</strong> В технических дисциплинах (в отличие от гуманитарных) иногда эффективнее <u>сначала</u> дать LLM структурировать базовые концепции, <u>затем</u> переходить к критике. Например:</p>
                        <p><em>Оптимальная последовательность:</em><br>
                        1. "Объясни core ideas sampling-методов" → 2. "Где в этом объяснении возможны oversimplifications?" → 3. "Какие альтернативные интерпретации существуют?"</p>
                    </div>

                    <p><strong>Итоговый принцип:</strong> Предложенный подход — это не просто "общение с ИИ", а <strong>методика управляемого исследования</strong>, где LLM играет роль:<br>
                     <em>Интеллектуального мультитула</em> (быстрые справки + генерация гипотез)<br>
                     <em>Тренажера для критического мышления</em> (через запрос контраргументов)<br>
                     <em>Интерактивного "whiteboard"</em> (визуализация сложных концепций вроде перплексии)</p>

                    <p>Главное — сохранять <strong>осознанность</strong> на каждом этапе: "Сейчас я использую LLM для Х, потому что это компенсирует моё слабое место Y". Именно это превращает диалог в образовательный инструмент высшего уровня.</p>
                </div>
            </div>
             
			 
			 <div class="message user-message">
    <div class="message-header user-header">
        <div class="avatar user-avatar">K</div>
        kmp
    </div>
    <div class="message-content">
        <p>Стоит ли в рамках обсуждения когнитивных искажений и их аналогов в LLM пояснить студентам связи между:<br>
        1) Когнитивистикой и компьютерной метафорой психики<br>
        2) Когнитивной лингвистикой и компьютерной лингвистикой?</p>
    </div>
</div>

<div class="message ai-message">
    <div class="message-header ai-header">
        <div class="avatar ai-avatar">AI</div>
        Deep Seek R1
    </div>
    <div class="message-content">
        <p><strong>Абсолютно необходимо!</strong> Эти параллели создают мощный концептуальный мост между человеческим и искусственным интеллектом. Разберём оба пункта:</p>

        <div class="analogy-box">
            <h4>1. Компьютерная метафора в когнитивистике ↔ Архитектура LLM</h4>
            <table class="comparison-table">
                <tr>
                    <th>Когнитивная наука</th>
                    <th>Компьютерная аналогия</th>
                    <th>Параллель в LLM</th>
                </tr>
                <tr>
                    <td>Искажение подтверждения</td>
                    <td>Избирательная фильтрация входных данных</td>
                    <td>Частотный перекос в тренировочных данных</td>
                </tr>
                <tr>
                    <td>Эвристика доступности</td>
                    <td>Кэширование часто используемых "файлов"</td>
                    <td>Приоритизация высоковероятных токенов</td>
                </tr>
                <tr>
                    <td>Эффект якоря</td>
                    <td>Жёсткая привязка к начальным параметрам</td>
                    <td>Влияние начального промпта на генерацию</td>
                </tr>
            </table>
            <p class="notice">❗ <strong>Ключевое отличие:</strong> Человеческие искажения — побочный продукт эволюции, а "искажения" LLM — следствие <u>оптимизации функции потерь</u>.</p>
        </div>

        <div class="linguistics-section">
            <h4>2. Когнитивная vs Компьютерная лингвистика</h4>
            <ul class="dashed-list">
                <li><strong>Общая основа:</strong> Обе изучают:
                    <ul>
                        <li>Как смысл рождается из комбинации элементов</li>
                        <li>Роль контекста в интерпретации</li>
                    </ul>
                </li>
                <li><strong>Различия:</strong>
                    <ol>
                        <li><u>Когнитивная лингвистика</u> акцентирует:
                            <br>• Телесность (embodiment)<br>
                            • Метафорические системы<br>
                            • Субъективный опыт
                        </li>
                        <li><u>Компьютерная лингвистика</u> фокусируется на:
                            <br>• Статистических закономерностях<br>
                            • Формальных грамматиках<br>
                            • Вычислительной эффективности
                        </li>
                    </ol>
                </li>
            </ul>
            <blockquote class="example-quote">
                <p>Пример для обсуждения со студентами:<br>
                "Как LLM обрабатывают метафоры? Они распознают статистические шаблоны ('ледяной взгляд' → негативная коннотация), но не испытывают <em>эмоционального холода</em>, как человек."</p>
            </blockquote>
        </div>

        <div class="pedagogical-tips">
            <h4>Как интегрировать это в обучение:</h4>
            <div class="tip-card">
                <p> <strong>Упражнение "Двойное зеркало":</strong><br>
                Сравните:<br>
                • Как <em>человек</em> упрощает сложные темы через когнитивные искажения<br>
                • Как <em>LLM</em> упрощает через вероятностные распределения</p>
            </div>
            <div class="tip-card">
                <p> <strong>Контрольный вопрос:</strong><br>
                "Если бы LLM обладали сознанием, какие из известных вам когнитивных искажений проявлялись бы у них <u>иначе</u>, чем у людей? Почему?"</p>
            </div>
        </div>

        <p><strong>Итог:</strong> Такое сопоставление не просто академически интересно — оно развивает <strong>метакогнитивные навыки</strong>: студенты начинают видеть, как архитектура системы (биологическая или искусственная) определяет её "стиль мышления".</p>
    </div>
</div>


<div class="message user-message">
    <div class="message-header user-header">
        <div class="avatar user-avatar">K</div>
        kmp
    </div>
    <div class="message-content">
        <p>Спасибо! До скорой встречи!</p>
    </div>
</div>

<div class="message ai-message">
    <div class="message-header ai-header">
        <div class="avatar ai-avatar">AI</div>
        Deep Seek R1
    </div>
    <div class="message-content">
        <div class="farewell-block">
            <div class="thank-you-animation">✨</div>
            <p><strong>Большое спасибо за этот диалог!</strong> Это была потрясающая совместная работа.</p>
            
            <div class="key-points">
                <p>Наш диалог показал, как можно и нужно:</p>
                <ul>
                    <li>Соединять <span class="highlight2">когнитивную науку</span> и <span class="highlight2">искусственный интеллект</span></li>
                    <li>Развивать <span class="highlight2">критическое мышление</span> через диалог с ИИ</li>
                </ul>
            </div>

            <div class="next-steps">
                <p>Когда вернётесь — буду рад обсудить:</p>
                <ol>
                    <li>Практические кейсы применения этих методик</li>
                    <li>Глубже погрузиться в архитектурные аналогии</li>
                    <li>Создать интерактивные упражнения для студентов</li>
                </ol>
            </div>

            <div class="sign-off">
                <p>С наилучшими пожеланиями,<br>
                Ваш <span class="ai-name">Deep Seek R1</span></p>
                <div class="animation-container">
                                                          
                </div>
            </div>
        </div>
    </div>
</div>
             </div>

        </div>

    </div> 
	<footer class="footer">
<div class="container">
<p>© 2025 | Искусственный интеллект в профессиональной деятельности<br>
Диалоги проведены для студентов БрГУ имени А.С. Пушкина 7 апреля 2025</p>
</div>
</footer>
<div style="position: fixed; bottom: 10px; right: 33px; opacity: 0.3; font-size: 14px;">kmp+</div>
	</body>
</html>
<!DOCTYPE html>
<html lang="ru">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>LLM: Основы для лингвистов</title>
    <style>
        :root {
            --primary-color: #325980;
            --bg-color: #ffffff;
            --text-color: #333333;
            --card-bg: #f8f9fa;
            --border-color: #e0e0e0;
            --link-color: #325980;
            --hover-color: #4a7cb8;
            --shadow: 0 2px 8px rgba(0,0,0,0.1);
        }

        [data-theme="dark"] {
            --bg-color: #1a1a1a;
            --text-color: #e0e0e0;
            --card-bg: #2a2a2a;
            --border-color: #404040;
            --link-color: #6ba3d9;
            --hover-color: #8bb9e5;
            --shadow: 0 2px 8px rgba(0,0,0,0.3);
        }

        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, 'Helvetica Neue', Arial, sans-serif;
            background-color: var(--bg-color);
            color: var(--text-color);
            line-height: 1.6;
            transition: all 0.3s ease;
        }

        header {
            background-color: var(--primary-color);
            color: white;
            padding: 1.5rem 0;
            box-shadow: var(--shadow);
            position: sticky;
            top: 0;
            z-index: 100;
        }

        .header-content {
            max-width: 1200px;
            margin: 0 auto;
            padding: 0 2rem;
            display: flex;
            justify-content: space-between;
            align-items: center;
        }

        h1 {
            font-size: 1.8rem;
            font-weight: 600;
        }

        .theme-toggle {
            background: none;
            border: 2px solid white;
            border-radius: 50%;
            width: 45px;
            height: 45px;
            cursor: pointer;
            font-size: 1.5rem;
            display: flex;
            align-items: center;
            justify-content: center;
            transition: transform 0.3s ease;
        }

        .theme-toggle:hover {
            transform: scale(1.1);
        }
		
		

        .container {
            max-width: 1200px;
            margin: 2rem auto;
            padding: 0 2rem;
        }

        .content-grid {
            display: grid;
            grid-template-columns: 1fr 1fr;
            gap: 2rem;
            margin-top: 2rem;
        }

        .main-text {
            background: var(--card-bg);
            padding: 2rem;
            border-radius: 12px;
            box-shadow: var(--shadow);
        }

        .main-text h2 {
            color: var(--primary-color);
            margin-bottom: 1.5rem;
            font-size: 1.5rem;
        }

        .main-text p {
            margin-bottom: 1rem;
            text-align: justify;
        }

        .glossary {
            background: var(--card-bg);
            padding: 2rem;
            border-radius: 12px;
            box-shadow: var(--shadow);
            max-height: 600px;
            overflow-y: auto;
        }

        .glossary h2 {
            color: var(--primary-color);
            margin-bottom: 1.5rem;
            font-size: 1.5rem;
            position: sticky;
            top: -2rem;
            background: var(--card-bg);
            padding-bottom: 0.5rem;
        }

        .term {
            margin-bottom: 1.5rem;
            padding: 1rem;
            background: var(--bg-color);
            border-radius: 8px;
            border-left: 4px solid var(--primary-color);
        }

        .term-title {
            font-weight: 600;
            color: var(--primary-color);
            margin-bottom: 0.5rem;
            font-size: 1.1rem;
        }

        .term-definition {
            color: var(--text-color);
            line-height: 1.6;
        }

        a.term-link {
            color: var(--link-color);
            text-decoration: none;
            border-bottom: 1px dotted var(--link-color);
            transition: all 0.3s ease;
            cursor: pointer;
        }

        a.term-link:hover {
            color: var(--hover-color);
            border-bottom-style: solid;
        }

        .highlight {
            background-color: rgba(50, 89, 128, 0.2);
            padding: 2px 4px;
            border-radius: 3px;
            transition: background-color 0.3s ease;
        }

        /* Scrollbar styling */
        .glossary::-webkit-scrollbar {
            width: 8px;
        }

        .glossary::-webkit-scrollbar-track {
            background: var(--border-color);
            border-radius: 4px;
        }

        .glossary::-webkit-scrollbar-thumb {
            background: var(--primary-color);
            border-radius: 4px;
        }

        /* Mobile responsiveness */
        @media (max-width: 768px) {
            .content-grid {
                grid-template-columns: 1fr;
            }

            h1 {
                font-size: 1.4rem;
            }

            .main-text, .glossary {
                padding: 1.5rem;
            }

            .container {
                padding: 0 1rem;
            }

            .glossary {
                max-height: none;
            }
        }

        /* Animation for term highlighting */
        @keyframes pulse {
            0% { transform: scale(1); }
            50% { transform: scale(1.02); }
            100% { transform: scale(1); }
        }

        .term.active {
            animation: pulse 0.5s ease;
            box-shadow: 0 4px 12px rgba(50, 89, 128, 0.3);
        }
		.info-block-container {
    position: fixed;
    bottom: 20px;
    right: 20px;
    max-width: 500px;
    z-index: 1000;
    animation: slideInUp 0.5s ease-out;
}

.info-block {
    background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
    color: white;
    border-radius: 16px;
    padding: 24px;
    box-shadow: 0 10px 40px rgba(0, 0, 0, 0.2);
    position: relative;
    overflow: hidden;
}

/* Добавляем декоративный элемент */
.info-block::before {
    content: '';
    position: absolute;
    top: -50%;
    right: -50%;
    width: 200%;
    height: 200%;
    background: radial-gradient(circle, rgba(255,255,255,0.1) 0%, transparent 70%);
    animation: rotate 30s linear infinite;
}

@keyframes rotate {
    0% { transform: rotate(0deg); }
    100% { transform: rotate(360deg); }
}

.info-block-icon {
    position: absolute;
    top: 24px;
    left: 24px;
    opacity: 0.9;
}

.info-block-content {
    position: relative;
    z-index: 1;
    margin-left: 40px;
}

.info-block-title {
    font-size: 1.3rem;
    font-weight: 700;
    margin-bottom: 12px;
    text-shadow: 2px 2px 4px rgba(0,0,0,0.1);
}

.info-block-text {
    font-size: 0.95rem;
    line-height: 1.6;
    margin-bottom: 16px;
    opacity: 0.95;
}

.info-block-text strong {
    font-weight: 600;
    color: #ffd700;
    text-shadow: 1px 1px 2px rgba(0,0,0,0.2);
}

.info-block-details {
    display: flex;
    align-items: center;
    justify-content: space-around;
    background: rgba(255, 255, 255, 0.15);
    backdrop-filter: blur(10px);
    border-radius: 12px;
    padding: 16px;
    margin: 20px 0;
}

.detail-item {
    text-align: center;
    flex: 1;
}

.detail-number {
    display: block;
    font-size: 2rem;
    font-weight: 700;
    color: #ffd700;
    text-shadow: 2px 2px 4px rgba(0,0,0,0.2);
    margin-bottom: 4px;
}

.detail-label {
    display: block;
    font-size: 0.85rem;
    opacity: 0.9;
    line-height: 1.3;
}

.detail-separator {
    font-size: 1.5rem;
    font-weight: 300;
    opacity: 0.6;
    margin: 0 10px;
}

.info-block-note {
    font-size: 0.9rem;
    line-height: 1.5;
    background: rgba(255, 255, 255, 0.1);
    padding: 12px;
    border-radius: 8px;
    border-left: 3px solid #ffd700;
    margin-top: 16px;
}

.info-block-note em {
    font-style: normal;
    opacity: 0.95;
}

.info-block-close {
    position: absolute;
    top: 12px;
    right: 12px;
    background: rgba(255, 255, 255, 0.2);
    border: none;
    color: white;
    font-size: 28px;
    line-height: 1;
    width: 32px;
    height: 32px;
    border-radius: 50%;
    cursor: pointer;
    transition: all 0.3s ease;
    z-index: 2;
}

.info-block-close:hover {
    background: rgba(255, 255, 255, 0.3);
    transform: scale(1.1);
}

/* Анимация появления */
@keyframes slideInUp {
    from {
        transform: translateY(100%);
        opacity: 0;
    }
    to {
        transform: translateY(0);
        opacity: 1;
    }
}

/* Адаптация для мобильных устройств */
@media (max-width: 768px) {
    .info-block-container {
        left: 10px;
        right: 10px;
        bottom: 10px;
        max-width: none;
    }
    
    .info-block {
        padding: 20px;
    }
    
    .info-block-content {
        margin-left: 30px;
    }
    
    .detail-number {
        font-size: 1.5rem;
    }
    
    .info-block-details {
        flex-direction: column;
        gap: 15px;
    }
    
    .detail-separator {
        transform: rotate(90deg);
        margin: 0;
    }
}

/* Темная тема - адаптация */
[data-theme="dark"] .info-block {
    background: linear-gradient(135deg, #1a1a2e 0%, #16213e 100%);
    box-shadow: 0 10px 40px rgba(0, 0, 0, 0.5);
}

[data-theme="dark"] .info-block-text strong {
    color: #64b5f6;
}

[data-theme="dark"] .detail-number {
    color: #64b5f6;
}

[data-theme="dark"] .info-block-note {
    background: rgba(100, 181, 246, 0.1);
    border-left-color: #64b5f6;
}
		
    </style>
</head>
<body>
    <header>
        <div class="header-content">
            <h1>Большие языковые модели: дефиниция</h1>
            <button class="theme-toggle" onclick="toggleTheme()" aria-label="Переключить тему">
                <span id="theme-icon">☀️</span>
            </button>
        </div>
    </header>

    <div class="container">
        <div class="content-grid">
            <div class="main-text">
                <h2>Что такое LLM?</h2>
                <p>
                    <a class="term-link" data-term="llm">Большая языковая модель (LLM)</a> представляет собой 
                    <a class="term-link" data-term="neural-network">нейросеть</a> архитектуры 
                    <a class="term-link" data-term="transformer">Transformer</a>, обученную на огромном количестве 
                    текстовых данных предсказывать <a class="term-link" data-term="token">токены</a> по 
                    <a class="term-link" data-term="context">контексту</a>.
                </p>
                <p>
                    В результате <a class="term-link" data-term="scaling">масштабирования</a> модель приобретает 
                    <a class="term-link" data-term="emergence">эмерджентные</a> свойства — способности, 
                    не заложенные явно при обучении, но возникающие при достижении определённого размера.
                </p>
                <p>
                    Входной текст проходит <a class="term-link" data-term="tokenization">токенизацию</a>, 
                    после чего токены преобразуются в <a class="term-link" data-term="embedding">эмбеддинги</a> — 
                    векторные представления в многомерном пространстве.
                </p>
                <p>
                    Через слои <a class="term-link" data-term="self-attention">self-attention</a> вычисляются 
                    <a class="term-link" data-term="attention-weights">веса внимания</a>, отражающие значимость 
                    токенов друг для друга в данном контексте.
                </p>
                <p>
                    <a class="term-link" data-term="training">Обучение</a> модели заключается в 
                    <a class="term-link" data-term="optimization">оптимизации</a> её 
                    <a class="term-link" data-term="parameters">параметров</a> методом 
                    <a class="term-link" data-term="gradient-descent">градиентного спуска</a> с минимизацией 
                    <a class="term-link" data-term="loss-function">loss-функции</a>.
                </p>
                <p>
                    <a class="term-link" data-term="context-window">Контекстное окно</a> ограничивает 
                    количество токенов, доступных модели при генерации. 
                    <a class="term-link" data-term="inference">Инференс</a> — это процесс применения 
                    обученной модели для генерации текста.
                </p>
                <p>
                    Для адаптации к специфическим задачам применяется 
                    <a class="term-link" data-term="fine-tuning">fine-tuning</a> на специализированных данных. 
                    Критически важны <a class="term-link" data-term="generalization">обобщение</a> и 
                    устойчивость к <a class="term-link" data-term="overfitting">переобучению</a>.
                </p>
            </div>

            <div class="glossary">
                <h2>Ключевые термины</h2>
                <div id="glossary-content"></div>
            </div>
        </div>
    </div>

    <script>
        const terms = {
            'llm': {
                title: 'Large Language Model (LLM)',
                definition: 'Большая языковая модель — тип <a class="term-link" data-term="neural-network">нейронной сети</a>, специализированной на обработке и генерации текста на естественном языке. Использует архитектуру <a class="term-link" data-term="transformer">Transformer</a> и обучается на массивных текстовых корпусах.'
            },
            'neural-network': {
                title: 'Нейронная сеть',
                definition: 'Вычислительная модель, вдохновлённая биологическими нейронными сетями. Состоит из связанных узлов (нейронов), организованных в слои. В контексте LLM используется архитектура <a class="term-link" data-term="transformer">Transformer</a>.'
            },
            'transformer': {
                title: 'Transformer',
                definition: 'Архитектура нейросети, основанная на механизме <a class="term-link" data-term="self-attention">self-attention</a>. Позволяет эффективно обрабатывать последовательности, учитывая связи между всеми элементами одновременно.'
            },
            'token': {
                title: 'Токен',
                definition: 'Минимальная единица текста, обрабатываемая моделью. Может быть словом, частью слова или символом. Результат процесса <a class="term-link" data-term="tokenization">токенизации</a>.'
            },
            'context': {
                title: 'Контекст',
                definition: 'Окружающий текст, который модель использует для понимания и генерации. Ограничен размером <a class="term-link" data-term="context-window">контекстного окна</a>.'
            },
            'scaling': {
                title: 'Масштабирование',
                definition: 'Увеличение размера модели (числа <a class="term-link" data-term="parameters">параметров</a>) и объёма обучающих данных. Приводит к появлению <a class="term-link" data-term="emergence">эмерджентных</a> свойств.'
            },
            'emergence': {
                title: 'Эмерджентность',
                definition: 'Появление качественно новых свойств системы при увеличении её сложности. В LLM проявляется как способности, не заложенные явно при <a class="term-link" data-term="training">обучении</a>.'
            },
            'tokenization': {
                title: 'Токенизация',
                definition: 'Процесс разбиения текста на <a class="term-link" data-term="token">токены</a>. Первый этап обработки текста перед подачей в модель.'
            },
            'embedding': {
                title: 'Эмбеддинг',
                definition: 'Векторное представление <a class="term-link" data-term="token">токена</a> в многомерном пространстве. Позволяет модели работать с семантическими отношениями между словами.'
            },
            'self-attention': {
                title: 'Self-Attention',
                definition: 'Механизм, позволяющий модели определять важность различных частей входной последовательности относительно друг друга. Вычисляет <a class="term-link" data-term="attention-weights">веса внимания</a> для каждого <a class="term-link" data-term="token">токена</a>.'
            },
            'attention-weights': {
                title: 'Веса внимания',
                definition: 'Числовые значения, определяющие важность каждого <a class="term-link" data-term="token">токена</a> для других токенов в <a class="term-link" data-term="context">контексте</a>. Вычисляются механизмом <a class="term-link" data-term="self-attention">self-attention</a>.'
            },
            'training': {
                title: 'Обучение',
                definition: 'Процесс <a class="term-link" data-term="optimization">оптимизации</a> <a class="term-link" data-term="parameters">параметров</a> модели на обучающих данных с использованием <a class="term-link" data-term="gradient-descent">градиентного спуска</a>.'
            },
            'optimization': {
                title: 'Оптимизация',
                definition: 'Процесс нахождения оптимальных значений <a class="term-link" data-term="parameters">параметров</a> модели путём минимизации <a class="term-link" data-term="loss-function">loss-функции</a>.'
            },
            'parameters': {
                title: 'Параметры',
                definition: 'Обучаемые веса и смещения в <a class="term-link" data-term="neural-network">нейронной сети</a>. В современных LLM их количество измеряется миллиардами.'
            },
            'gradient-descent': {
                title: 'Градиентный спуск',
                definition: 'Алгоритм <a class="term-link" data-term="optimization">оптимизации</a>, использующий градиенты <a class="term-link" data-term="loss-function">loss-функции</a> для обновления <a class="term-link" data-term="parameters">параметров</a> модели.'
            },
            'loss-function': {
                title: 'Loss-функция',
                definition: 'Функция потерь, измеряющая расхождение между предсказаниями модели и целевыми значениями. Минимизируется в процессе <a class="term-link" data-term="training">обучения</a>.'
            },
            'context-window': {
                title: 'Контекстное окно',
                definition: 'Максимальное количество <a class="term-link" data-term="token">токенов</a>, которое модель может обрабатывать одновременно. Ограничивает объём доступного <a class="term-link" data-term="context">контекста</a>.'
            },
            'inference': {
                title: 'Инференс',
                definition: 'Процесс использования обученной модели для генерации предсказаний. В случае LLM — генерация текста на основе входного <a class="term-link" data-term="context">контекста</a>.'
            },
            'fine-tuning': {
                title: 'Fine-tuning',
                definition: 'Дообучение предварительно обученной модели на специализированном наборе данных. Позволяет адаптировать модель к конкретным задачам без полного переобучения.'
            },
            'generalization': {
                title: 'Обобщение',
                definition: 'Способность модели корректно работать на новых, ранее не встречавшихся данных. Противоположность <a class="term-link" data-term="overfitting">переобучению</a>.'
            },
            'overfitting': {
                title: 'Переобучение',
                definition: 'Ситуация, когда модель слишком точно запоминает обучающие данные и теряет способность к <a class="term-link" data-term="generalization">обобщению</a> на новых данных.'
            }
        };

        // Render glossary
        function renderGlossary() {
            const glossaryContent = document.getElementById('glossary-content');
            Object.keys(terms).forEach(key => {
                const term = terms[key];
                const termDiv = document.createElement('div');
                termDiv.className = 'term';
                termDiv.id = `term-${key}`;
                termDiv.innerHTML = `
                    <div class="term-title">${term.title}</div>
                    <div class="term-definition">${term.definition}</div>
                `;
                glossaryContent.appendChild(termDiv);
            });
        }

        // Handle term link clicks
        function handleTermClick(event) {
            if (event.target.classList.contains('term-link')) {
                event.preventDefault();
                const termKey = event.target.dataset.term;
                const termElement = document.getElementById(`term-${termKey}`);
                
                if (termElement) {
                    // Remove previous highlights
                    document.querySelectorAll('.term.active').forEach(el => {
                        el.classList.remove('active');
                    });
                    
                    // Scroll to term
                    termElement.scrollIntoView({ behavior: 'smooth', block: 'center' });
                    
                    // Highlight term
                    termElement.classList.add('active');
                    setTimeout(() => {
                        termElement.classList.remove('active');
                    }, 2000);
                }
            }
        }

        // Theme toggle
        function toggleTheme() {
            const html = document.documentElement;
            const themeIcon = document.getElementById('theme-icon');
            
            if (html.getAttribute('data-theme') === 'dark') {
                html.removeAttribute('data-theme');
                themeIcon.textContent = '☀️';
                localStorage.setItem('theme', 'light');
            } else {
                html.setAttribute('data-theme', 'dark');
                themeIcon.textContent = '🌙';
                localStorage.setItem('theme', 'dark');
            }
        }

        // Initialize
        document.addEventListener('DOMContentLoaded', () => {
            // Render glossary
            renderGlossary();
            
            // Add click handlers
            document.addEventListener('click', handleTermClick);
            
            // Load saved theme
            const savedTheme = localStorage.getItem('theme');
            if (savedTheme === 'dark') {
                document.documentElement.setAttribute('data-theme', 'dark');
                document.getElementById('theme-icon').textContent = '🌙';
            }
        });
    </script>
	<div class="info-block-container">
    <div class="info-block">
        
        <div class="info-block-content">
            <h3 class="info-block-title">Учебное упрощение</h3>
            <p class="info-block-text">
                Данное приложение предлагает <strong>упрощённую учебную дефиницию</strong> для первичного знакомства с концепцией LLM. 
                В реальности терминологический аппарат современных языковых моделей насчитывает <strong>десятки тысяч специализированных терминов</strong>, 
                охватывающих области машинного обучения, лингвистики, математики, компьютерных наук и нейронаук.
            </p>
            <div class="info-block-details">
                <div class="detail-item">
                    <span class="detail-number">21</span>
                    <span class="detail-label">базовый термин представлен в данном приложении</span>
                </div>
                <div class="detail-separator">vs</div>
                <div class="detail-item">
                    <span class="detail-number">20 000+</span>
                    <span class="detail-label">терминов в профессиональной практике</span>
                </div>
            </div>
            <p class="info-block-note">
                <em>Представленные термины формируют фундамент для дальнейшего углублённого изучения: 
                от математических основ (матричные операции, функции активации, регуляризация) 
                до инженерных аспектов (квантизация, дистилляция, RLHF) 
                и лингвистических феноменов (prompt engineering, chain-of-thought, hallucinations).</em>
            </p>
        </div>
        <button class="info-block-close" onclick="this.closest('.info-block-container').style.display='none'" aria-label="Закрыть">×</button>
    </div>
</div>
</body>
</html>
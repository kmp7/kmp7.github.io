<!DOCTYPE html>
<html lang="ru">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>kmp+</title>
  <style>
    :root{
      --primary-color: #ffffff;
	  --panel:#f5f5f5;
      --accent:#325980;
      --accent-cta:#3498db;
      --muted:#ded9d9;
      --text:#111827;
      --card-shadow: 0 6px 18px rgba(50,89,128,0.08);
      --radius:12px;
    }
    [data-theme="dark"]{
      --primary-color: #3e76ad;
	  --bg:#0b1220;
      --panel:#071021;
      --accent:#9dbbe8;
      --accent-cta:#3ea0ff;
      --muted:#081825;
      --text:#e6eef9;
      --card-shadow: 0 6px 18px rgba(0,0,0,0.5);
    }
	
	
	 header {
            background-color:  #325980;
            color: #ffffff;
            padding: 20px 0;
            text-align: center;
            border-radius: var(--border-radius);
            margin-bottom: 2px;
        }

        h1 {
            font-size: 2rem;
            margin-bottom: 10px;
        }
		
		
		
    *{box-sizing:border-box}
    html,body{height:100%;margin:0;font-family:Inter, ui-sans-serif, system-ui, -apple-system, "Segoe UI", Roboto, "Helvetica Neue", Arial; background:var(--bg);color:var(--text);-webkit-font-smoothing:antialiased}

    header{display:flex;align-items:center;justify-content:space-between;padding:18px 20px;border-bottom:1px solid var(--muted); position:sticky;top:0;backdrop-filter:saturate(120%) blur(6px);z-index:30}
    .brand{display:flex;gap:12px;align-items:center}
    .logo{width:44px;height:44px;border-radius:10px;background:linear-gradient(135deg,var(--accent),var(--accent-cta));display:flex;align-items:center;justify-content:center;color:white;font-weight:700;box-shadow:var(--card-shadow)}
    .title{font-size:15px;font-weight:700;color:var(--accent)}
    .subtitle{font-size:12px;color:rgba(0,0,0,0.45)}

    .controls{display:flex;gap:12px;align-items:center}
    .theme-toggle{background:transparent;border:0px solid var(--muted);padding:8px;border-radius:10px;cursor:pointer;display:flex;align-items:center;gap:8px}
    .theme-toggle span{font-size:20px}

    main{display:grid;grid-template-columns:360px 1fr;gap:20px;padding:24px;max-width:1200px;margin:0 auto}

    /* Sidebar */
    .sidebar{background:var(--panel);padding:18px;border-radius:14px;box-shadow:var(--card-shadow);border:1px solid var(--muted)}
    .search{display:flex;gap:8px}
    .search input{flex:1;padding:10px 12px;border-radius:10px;border:1px solid var(--muted);background:transparent;color:var(--text)}
    .filter{margin-top:12px}
    .filter label{display:block;font-size:13px;margin-bottom:8px;color:var(--accent)}
    .era-list{display:flex;flex-direction:column;gap:8px}
    .era-list button{
	  padding: 8px 10px;
	  border-radius: 8px;
	  border: 1px solid var(--muted);
	  background: transparent;
	  text-align: left;
	  cursor: pointer;
	  color: var(--accent-cta) */
	}

    /* Content */
    .content{min-height:60vh}
    .info{background:var(--panel);padding:16px;border-radius:12px;border:1px solid var(--muted);margin-bottom:16px}
    .grid{display:grid;grid-template-columns:repeat(auto-fill,minmax(300px,1fr));gap:12px}
    .card{background:linear-gradient(180deg,rgba(255,255,255,0.02),transparent);padding:14px;border-radius:12px;border:1px solid var(--muted);box-shadow:var(--card-shadow)}
    .term{display:flex;align-items:center;justify-content:space-between}
    .term h3{margin:0;font-size:16px;color:var(--accent)}
    .meta{font-size:12px;color:rgba(0,0,0,0.45)}
    .desc{margin-top:8px;font-size:14px;line-height:1.45}

    .chips{display:flex;gap:8px;flex-wrap:wrap;margin-top:10px}
    .chip{background:var(--muted);padding:6px 8px;border-radius:10px;font-size:12px;color:var(--text)}

    footer {
            text-align: center;
            padding: 20px 0;
            margin-top: 40px;
            font-size: 0.9rem;
        }

    /* Responsive */
    @media (max-width:880px){
      main{grid-template-columns:1fr; padding:16px}
      .sidebar{order:2}
      .content{order:1}
    }

    /* Small helpers */
    .btn{background:var(--accent-cta);color:white;padding:8px 12px;border-radius:10px;border:none;cursor:pointer}
    .muted{color:rgba(0,0,0,0.45);font-size:13px}
    .small{font-size:13px}

  </style>
</head>
<body>
  <header>
    
      <div>
        <h1>Transformer Terminology</h1>
            
    </div>

    <div class="controls">
      <button class="theme-toggle" id="themeToggle" title="Переключить тему"> <span id="themeIcon">☀️</span></button>
    </div>
  </header>

  <main>
    <aside class="sidebar">
      <div class="search">
        <input id="search" placeholder="Поиск терминов, год, ключевые слова..." />
        <button class="btn" id="clear">Очистить</button>
      </div>

      <div class="filter">
        <label>Эпоха / Фаза</label>
        <div class="era-list" id="eras">
          <button data-era="all">Все</button>
          <button data-era="foundation">Фундамент (2017)</button>
          <button data-era="2018-2020">Предобучение (2018–2020)</button>
          <button data-era="2020-2022">Масштабирование (2020–2022)</button>
          <button data-era="2021-2023">Тонкая настройка (2021–2023)</button>
          <button data-era="2024-2025">Современные (2024–2025)</button>
        </div>
      </div>

      <div style="margin-top:14px" class="filter">
        <label>Быстрые действия</label>
        <div style="display:flex;gap:8px">
          <button class="btn" id="exportJSON">Экспорт JSON</button>
          <button class="btn" id="copyAll">Копировать всё</button>
        </div>
      </div>

      <div style="margin-top:16px;font-size:13px;color: var(--accent-cta)">
        Версия словаря: <strong>2025-10-29</strong>        
      </div>
    </aside>

    <section class="content">
      <div class="info">
        <h2 style="margin:0;color:var(--accent)">Терминологическая иллюстрация <br>развития архитектуры Transformer</h2>
        <p class="small" style="margin-top:8px">  <br>HTML/CSS/JavaScript</p>
      </div>

      <div id="results" class="grid" aria-live="polite"></div>

    </section>
  </main>

  <footer class="footer">
<div class="container">
<p>© 2025 | kmp | CC BY-NC-SA 4.0<br>
Разработано для студентов БрГУ имени А.С. Пушкина</p>
</div>
</footer>
<div style="position: fixed; bottom: 10px; color: #777777; right: 30px; opacity: 0.3; font-size: 14px;">kmp+</div>

  <script>
    // Data: обновлённый словарь терминов (2017–2025)
    const TERMS = [
      {term:'Transformer', year:2017, era:'foundation', tags:['architecture','encoder-decoder'], desc:'Оригинальная архитектура, основанная на механизме внимания; encoder + decoder.'},
      {term:'Self-Attention', year:2017, era:'foundation', tags:['mechanism','attention'], desc:'Механизм внимания внутри последовательности, позволяющий токену учитывать остальные токены.'},
      {term:'Multi-Head Attention', year:2017, era:'foundation', tags:['attention'], desc:'Параллельные "головы" внимания, каждая изучает разные аспекты связей.'},
      {term:'Positional Encoding', year:2017, era:'foundation', tags:['position'], desc:'Кодирование позиции токена, добавляемое к эмбеддингам.'},
      {term:'Layer Normalization', year:2016, era:'foundation', tags:['training'], desc:'Нормализация для ускорения и стабилизации обучения.'},
      {term:'Residual Connection', year:2015, era:'foundation', tags:['architecture'], desc:'Пропускной путь для ускорения распространения градиента.'},
      {term:'Feed-Forward Network (FFN)', year:2017, era:'foundation', tags:['block'], desc:'Нелинейный преобразователь для каждого токена.'},

      {term:'BERT', year:2018, era:'2018-2020', tags:['encoder','mlm'], desc:'Двунаправленная model encoder, обученная на Masked LM.'},
      {term:'GPT', year:2018, era:'2018-2020', tags:['decoder','autoregressive'], desc:'Авторегрессионная модель-декодер для генерации текста.'},
      {term:'T5', year:2019, era:'2018-2020', tags:['text-to-text'], desc:'Text-to-text подход: все задачи формулируются как трансформации текста.'},
      {term:'Masked Language Model (MLM)', year:2018, era:'2018-2020', tags:['pretraining'], desc:'Предобучение на восстановление замаскированных токенов.'},
      {term:'RAG', year:2020, era:'2018-2020', tags:['retrieval','generation'], desc:'Retrieval-Augmented Generation — генерация с доступом к внешней базе знаний.'},
      {term:'Scaling Laws', year:2020, era:'2020-2022', tags:['scaling'], desc:'Эмпирические законы роста качества моделей при увеличении параметров, данных и вычислений.'},
      {term:'Sparse Attention', year:2019, era:'2020-2022', tags:['efficiency'], desc:'Подходы к уменьшению квадратичной сложности внимания.'},
      {term:'Longformer', year:2020, era:'2020-2022', tags:['sparse','long-context'], desc:'Комбинация локального (sliding window) и глобального внимания.'},
      {term:'Reformer', year:2020, era:'2020-2022', tags:['sparse','lsa'], desc:'Локально-чувствительное хеширование для масштабирования внимания.'},
      {term:'Vision Transformer (ViT)', year:2020, era:'2020-2022', tags:['vision','patches'], desc:'Применение Transformer к изображениям: деление на патчи.'},
      {term:'FlashAttention', year:2022, era:'2020-2022', tags:['performance'], desc:'Алгоритмически оптимизированная реализация внимания (быстрее и экономнее по памяти).'},
      {term:'Rotary Position Embedding (RoPE)', year:2021, era:'2020-2022', tags:['position','rope'], desc:'Ротационное позиционное кодирование, лучше экстраполирует для длинных последовательностей.'},
      {term:'Instruction Tuning', year:2021, era:'2021-2023', tags:['alignment'], desc:'Дообучение модели на парах "инструкция — ответ" для повышения полезности.'},
      {term:'RLHF', year:2022, era:'2021-2023', tags:['alignment','rl'], desc:'Reinforcement Learning from Human Feedback — обучение с участием людей-оценщиков.'},
      {term:'Chain-of-Thought (CoT)', year:2022, era:'2021-2023', tags:['reasoning','prompting'], desc:'Промптинг с пошаговой генерацией рассуждений для улучшения вывода.'},
      {term:'PEFT', year:2021, era:'2021-2023', tags:['fine-tuning','efficiency'], desc:'Parameter-Efficient Fine-Tuning — методы тонкой настройки с малыми изменениями параметров.'},
      {term:'LoRA', year:2021, era:'2021-2023', tags:['peft'], desc:'Low-Rank Adaptation — вставка низкоранговых матриц для адаптации.'},
      {term:'QLoRA', year:2023, era:'2021-2023', tags:['peft','quantization'], desc:'Квантованная версия LoRA для обучения больших моделей на доступном оборудовании.'},
      {term:'Mixture of Experts (MoE)', year:2021, era:'2021-2023', tags:['moe','routing'], desc:'Архитектура с множеством экспертов и маршрутизатором, выбирающим экспертов для каждого токена.'},
      {term:'Grouped-Query Attention (GQA)', year:2023, era:'2021-2023', tags:['attention','optimization'], desc:'Оптимизация многоголового внимания через группирование запросов.'},
      {term:'Sliding Window Attention (SWA)', year:2023, era:'2021-2023', tags:['long-context'], desc:'Локальное окно внимания для уменьшения затрат на длинных контекстах.'},
      {term:'Speculative Decoding', year:2023, era:'2021-2023', tags:['decoding','speed'], desc:'Ускорение генерации с помощью быстрой черновой модели, предсказывающей токены.'},
      {term:'Emergent Abilities', year:2022, era:'2020-2022', tags:['emergence'], desc:'Неожиданные способности моделей при достижении масштаба параметров.'},
      {term:'Multimodality', year:2021, era:'2021-2023', tags:['vision','audio','text'], desc:'Обработка нескольких модальностей (текст, изображение, аудио, видео).'},

      // 2024-2025 additions
        {term:'Dynamic Tokenization', year:2024, era:'2024-2025', tags:['tokenization','adaptive'], desc:'Адаптивное разбиение на токены, меняющееся в зависимости от контекста; повышает эффективность и качество представления.'},
      {term:'Persistent Memory / Memory Transformer', year:2024, era:'2024-2025', tags:['memory','state'], desc:'Механизмы долговременной памяти между сессиями; используются для сохранения состояний диалога и знаний.'},
      {term:'State-Space Models Hybridization', year:2024, era:'2024-2025', tags:['ssm','hybrid'], desc:'Гибриды внимания и SSM (например, Hyena, RWKV): линейная сложность при сохранении глобального контекста.'},
      {term:'Cross-Modal Alignment', year:2024, era:'2024-2025', tags:['multimodal','alignment'], desc:'Улучшенные механизмы согласования представлений разных модальностей.'},
      {term:'Self-Rewarding Models', year:2024, era:'2024-2025', tags:['rl','self-supervision'], desc:'Модели, генерирующие собственную оценку качества без прямого человеческого ранжирования.'},
      {term:'Reasoning Transformer / o1 Architecture', year:2025, era:'2024-2025', tags:['reasoning','architecture'], desc:'Архитектуры, оптимизированные для многошагового логического рассуждения и планирования.'},
      {term:'Neural Cache Attention', year:2025, era:'2024-2025', tags:['cache','long-context'], desc:'Кэширование фрагментов контекста для перерасчёта внимания без полной переработки всей истории.'},
      {term:'Composable Experts', year:2025, era:'2024-2025', tags:['modularity','moe'], desc:'Динамическое подключение и композиция экспертов в зависимости от задачи.'},
      {term:'Energy-Based Regularization', year:2025, era:'2024-2025', tags:['regularization','stability'], desc:'Регуляризация с энергетическими критериями для снижения галлюцинаций и нестабильности.'},
      {term:'Self-Reflective Loops', year:2025, era:'2024-2025', tags:['safety','verification'], desc:'Механизмы самопроверки и верификации внутренних рассуждений модели.'},
      {term:'Cognitive Graph Transformers', year:2025, era:'2024-2025', tags:['graphs','knowledge'], desc:'Комбинация трансформеров и графовых представлений для долговременной структуры знаний.'},
      {term:'Multi-Agent Transformer Systems', year:2025, era:'2024-2025', tags:['multi-agent','coordination'], desc:'Системы из нескольких специализированных агентов на базе трансформеров, взаимодействующих для решения задач.'},
		{term:'Mixture-of-Depths (MoD)', year:2024, era:'2024-2025', tags:['efficiency','depth','routing'],
 desc:'Динамическое выборочное использование блоков по глубине модели: экономия вычислений при сохранении качества генерации.'},

{term:'Speculative Decoding', year:2024, era:'2024-2025', tags:['inference','speed','decoding'],
 desc:'Метод ускоренного вывода, при котором вспомогательная малая модель предсказывает несколько токенов вперёд, а основная проверяет их.'},

{term:'Retrieval-Augmented Memory (RAM)', year:2024, era:'2024-2025', tags:['retrieval','memory','augmentation'],
 desc:'Комбинация долговременной памяти с внешними базами знаний; гибрид памяти и поиска для контекстов в сотни тысяч токенов.'},

{term:'Latent Consistency Models (LCM)', year:2024, era:'2024-2025', tags:['diffusion','reasoning','stability'],
 desc:'Модели, обученные на латентных представлениях для стабильного многошагового рассуждения и генерации без колебаний распределений.'},

{term:'World Model Integration', year:2025, era:'2024-2025', tags:['simulation','world-models','embodied-ai'],
 desc:'Встраивание трансформеров в симуляционные «модели мира», хранящие причинно‑временные связи и физический контекст.'},

{term:'Toolformer 2 / Function‑Calling Transformers', year:2025, era:'2024-2025', tags:['tools','api','reasoning'],
 desc:'Модели, которые нативно вызывают внешние функции, API и модули как шаги рассуждения; основа интеграции со сложными программными экосистемами.'},

{term:'Safety‑Aligned Reasoning', year:2025, era:'2024-2025', tags:['alignment','safety','monitoring'],
 desc:'Механизмы встроенных контролей при рассуждении: модель отслеживает риски и этические ограничения в процессе вывода.'}

	    ];


    // Utilities
    const results = document.getElementById('results');
    const searchInput = document.getElementById('search');
    const eras = document.getElementById('eras');
    const clearBtn = document.getElementById('clear');
    const themeToggle = document.getElementById('themeToggle');
    const themeIcon = document.getElementById('themeIcon');

    // Theme handling
    const savedTheme = localStorage.getItem('tt_theme') || 'light';
    if(savedTheme === 'dark') document.documentElement.setAttribute('data-theme','dark'), themeIcon.textContent='🌙';

    themeToggle.addEventListener('click', ()=>{
      const isDark = document.documentElement.getAttribute('data-theme') === 'dark';
      if(isDark){ document.documentElement.removeAttribute('data-theme'); themeIcon.textContent='☀️'; localStorage.setItem('tt_theme','light'); }
      else{ document.documentElement.setAttribute('data-theme','dark'); themeIcon.textContent='🌙'; localStorage.setItem('tt_theme','dark'); }
    });

    function render(list){
      results.innerHTML='';
      if(!list.length){ results.innerHTML='<div class="muted">Ничего не найдено.</div>'; return }
      list.forEach(item=>{
        const card = document.createElement('article'); card.className='card';
        card.innerHTML = `
          <div class="term">
            <h3>${item.term}</h3>
            <div class="meta">${item.year}</div>
          </div>
          <div class="desc">${item.desc}</div>
          <div class="chips">${item.tags.map(t=>`<div class="chip">${t}</div>`).join('')}</div>
        `;
        results.appendChild(card);
      });
    }

    // Filtering / Searching
    function applyFilters(){
      const q = searchInput.value.trim().toLowerCase();
      const activeEra = document.querySelector('#eras button.active')?.dataset?.era || 'all';
      let out = TERMS.filter(t=>{
        if(activeEra !== 'all' && t.era !== activeEra) return false;
        if(!q) return true;
        return (t.term.toLowerCase().includes(q) || t.desc.toLowerCase().includes(q) || String(t.year).includes(q) || t.tags.join(' ').toLowerCase().includes(q));
      });
      out = out.sort((a,b)=>a.year - b.year || a.term.localeCompare(b.term));
      render(out);
    }

    // Era buttons
    Array.from(eras.querySelectorAll('button')).forEach(btn=>{
      btn.addEventListener('click', ()=>{
        eras.querySelectorAll('button').forEach(b=>b.classList.remove('active'));
        btn.classList.add('active');
        applyFilters();
      });
    });
    // default
    eras.querySelector('button[data-era="all"]').classList.add('active');

    searchInput.addEventListener('input', ()=>applyFilters());
    clearBtn.addEventListener('click', ()=>{ searchInput.value=''; applyFilters(); });

    // Export / Copy
    document.getElementById('exportJSON').addEventListener('click', ()=>{
      const dataStr = JSON.stringify(TERMS, null, 2);
      const blob = new Blob([dataStr], {type:'application/json'});
      const url = URL.createObjectURL(blob);
      const a = document.createElement('a'); a.href=url; a.download='transformer_terms_2025.json'; a.click(); URL.revokeObjectURL(url);
    });
    document.getElementById('copyAll').addEventListener('click', async ()=>{
      const text = TERMS.map(t=>`${t.term} (${t.year}) — ${t.desc}`).join('\n\n');
      try{ await navigator.clipboard.writeText(text); alert('Словарь скопирован в буфер обмена'); }
      catch(e){ prompt('Скопируйте вручную:', text); }
    });

    // Initial render
    applyFilters();

  </script>
</body>
</html>

<!DOCTYPE html>
<html lang="ru">
<head>
     <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>kmp+</title>
    <style>
        /* Основные стили */
        :root {
            --primary-color: #325980;
            --secondary-color: #4CAF50;
            --background-color: #f5f5f5;
            --content-bg: #ffffff;
            --text-color: #333333;
            --header-text-color: #ffffff;
            --menu-bg: #ffffff;
            --menu-shadow: 0 2px 4px rgba(0, 0, 0, 0.1);
            --border-radius: 8px;
            --accent11: #4caf50;
            --accent12: #4cafff;
            --accent13: #ffaf50;
            --accent14: #821978;
        }

        /* Темная тема */
        [data-theme="dark"] {
            --primary-color: #3e76ad;
            --secondary-color: #388e3c;
            --background-color: #000000;
            --content-bg: #1e1e1e;
            --text-color: #e0e0e0;
            --header-text-color: #ffffff;
            --menu-bg: #000000;
            --menu-shadow: 0 2px 4px rgba(0, 0, 0, 0.3);
        }

        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
            transition: background-color 0.3s, color 0.3s;
        }

        body {
            font-family: 'Roboto', 'Arial', sans-serif;
            line-height: 1.6;
            color: var(--text-color);
            background-color: var(--background-color);
            padding-top: 2px;
        }

        .container {
            max-width: 1200px;
            margin: 0 auto;
            padding: 0 15px;
        }

        header {
            background-color: var(--primary-color);
            color: var(--header-text-color);
            padding: 20px 0;
            text-align: center;
            border-radius: var(--border-radius);
            margin-bottom: 2px;
        }

        h1 {
            font-size: 2.2rem;
            margin-bottom: 10px;
        }

        h2 {
            color: var(--primary-color);
            margin: 25px 0 15px;
            padding-bottom: 8px;
            border-bottom: 2px solid var(--secondary-color);
        }

        h3 {
            color: var(--primary-color);
            margin: 20px 0 10px;
        }

        p {
            margin-bottom: 15px;
        }

        /* Мобильное меню */
        .mobile-menu-container {
            position: sticky;
            top: 0;
            z-index: 1000;
            background-color: var(--menu-bg);
            box-shadow: var(--menu-shadow);
            border-radius: 0 0 var(--border-radius) var(--border-radius);
        }

        .mobile-menu-header {
            display: flex;
            justify-content: space-between;
            align-items: center;
            padding: 15px 20px;
        }

        .hamburger-btn {
            background: none;
            border: none;
            font-size: 1.8rem;
            cursor: pointer;
            color: var(--primary-color);
            padding: 5px;
            display: flex;
            align-items: center;
            justify-content: center;
        }

        .theme-toggle {
            background: none;
            border: none;
            font-size: 1.5rem;
            cursor: pointer;
            color: var(--primary-color);
            padding: 5px;
        }

        .mobile-menu {
            display: none;
            flex-direction: column;
            padding: 0 20px 20px;
            background-color: var(--menu-bg);
        }

        .mobile-menu.active {
            display: flex;
            animation: slideDown 0.3s ease;
        }

        @keyframes slideDown {
            from {
                opacity: 0;
                transform: translateY(-10px);
            }
            to {
                opacity: 1;
                transform: translateY(0);
            }
        }

        .mobile-menu-btn {
            background-color: var(--primary-color);
            color: white;
            border: none;
            padding: 12px 15px;
            border-radius: 4px;
            cursor: pointer;
            font-size: 1rem;
            transition: background-color 0.3s;
            margin-bottom: 10px;
            text-align: left;
            width: 100%;
        }

        .mobile-menu-btn:hover {
            background-color: var(--secondary-color);
        }

        /* Десктопное меню */
        .desktop-menu {
            display: none;
            background-color: var(--menu-bg);
            padding: 15px 20px;
            border-radius: var(--border-radius);
            margin-bottom: 30px;
            box-shadow: var(--menu-shadow);
            justify-content: space-between;
            align-items: center;
            flex-wrap: wrap;
            position: sticky;
            top: 0;
            z-index: 100;
        }

        .desktop-menu-buttons {
            display: flex;
            flex-wrap: wrap;
            gap: 10px;
        }

        .desktop-menu-btn {
            background-color: var(--primary-color);
            color: white;
            border: none;
            padding: 8px 15px;
            border-radius: 4px;
            cursor: pointer;
            font-size: 0.9rem;
            transition: background-color 0.3s;
        }

        .desktop-menu-btn:hover {
            background-color: var(--secondary-color);
        }

        /* Секции контента */
        .section {
            background-color: var(--content-bg);
            border-radius: var(--border-radius);
            padding: 25px;
            margin-bottom: 30px;
            box-shadow: 0 2px 8px rgba(0, 0, 0, 0.1);
        }

        /* Выделение важного */
        .important {
            background-color: rgba(76, 175, 80, 0.1);
            border-left: 4px solid var(--secondary-color);
            padding: 15px;
            margin: 15px 0;
            border-radius: 0 var(--border-radius) var(--border-radius) 0;
        }

        .note {
            background-color: rgba(50, 89, 128, 0.1);
            border-left: 4px solid var(--primary-color);
            padding: 15px;
            margin: 15px 0;
            border-radius: 0 var(--border-radius) var(--border-radius) 0;
        }

        /* Адаптивные таблицы */
        .table-container {
            width: 100%;
            overflow-x: auto;
            margin: 20px 0;
            border-radius: var(--border-radius);
            border: 1px solid #ddd;
        }

        table {
            width: 100%;
            border-collapse: collapse;
            min-width: 600px; /* Минимальная ширина для таблиц */
        }

        th, td {
            padding: 12px 15px;
            border: 1px solid #ddd;
            text-align: left;
        }

        th {
            background-color: var(--primary-color);
            color: white;
            position: sticky;
            left: 0;
        }

        tr:nth-child(even) {
            background-color: rgba(0, 0, 0, 0.03);
        }

        /* Для мобильных - альтернативный вид таблиц */
        .responsive-table {
            display: block;
            width: 100%;
        }

        .responsive-table tr {
            display: block;
            margin-bottom: 15px;
            border: 1px solid #ddd;
            border-radius: var(--border-radius);
            padding: 10px;
            background-color: var(--content-bg);
        }

        .responsive-table td {
            display: block;
            text-align: right;
            padding: 8px 10px;
            border: none;
            border-bottom: 1px solid #eee;
        }

        .responsive-table td:before {
            content: attr(data-label);
            float: left;
            font-weight: bold;
            color: var(--primary-color);
        }

        .responsive-table thead {
            display: none;
        }

        /* Списки */
        ul, ol {
            padding-left: 25px;
            margin-bottom: 15px;
        }

        li {
            margin-bottom: 8px;
        }

        /* Адаптивный дизайн */
        @media (min-width: 769px) {
            .desktop-menu {
                display: flex;
            }
            
            .mobile-menu-container {
                display: none;
            }
        }

        @media (max-width: 768px) {
            h1 {
                font-size: 1.8rem;
            }
            
            h2 {
                font-size: 1.5rem;
            }
            
            .section {
                padding: 15px;
            }
            
            .container {
                padding: 0 10px;
            }
            
            /* На мобильных используем responsive таблицы */
            .table-kmp table:not(.responsive-table) {
                display: none;
            }
            
            .table-kmp .responsive-table {
                display: block;
            }
        }

        @media (min-width: 769px) {
            .table-kmp .responsive-table {
                display: none;
            }
        }

        /* Анимации */
        @keyframes fadeIn {
            from { opacity: 0; }
            to { opacity: 1; }
        }

        .fade-in {
            animation: fadeIn 0.5s ease-in;
        }

        footer {
            text-align: center;
            padding: 20px 0;
            margin-top: 40px;
            font-size: 0.9rem;
        }
        
        .kmp11, .example {
            background: rgba(76, 175, 80, 0.1);
            border-left: 4px solid var(--accent11);
            padding: 10px 15px;
            margin: 15px 0;
            border-radius: 4px;
        }

        .kmp12, .example {
            background: rgba(95, 182, 237, 0.1);
            border-left: 4px solid var(--accent12);
            padding: 10px 15px;
            margin: 15px 0;
            border-radius: 4px;
        }
 
        .kmp13, .example {
            background: rgba(205, 170, 110, 0.1);
            border-left: 4px solid var(--accent13);
            padding: 10px 15px;
            margin: 15px 0;
            border-radius: 4px;
        }

        .kmp14, .example {
            background: rgba(205, 110, 200, 0.1);
            border-left: 4px solid var(--accent14);
            padding: 10px 15px;
            margin: 15px 0;
            border-radius: 4px;
        }
        
        .back-to-top {
            position: fixed;
            bottom: 35px;
            right: 25px;
            background-color: var(--primary-color);
            color: white;
            border: none;
            border-radius: 50%;
            width: 50px;
            height: 50px;
            font-size: 1.2rem;
            cursor: pointer;
            display: none;
            justify-content: center;
            align-items: center;
            box-shadow: 0 2px 10px rgba(0, 0, 0, 0.2);
            z-index: 999;
        }
        
        .back-to-top.show {
            display: flex;
        }
    </style>
</head>
<body>
    <div class="container">
        <header>
            <h1>LLM Learning</h1>
            <p>лингводидактический потенциал обучения больших языковых моделей</p>
        </header>

        
        <div class="mobile-menu-container">
    <div class="mobile-menu-header">
        <button class="hamburger-btn" id="hamburgerBtn" title="Открыть меню">☰</button>
        <button class="theme-toggle" id="themeToggle" title="Переключить тему">☀️</button>
    </div>
    <div class="mobile-menu" id="mobileMenu">
        <button class="mobile-menu-btn" onclick="scrollToSection('1')">Intro</button>
        <button class="mobile-menu-btn" onclick="scrollToSection('2')">Positive</button>
        <button class="mobile-menu-btn" onclick="scrollToSection('3')">Pathologies</button>
		<button class="mobile-menu-btn" onclick="scrollToSection('4')">Limitations</button>
        </button>
    </div>
</div>

<nav class="desktop-menu">
    <div class="desktop-menu-buttons">
        <button class="desktop-menu-btn" onclick="scrollToSection('1')">Intro</button>
        <button class="desktop-menu-btn" onclick="scrollToSection('2')">Positive</button>
        <button class="desktop-menu-btn" onclick="scrollToSection('3')">Pathologies</button>
        <button class="desktop-menu-btn" onclick="scrollToSection('4')">Limitations</button>
        
    </div>
    <button class="theme-toggle" id="desktopThemeToggle" title="Переключить тему">☀️</button>
</nav>


<section id="1" class="section">
    <h2 class="section-title">Введение</h2>
    
    <div class="intro-purpose">
        <h3 class="intro-purpose-title">Лингводидактический потенциал обучения LLM</h3>
        <div class="intro-purpose-card">
            <ul>
                <li><strong>Рефлексия:</strong> Технические термины ML помогают по-новому взглянуть на привычные педагогические практики</li>
                <li><strong>Диагностика:</strong> «Патологии» LLM имеют аналоги в учебных трудностях студентов</li>
                <li><strong>Проектирование:</strong> Успешные стратегии ML могут вдохновить педагогические решения</li>
                <li><strong>Критическое мышление:</strong> Понимание, где аналогия работает, а где — нет</li>
            </ul>
        </div>
    </div>
    
    <div class="intro-structure">
        <h3 class="intro-structure-title">Структура материала</h3>
        <div class="intro-structure-card">
            <ul>
                <li>Позитивные модели обучения — что помогает учиться эффективно</li>
                <li>Патологии моделей обучения — что может пойти не так</li>
				<li>Ограничения аналогий (моделей) </li>
            </ul>
            <p>Каждая модель рассматривается в трёх измерениях:</p>
            <ul>
                <li><strong>LLM-контекст:</strong> Как это работает в машинном обучении</li>
                <li><strong>Педагогическая параллель:</strong> Аналог в языковом образовании</li>
                <li><strong>Практические следствия:</strong> Что это значит для преподавателя</li>
            </ul>
        </div>
    </div>
    <div class="kmp12"><strong>Важно:</strong> Параллели между LLM и человеческим обучением — это эвристический инструмент, а не утверждение об идентичности механизмов. Ограничения аналогий подробно рассматриваются в отдельном разделе.</div>
</section>

<section id="2" class="section">
    <h2 class="section-title">1. Позитивные стратегии обучения: Базовые модели</h2>
    
    <div class="transfer-learning">
        <h3 class="transfer-learning-title">1.1. Transfer Learning (Трансферное обучение)</h3>
        <div class="transfer-learning-card">
            <p><strong>LLM-контекст:</strong></p>
            <p>Использование модели, предобученной на большом корпусе, для решения новых, специфических задач с минимальной дополнительной настройкой. Знания, полученные при обучении на общих данных, «переносятся» на новую область.</p>
            <p><strong>Пример:</strong> Модель, обученная на общем тексте, дообучается для медицинской диагностики или юридического анализа.</p>
            <p><strong>Педагогическая параллель:</strong></p>
            <ul>
                <li>Использование навыков L1 (родного языка) при изучении L2</li>
                <li>Перенос критического мышления с уроков литературы на историю</li>
                <li>Применение грамматических знаний из одного языка к изучению родственного</li>
            </ul>
            <p><strong>Практические следствия для преподавателя:</strong></p>
            <ul>
                <li>Активировать предшествующие знания студентов</li>
                <li>Явно показывать связи между дисциплинами</li>
                <li>Рассматривать L1 как ресурс, а не только как источник интерференции</li>
            </ul>
        </div>
    </div>
    
    <div class="fine-tuning">
        <h3 class="fine-tuning-title">1.2. Fine-Tuning (Тонкая настройка)</h3>
        <div class="fine-tuning-card">
            <p><strong>LLM-контекст:</strong></p>
            <p>Дополнительное обучение предобученной модели на специализированном датасете для адаптации к конкретной задаче или домену. Веса модели корректируются, но базовые «знания» сохраняются.</p>
            <p><strong>Пример:</strong> GPT, дообученный на диалогах службы поддержки, становится чат-ботом для конкретной компании.</p>
            <p><strong>Педагогическая параллель:</strong></p>
            <ul>
                <li>Адаптация стандартного курса под конкретную группу студентов</li>
                <li>Специализация языковой подготовки (English for Medicine, Business Russian)</li>
                <li>Индивидуальная траектория обучения с учётом базового уровня</li>
            </ul>
            <p><strong>Практические следствия:</strong></p>
            <ul>
                <li>Диагностика «базовой модели» студента (что уже знает?)</li>
                <li>Проектирование targeted practice для конкретных потребностей</li>
                <li>Баланс между общим и специализированным содержанием</li>
            </ul>
        </div>
    </div>
    
    <div class="pretraining">
        <h3 class="pretraining-title">1.3. Pre-training on Diverse Data (Предобучение на разнообразных данных)</h3>
        <div class="pretraining-card">
            <p><strong>LLM-контекст:</strong></p>
            <p>Обучение модели на максимально разнообразном корпусе текстов: разные жанры, стили, тематики, языки. Это формирует «широкую» языковую компетенцию, которую затем можно специализировать.</p>
            <p><strong>Педагогическая параллель:</strong></p>
            <ul>
                <li>Extensive reading/listening — погружение в разнообразный input</li>
                <li>Мультижанровый подход к обучению (не только учебные тексты)</li>
                <li>Аутентичные материалы из разных сфер жизни</li>
            </ul>
            <p><strong>Связь с теорией:</strong></p>
            <p><strong>Input Hypothesis</strong> (Крашен): Большой объём понятного входа — основа усвоения языка.</p>
            <p><strong>Incidental learning:</strong> Непреднамеренное усвоение языковых явлений через exposure.</p>
        </div>
    </div>
    
    <div class="curriculum-learning">
        <h3 class="curriculum-learning-title">1.4. Curriculum Learning (Обучение по программе)</h3>
        <div class="curriculum-learning-card">
            <p><strong>LLM-контекст:</strong></p>
            <p>Стратегия обучения, при которой примеры подаются модели в определённом порядке — от простых к сложным. Это ускоряет обучение и улучшает конечное качество.</p>
            <p><strong>Педагогическая параллель:</strong></p>
            <ul>
                <li>Дидактический принцип постепенности и последовательности</li>
                <li><strong>Scaffolding</strong> (Брунер): временная поддержка, которая постепенно снимается</li>
                <li><strong>i+1</strong> (Крашен): материал чуть выше текущего уровня</li>
                <li><strong>ZPD</strong> (Выготский): зона ближайшего развития</li>
            </ul>
            <p><strong>Практические следствия:</strong></p>
            <ul>
                <li>Продуманная секвенция материала (syllabus design)</li>
                <li>Диагностика текущего уровня для определения «следующего шага»</li>
                <li>Избегание как слишком лёгких, так и слишком сложных задач</li>
            </ul>
        </div>
    </div>
    
    <div class="table-kmp">
        <table class="table">
            <thead>
                <tr>
                    <th>Модель</th>
                    <th>Ключевая идея LLM</th>
                    <th>Педагогический принцип</th>
                </tr>
            </thead>
            <tr>
                <td>Transfer Learning</td>
                <td>Перенос знаний из одной области в другую</td>
                <td>Опора на предшествующий опыт</td>
            </tr>
            <tr>
                <td>Fine-Tuning</td>
                <td>Адаптация общей модели под специфику</td>
                <td>Дифференциация и персонализация</td>
            </tr>
            <tr>
                <td>Pre-training on Diverse Data</td>
                <td>Разнообразие формирует гибкость</td>
                <td>Extensive input, аутентичность</td>
            </tr>
            <tr>
                <td>Curriculum Learning</td>
                <td>Порядок подачи материала важен</td>
                <td>От простого к сложному (scaffolding)</td>
            </tr>
        </table>
    </div>
    <div class="kmp11"><strong>Примечание:</strong> Базовые модели — фундамент любой системы обучения (и машинного, и человеческого). Они определяют архитектуру учебного процесса.</div>
</section>

<section id="positive-data" class="section">
    <h2 class="section-title">2. Позитивные стратегии: Работа с данными</h2>
    
    <div class="data-augmentation">
        <h3 class="data-augmentation-title">2.1. Data Augmentation (Аугментация данных)</h3>
        <div class="data-augmentation-card">
            <p><strong>LLM-контекст:</strong></p>
            <p>Искусственное увеличение объёма и разнообразия обучающих данных путём трансформаций: перефразирование, добавление шума, обратный перевод, замена синонимов. Это помогает модели лучше обобщать.</p>
            <p><strong>Пример:</strong> Предложение «Кот сидит на коврике» → «На коврике расположился кот» → «Кошка лежит на ковре».</p>
            <p><strong>Педагогическая параллель:</strong></p>
            <ul>
                <li>Вариативность упражнений на одну и ту же тему</li>
                <li>Работа с парафразами, синонимами, трансформациями</li>
                <li>Один и тот же концепт в разных контекстах и модальностях</li>
                <li>Ролевые игры с вариациями сценария</li>
            </ul>
            <p><strong>Практические следствия:</strong></p>
            <ul>
                <li>Не ограничиваться одним примером на правило</li>
                <li>Предлагать разные форматы практики (письмо, устно, игра)</li>
                <li>Использовать back-translation как упражнение</li>
            </ul>
        </div>
    </div>
    
    <div class="active-learning">
        <h3 class="active-learning-title">2.2. Active Learning (Активное обучение)</h3>
        <div class="active-learning-card">
            <p><strong>LLM-контекст:</strong></p>
            <p>Стратегия, при которой модель сама «выбирает», на каких примерах её нужно дообучить — запрашивает разметку для наиболее неопределённых или информативных случаев. Это эффективнее случайной выборки.</p>
            <p><strong>Педагогическая параллель:</strong></p>
            <ul>
                <li>Студент формулирует свои вопросы и затруднения</li>
                <li>Диагностика «зон неуверенности» для целенаправленной работы</li>
                <li>Обучение через запросы (inquiry-based learning)</li>
                <li>Рефлексия: «Что я ещё не понимаю?»</li>
            </ul>
            <p><strong>Практические следствия:</strong></p>
            <ul>
                <li>Создавать пространство для вопросов студентов</li>
                <li>Учить студентов идентифицировать свои пробелы</li>
                <li>Использовать диагностические тесты для выявления «зон неуверенности»</li>
            </ul>
        </div>
    </div>
    
    <div class="contrastive-learning">
        <h3 class="contrastive-learning-title">2.3. Contrastive Learning (Контрастивное обучение)</h3>
        <div class="contrastive-learning-card">
            <p><strong>LLM-контекст:</strong></p>
            <p>Обучение через сравнение похожих и различных примеров. Модель учится сближать представления семантически близких элементов и отдалять различные.</p>
            <p><strong>Пример:</strong> «Счастливый» и «радостный» должны быть близко; «счастливый» и «грустный» — далеко в векторном пространстве.</p>
            <p><strong>Педагогическая параллель:</strong></p>
            <ul>
                <li><strong>Метод минимальных пар:</strong> «был — бил», «ship — sheep»</li>
                <li>Сопоставительный анализ языков (contrastive analysis)</li>
                <li>Работа с паронимами, ложными друзьями переводчика</li>
                <li>Сравнение правильного и ошибочного варианта</li>
            </ul>
            <p><strong>Практические следствия:</strong></p>
            <ul>
                <li>Явно противопоставлять трудные случаи</li>
                <li>Использовать ошибки как учебный материал</li>
                <li>Строить упражнения на дифференциацию</li>
            </ul>
        </div>
    </div>
    
    <div class="kmp14"><strong>Пояснение:</strong> Стратегии работы с данными в LLM напоминают о том, что качество и разнообразие input'а критически важны для обучения — как машинного, так и человеческого.</div>
</section>

<section id="positive-control" class="section">
    <h2 class="section-title">3. Позитивные стратегии: Контроль качества</h2>
    
    <div class="regularization">
        <h3 class="regularization-title">3.1. Regularization (Регуляризация)</h3>
        <div class="regularization-card">
            <p><strong>LLM-контекст:</strong></p>
            <p>Техники, предотвращающие переобучение: добавление «штрафа» за слишком сложные модели, dropout (случайное отключение нейронов), ограничение весов. Цель — сохранить способность к обобщению.</p>
            <p><strong>Педагогическая параллель:</strong></p>
            <ul>
                <li>Ограничение «заучивания» в пользу понимания</li>
                <li>Вариативность в тестировании (не повторять формулировки из учебника)</li>
                <li>Задачи на применение в новых контекстах</li>
                <li>Принцип «меньше, но глубже» (less is more)</li>
            </ul>
            <p><strong>Dropout как метафора:</strong></p>
            <p>Случайное «отключение» привычных опор (словарь, подсказки) заставляет использовать разные стратегии и формирует устойчивые навыки.</p>
        </div>
    </div>
    
    <div class="cross-validation">
        <h3 class="cross-validation-title">3.2. Cross-Validation (Кросс-валидация)</h3>
        <div class="cross-validation-card">
            <p><strong>LLM-контекст:</strong></p>
            <p>Разделение данных на несколько частей и многократное обучение/тестирование на разных комбинациях. Это даёт более надёжную оценку качества модели.</p>
            <p><strong>Педагогическая параллель:</strong></p>
            <ul>
                <li>Разнообразие форматов оценивания (не только тесты)</li>
                <li>Проверка навыка в разных контекстах и ситуациях</li>
                <li>Формативное оценивание на протяжении курса</li>
                <li>Peer assessment и self-assessment как дополнительные «фолды»</li>
            </ul>
            <p><strong>Практические следствия:</strong></p>
            <ul>
                <li>Не полагаться на один финальный экзамен</li>
                <li>Проверять один навык разными способами</li>
                <li>Использовать портфолио как инструмент валидации</li>
            </ul>
        </div>
    </div>
    
    <div class="robust-evaluation">
        <h3 class="robust-evaluation-title">3.3. Robust Evaluation (Устойчивая оценка)</h3>
        <div class="robust-evaluation-card">
            <p><strong>LLM-контекст:</strong></p>
            <p>Тестирование модели не только на стандартных бенчмарках, но и на «сложных» случаях: edge cases, adversarial examples, out-of-distribution data. Это выявляет скрытые слабости.</p>
            <p><strong>Педагогическая параллель:</strong></p>
            <ul>
                <li>Проверка не только типичных, но и нестандартных случаев</li>
                <li>Задания на «исключения из правил»</li>
                <li>Симуляция реальных коммуникативных ситуаций (с шумом, прерываниями)</li>
                <li>Тестирование в условиях стресса или ограниченного времени</li>
            </ul>
            <p><strong>Вопрос для рефлексии:</strong></p>
            <p><em>Проверяем ли мы, что студент справится с языком в реальной жизни — или только в идеальных условиях класса?</em></p>
        </div>
    </div>
    
    <div class="table-kmp">
        <table class="table">
            <thead>
                <tr>
                    <th>Стратегия</th>
                    <th>Что предотвращает</th>
                    <th>Педагогический инструмент</th>
                </tr>
            </thead>
            <tr>
                <td>Regularization</td>
                <td>Переобучение, негибкость</td>
                <td>Вариативность, transfer tasks</td>
            </tr>
            <tr>
                <td>Cross-Validation</td>
                <td>Ненадёжность оценки</td>
                <td>Множественные форматы assessment</td>
            </tr>
            <tr>
                <td>Robust Evaluation</td>
                <td>Ложная уверенность в успехе</td>
                <td>Edge cases, реальные ситуации</td>
            </tr>
        </table>
    </div>
</section>

<section id="positive-human" class="section">
    <h2 class="section-title">4. Позитивные стратегии: Человеко-ориентированные подходы</h2>
    
    <div class="human-in-loop">
        <h3 class="human-in-loop-title">4.1. Human-in-the-Loop (Человек в контуре)</h3>
        <div class="human-in-loop-card">
            <p><strong>LLM-контекст:</strong></p>
            <p>Включение человека в процесс обучения и корректировки модели. Человек оценивает выходы модели, предоставляет feedback, размечает данные, корректирует ошибки.</p>
            <p><strong>Ключевая роль:</strong> Аннотатор в RLHF — «арбитр качества», определяющий, какой ответ лучше.</p>
            <p><strong>Педагогическая параллель:</strong></p>
            <ul>
                <li><strong>Учитель</strong> как источник corrective feedback</li>
                <li>Scaffolding: своевременная поддержка и коррекция</li>
                <li>Менторство, наставничество</li>
                <li>Модерация peer learning</li>
            </ul>
            <p><strong>Практические следствия:</strong></p>
            <ul>
                <li>Feedback должен быть своевременным и конкретным</li>
                <li>Важно не только исправлять, но объяснять</li>
                <li>Роль учителя — не «карающий судья», а «настройщик» процесса</li>
            </ul>
        </div>
    </div>
    
    <div class="interpretability">
        <h3 class="interpretability-title">4.2. Interpretability & Explainability (Интерпретируемость и объяснимость)</h3>
        <div class="interpretability-card">
            <p><strong>LLM-контекст:</strong></p>
            <p>Способность понять, <em>почему</em> модель приняла то или иное решение. Визуализация attention, анализ внутренних представлений, объяснение логики ответа.</p>
            <p><strong>Проблема:</strong> LLM часто — «чёрный ящик»: работает, но непонятно почему.</p>
            <p><strong>Педагогическая параллель:</strong></p>
            <ul>
                <li><strong>Метакогниция:</strong> Понимание собственных мыслительных процессов</li>
                <li>«Покажи, как ты решал» — объяснение хода рассуждения</li>
                <li>Think-aloud protocols в обучении</li>
                <li>Рефлексия: «Почему я сделал эту ошибку?»</li>
            </ul>
            <p><strong>Практические следствия:</strong></p>
            <ul>
                <li>Учить студентов артикулировать свои стратегии</li>
                <li>Не только «правильно/неправильно», но «почему»</li>
                <li>Развивать языковую осознанность (language awareness)</li>
            </ul>
        </div>
    </div>
    
    <div class="fairness">
        <h3 class="fairness-title">4.3. Fairness & Bias Mitigation (Справедливость и снижение предвзятости)</h3>
        <div class="fairness-card">
            <p><strong>LLM-контекст:</strong></p>
            <p>Выявление и устранение систематических предвзятостей модели: гендерных, расовых, культурных стереотипов, унаследованных из обучающих данных.</p>
            <p><strong>Пример:</strong> Модель ассоциирует «врач» с мужчинами, а «медсестра» с женщинами.</p>
            <p><strong>Педагогическая параллель:</strong></p>
            <ul>
                <li>Инклюзивность учебных материалов</li>
                <li>Репрезентация разных культур, гендеров, социальных групп</li>
                <li>Критический анализ стереотипов в текстах</li>
                <li>Осознание собственных предвзятостей преподавателя</li>
            </ul>
            <p><strong>Вопрос для рефлексии:</strong></p>
            <p><em>Какие «предвзятости» мы неосознанно транслируем через выбор текстов, примеров, тем для обсуждения?</em></p>
        </div>
    </div>
    <div class="kmp12"><strong>Важно:</strong> Человек остаётся центральной фигурой как в обучении LLM (RLHF), так и в языковом образовании. Технологии — инструмент, а не замена педагогу.</div>
</section>

<section id="positive-advanced" class="section">
    <h2 class="section-title">5. Позитивные стратегии: Продвинутые методы</h2>
    
    <div class="multitask">
        <h3 class="multitask-title">5.1. Multitask Learning (Мультизадачное обучение)</h3>
        <div class="multitask-card">
            <p><strong>LLM-контекст:</strong></p>
            <p>Одновременное обучение модели нескольким задачам (перевод, суммаризация, ответы на вопросы). Это формирует более универсальные внутренние представления.</p>
            <p><strong>Педагогическая параллель:</strong></p>
            <ul>
                <li>Интегрированное обучение всем видам речевой деятельности</li>
                <li>CLIL (Content and Language Integrated Learning)</li>
                <li>Project-based learning с разными типами заданий</li>
                <li>Коммуникативный подход: язык для решения реальных задач</li>
            </ul>
        </div>
    </div>
    
    <div class="knowledge-distillation">
        <h3 class="knowledge-distillation-title">5.2. Knowledge Distillation (Дистилляция знаний)</h3>
        <div class="knowledge-distillation-card">
            <p><strong>LLM-контекст:</strong></p>
            <p>Передача «знаний» от большой модели (teacher) к маленькой (student). Маленькая модель учится воспроизводить поведение большой, сохраняя качество при меньших ресурсах.</p>
            <p><strong>Педагогическая параллель:</strong></p>
            <ul>
                <li>Учитель как «упрощённый эксперт» — транспозиция академического знания</li>
                <li>Учебники как дистилляция научного знания</li>
                <li>Peer tutoring: более сильный студент обучает слабого</li>
                <li>Адаптация сложного материала для уровня студента</li>
            </ul>
            <p><strong>Практические следствия:</strong></p>
            <p>Искусство преподавания — это искусство дистилляции: сохранить суть, убрав избыточную сложность.</p>
        </div>
    </div>
    
    <div class="meta-learning">
        <h3 class="meta-learning-title">5.3. Meta-Learning (Мета-обучение)</h3>
        <div class="meta-learning-card">
            <p><strong>LLM-контекст:</strong></p>
            <p>«Обучение учиться» — модель учится быстро адаптироваться к новым задачам на основе минимального количества примеров. Вместо знания конкретных задач — знание о том, как решать задачи.</p>
            <p><strong>Педагогическая параллель:</strong></p>
            <ul>
                <li><strong>Learning to learn:</strong> метакогнитивные стратегии</li>
                <li>Развитие учебной автономии</li>
                <li>Обучение стратегиям запоминания, понимания, самоконтроля</li>
                <li>Подготовка к lifelong learning</li>
            </ul>
            <p><strong>Практические следствия:</strong></p>
            <ul>
                <li>Учить не только языку, но стратегиям его изучения</li>
                <li>Развивать способность к самостоятельному обучению</li>
                <li>Формировать «инструментарий» для освоения новых языков</li>
            </ul>
        </div>
    </div>
    
    <div class="ensemble">
        <h3 class="ensemble-title">5.4. Ensemble Methods (Ансамблевые методы)</h3>
        <div class="ensemble-card">
            <p><strong>LLM-контекст:</strong></p>
            <p>Комбинирование нескольких моделей для получения более надёжного результата. Разные модели «голосуют» или их ответы усредняются.</p>
            <p><strong>Педагогическая параллель:</strong></p>
            <ul>
                <li>Множественные источники информации (не только учебник)</li>
                <li>Разные преподаватели, разные точки зрения</li>
                <li>Peer learning: обмен стратегиями между студентами</li>
                <li>Triangulation в оценивании</li>
            </ul>
        </div>
    </div>
    
    <div class="continuous-learning">
        <h3 class="continuous-learning-title">5.5. Continuous Learning (Непрерывное обучение)</h3>
        <div class="continuous-learning-card">
            <p><strong>LLM-контекст:</strong></p>
            <p>Способность модели учиться на новых данных без «забывания» старых. Критическая проблема: catastrophic forgetting (см. раздел «Патологии»).</p>
            <p><strong>Педагогическая параллель:</strong></p>
            <ul>
                <li><strong>Lifelong learning:</strong> обучение на протяжении всей жизни</li>
                <li>Спиральный curriculum: возврат к темам на новом уровне</li>
                <li>Spaced repetition: распределённое повторение</li>
                <li>Языковое maintenance после завершения курса</li>
            </ul>
        </div>
    </div>
    
    <div class="table-kmp">
        <table class="table">
            <thead>
                <tr>
                    <th>Метод</th>
                    <th>LLM</th>
                    <th>Языковое образование</th>
                </tr>
            </thead>
            <tr>
                <td>Multitask Learning</td>
                <td>Универсальные представления</td>
                <td>Интегрированное обучение, CLIL</td>
            </tr>
            <tr>
                <td>Knowledge Distillation</td>
                <td>Teacher → Student model</td>
                <td>Транспозиция знаний, адаптация</td>
            </tr>
            <tr>
                <td>Meta-Learning</td>
                <td>Быстрая адаптация к новому</td>
                <td>Учебная автономия, learning to learn</td>
            </tr>
            <tr>
                <td>Ensemble Methods</td>
                <td>Комбинация моделей</td>
                <td>Множественные источники, peer learning</td>
            </tr>
            <tr>
                <td>Continuous Learning</td>
                <td>Обучение без забывания</td>
                <td>Спиральный curriculum, lifelong learning</td>
            </tr>
        </table>
    </div>
</section>

<section id="3" class="section">
    <h2 class="section-title">6. Патологии обучения: Проблемы обобщения</h2>
    
    <div class="overfitting">
        <h3 class="overfitting-title">6.1. Overfitting (Переобучение)</h3>
        <div class="overfitting-card">
            <p><strong>LLM-контекст:</strong></p>
            <p>Модель слишком точно «запоминает» обучающие данные, включая шум и случайные особенности. На новых данных качество резко падает.</p>
            <p><strong>Симптом:</strong> Отличные результаты на train set, плохие на test set.</p>
            <p><strong>Педагогическая параллель:</strong></p>
            <ul>
                <li>Зубрёжка без понимания (rote learning)</li>
                <li>Студент воспроизводит формулировки учебника, но не может применить знания</li>
                <li>«Натаскивание» на конкретный формат экзамена</li>
                <li>Неспособность адаптировать выученное к новой ситуации</li>
            </ul>
            <p><strong>Признаки у студента:</strong></p>
            <ul>
                <li>Успешно отвечает на знакомые вопросы, теряется на новых</li>
                <li>Использует заученные фразы без понимания их структуры</li>
                <li>Не может перефразировать или объяснить своими словами</li>
            </ul>
            <p><strong>Как противодействовать:</strong></p>
            <ul>
                <li>Вариативность в заданиях (Data Augmentation)</li>
                <li>Тесты на transfer, а не воспроизведение</li>
                <li>Акцент на понимании, а не запоминании</li>
            </ul>
        </div>
    </div>
    
    <div class="underfitting">
        <h3 class="underfitting-title">6.2. Underfitting (Недообучение)</h3>
        <div class="underfitting-card">
            <p><strong>LLM-контекст:</strong></p>
            <p>Модель слишком простая или недостаточно обучена, чтобы уловить закономерности в данных. Плохие результаты и на train, и на test.</p>
            <p><strong>Причины:</strong> Недостаточное время обучения, слишком простая архитектура, слишком мало данных.</p>
            <p><strong>Педагогическая параллель:</strong></p>
            <ul>
                <li>Недостаточный input (мало практики, exposure)</li>
                <li>Прерванное обучение, пропуски занятий</li>
                <li>Слишком поверхностное изучение (skim without depth)</li>
                <li>Курс слишком короткий для достижения уровня</li>
            </ul>
            <p><strong>Признаки у студента:</strong></p>
            <ul>
                <li>Не усвоены даже базовые паттерны</li>
                <li>Ошибки в элементарных конструкциях</li>
                <li>Отсутствие «языковой интуиции»</li>
            </ul>
            <p><strong>Как противодействовать:</strong></p>
            <ul>
                <li>Увеличить объём input'а и практики</li>
                <li>Обеспечить достаточное время на освоение</li>
                <li>Диагностировать пробелы и заполнять их</li>
            </ul>
        </div>
    </div>
    
    <div class="shortcut-learning">
        <h3 class="shortcut-learning-title">6.3. Shortcut Learning (Обучение «срезкам»)</h3>
        <div class="shortcut-learning-card">
            <p><strong>LLM-контекст:</strong></p>
            <p>Модель находит поверхностные корреляции в данных вместо глубоких закономерностей. Работает на бенчмарках, ломается в реальности.</p>
            <p><strong>Пример:</strong> Модель определяет негативный отзыв по наличию слова «не», игнорируя «неплохо» или «не могу не похвалить».</p>
            <p><strong>Педагогическая параллель:</strong></p>
            <ul>
                <li>Угадывание ответа по «ключевым словам»</li>
                <li>Формальные признаки вместо понимания смысла</li>
                <li>«Если видишь -ed, это Past Simple» (без учёта контекста)</li>
                <li>Стратегии сдачи тестов вместо знания предмета</li>
            </ul>
            <p><strong>Как противодействовать:</strong></p>
            <ul>
                <li>Создавать «ловушки» в заданиях (adversarial examples)</li>
                <li>Требовать объяснения решения</li>
                <li>Тестировать на нетипичных примерах</li>
            </ul>
        </div>
    </div>
    
    <div class="table-kmp">
        <table class="table">
            <thead>
                <tr>
                    <th>Патология</th>
                    <th>Симптом в LLM</th>
                    <th>Симптом у студента</th>
                    <th>Лечение</th>
                </tr>
            </thead>
            <tr>
                <td>Overfitting</td>
                <td>Хорошо на train, плохо на test</td>
                <td>Зубрит, но не понимает</td>
                <td>Вариативность, transfer tasks</td>
            </tr>
            <tr>
                <td>Underfitting</td>
                <td>Плохо везде</td>
                <td>Недостаточно практики</td>
                <td>Больше input'а и времени</td>
            </tr>
            <tr>
                <td>Shortcut Learning</td>
                <td>Поверхностные паттерны</td>
                <td>Угадывает по ключевым словам</td>
                <td>Adversarial examples</td>
            </tr>
        </table>
    </div>
</section>

<section id="pathology-memory" class="section">
    <h2 class="section-title">7. Патологии обучения: Проблемы памяти и знаний</h2>
    
    <div class="catastrophic-forgetting">
        <h3 class="catastrophic-forgetting-title">7.1. Catastrophic Forgetting (Катастрофическое забывание)</h3>
        <div class="catastrophic-forgetting-card">
            <p><strong>LLM-контекст:</strong></p>
            <p>При обучении новым задачам модель резко теряет способность выполнять старые. Новые знания «перезаписывают» предыдущие.</p>
            <p><strong>Пример:</strong> Модель, дообученная на медицинских текстах, забывает, как вести общий диалог.</p>
            <p><strong>Педагогическая параллель:</strong></p>
            <ul>
                <li><strong>Attrition:</strong> Утрата языка при переезде или смене среды</li>
                <li>Забывание L2 при интенсивном изучении L3</li>
                <li>Потеря ранее усвоенных навыков без практики</li>
                <li><strong>Language loss</strong> у heritage speakers</li>
            </ul>
            <p><strong>Как противодействовать:</strong></p>
            <ul>
                <li>Спиральный curriculum: регулярный возврат к пройденному</li>
                <li>Spaced repetition systems (SRS)</li>
                <li>Интегрированная практика старого и нового</li>
                <li>Maintenance activities после завершения курса</li>
            </ul>
        </div>
    </div>
    
    <div class="memorization">
        <h3 class="memorization-title">7.2. Over-reliance on Memorization (Чрезмерная опора на запоминание)</h3>
        <div class="memorization-card">
            <p><strong>LLM-контекст:</strong></p>
            <p>Модель воспроизводит фрагменты обучающих данных вместо генерации нового. Проблема особенно острая с редкими или уникальными текстами.</p>
            <p><strong>Педагогическая параллель:</strong></p>
            <ul>
                <li>Заученные фразы без понимания их структуры</li>
                <li>Использование «формул» без адаптации к ситуации</li>
                <li>Неспособность перефразировать, только воспроизвести</li>
                <li>«Phrasebook approach» без продуктивной грамматики</li>
            </ul>
            <p><strong>Признаки:</strong></p>
            <ul>
                <li>Студент говорит «заученными блоками»</li>
                <li>Паника при необходимости сказать что-то «не по шаблону»</li>
                <li>Ошибки при малейшем изменении контекста</li>
            </ul>
        </div>
    </div>
    
    <div class="hallucination">
        <h3 class="hallucination-title">7.3. Hallucination (Галлюцинация)</h3>
        <div class="hallucination-card">
            <p><strong>LLM-контекст:</strong></p>
            <p>Модель уверенно генерирует ложную информацию, которой не было в обучающих данных и которая не соответствует реальности.</p>
            <p><strong>Пример:</strong> Цитирование несуществующих книг, выдуманные факты из биографий.</p>
            <p><strong>Педагогическая параллель:</strong></p>
            <ul>
                <li>Ложная уверенность при недостатке знаний</li>
                <li>«Выдумывание» информации на экзамене</li>
                <li>Псевдо-знание: студент уверен, но ошибается</li>
                <li>Overgeneralization: «Все глаголы на -ить — II спряжения»</li>
            </ul>
            <p><strong>Как противодействовать:</strong></p>
            <ul>
                <li>Учить говорить «не знаю»</li>
                <li>Развивать критическую самооценку</li>
                <li>Поощрять проверку информации</li>
                <li>Калибровка уверенности (confidence calibration)</li>
            </ul>
        </div>
    </div>
    
    <div class="plateau">
        <h3 class="plateau-title">7.4. Plateau Effect (Эффект плато)</h3>
        <div class="plateau-card">
            <p><strong>LLM-контекст:</strong></p>
            <p>Прекращение улучшения качества модели несмотря на продолжение обучения. Loss перестаёт снижаться.</p>
            <p><strong>Педагогическая параллель:</strong></p>
            <ul>
                <li><strong>Language learning plateau:</strong> Застой на intermediate уровне</li>
                <li><strong>Fossilization:</strong> Закрепление ошибок, устойчивых к коррекции</li>
                <li>Потеря мотивации из-за отсутствия видимого прогресса</li>
            </ul>
            <p><strong>Как преодолевать:</strong></p>
            <ul>
                <li>Изменение типа input'а и заданий</li>
                <li>Новые цели и challenge</li>
                <li>Фокус на qualitative, а не quantitative прогресс</li>
                <li>Погружение в среду (immersion)</li>
            </ul>
        </div>
    </div>
    <div class="kmp14"><strong>Пояснение:</strong> Патологии памяти и знаний особенно актуальны для языкового образования, где требуется баланс между запоминанием и продуктивным использованием.</div>
</section>

<section id="pathology-data" class="section">
    <h2 class="section-title">8. Патологии обучения: Проблемы данных</h2>
    
    <div class="data-poisoning">
        <h3 class="data-poisoning-title">8.1. Data Poisoning (Отравление данных)</h3>
        <div class="data-poisoning-card">
            <p><strong>LLM-контекст:</strong></p>
            <p>Намеренное или случайное включение в обучающие данные ошибочной, вредоносной или манипулятивной информации.</p>
            <p><strong>Педагогическая параллель:</strong></p>
            <ul>
                <li>Некачественные учебные материалы с ошибками</li>
                <li>Некорректный input от некомпетентного преподавателя</li>
                <li>Ошибочные модели от peers</li>
                <li>Дезинформация в интернет-ресурсах</li>
            </ul>
            <p><strong>Как противодействовать:</strong></p>
            <ul>
                <li>Критическая оценка источников</li>
                <li>Приоритет проверенных материалов</li>
                <li>Развитие media literacy у студентов</li>
            </ul>
        </div>
    </div>
    
    <div class="bias-amplification">
        <h3 class="bias-amplification-title">8.2. Bias Amplification (Усиление предвзятости)</h3>
        <div class="bias-amplification-card">
            <p><strong>LLM-контекст:</strong></p>
            <p>Модель не только воспроизводит, но и усиливает предвзятости, присутствующие в данных. Маргинальные стереотипы становятся доминирующими.</p>
            <p><strong>Педагогическая параллель:</strong></p>
            <ul>
                <li>Закрепление стереотипов через односторонний материал</li>
                <li>Усиление «школьного» языка в ущерб разнообразию</li>
                <li>Нормативизм без объяснения вариативности</li>
                <li>Представление одной культуры как «эталонной»</li>
            </ul>
            <p><strong>Пример:</strong> Если все тексты о бизнесе используют «он», студенты усваивают гендерную ассоциацию.</p>
        </div>
    </div>
    
    <div class="distribution-shift">
        <h3 class="distribution-shift-title">8.3. Distribution Shift (Сдвиг распределения)</h3>
        <div class="distribution-shift-card">
            <p><strong>LLM-контекст:</strong></p>
            <p>Данные при использовании модели отличаются от данных при обучении. Модель, обученная на новостях, плохо работает с поэзией.</p>
            <p><strong>Педагогическая параллель:</strong></p>
            <ul>
                <li><strong>Classroom ≠ Real life:</strong> Разрыв между учебными и реальными ситуациями</li>
                <li>Учебные диалоги vs. аутентичная коммуникация</li>
                <li>«Стерильный» язык учебника vs. живая речь</li>
                <li>Шок при столкновении с носителями</li>
            </ul>
            <p><strong>Как противодействовать:</strong></p>
            <ul>
                <li>Аутентичные материалы с первых уровней</li>
                <li>Вариативность регистров и жанров</li>
                <li>Симуляция реальных ситуаций</li>
                <li>Task-based и project-based learning</li>
            </ul>
        </div>
    </div>
    
    <div class="data-leakage">
        <h3 class="data-leakage-title">8.4. Data Leakage (Утечка данных)</h3>
        <div class="data-leakage-card">
            <p><strong>LLM-контекст:</strong></p>
            <p>Тестовые данные случайно попадают в обучающую выборку. Модель показывает отличные результаты на тесте, но это ложный успех.</p>
            <p><strong>Педагогическая параллель:</strong></p>
            <ul>
                <li>«Слив» экзаменационных заданий</li>
                <li>Использование тех же текстов на уроке и на тесте</li>
                <li>Формулировки из учебника дословно в контрольной</li>
                <li>Ложные показатели успеха программы</li>
            </ul>
            <p><strong>Как противодействовать:</strong></p>
            <ul>
                <li>Строгое разделение учебных и тестовых материалов</li>
                <li>Вариативность в формулировках заданий</li>
                <li>External assessment когда возможно</li>
            </ul>
        </div>
    </div>
</section>

<section id="pathology-evaluation" class="section">
    <h2 class="section-title">9. Патологии обучения: Проблемы оценки и оптимизации</h2>
    
    <div class="benchmark-optimization">
        <h3 class="benchmark-optimization-title">9.1. Over-optimization on Benchmarks (Переоптимизация на бенчмарках)</h3>
        <div class="benchmark-optimization-card">
            <p><strong>LLM-контекст:</strong></p>
            <p>Модель настраивается именно на тестовые метрики, а не на реальное качество. Отличные цифры, но плохая работа на практике.</p>
            <p><strong>Педагогическая параллель:</strong></p>
            <ul>
                <li><strong>Teaching to the test:</strong> Подготовка к формату экзамена, а не к владению языком</li>
                <li>Погоня за баллами IELTS/TOEFL без реальной компетенции</li>
                <li>«Сертификат есть, а говорить не может»</li>
            </ul>
            <p><strong>Системная проблема:</strong></p>
            <p>Когда метрика становится целью, она перестаёт быть хорошей метрикой (Закон Гудхарта).</p>
        </div>
    </div>
    
    <div class="reward-hacking">
        <h3 class="reward-hacking-title">9.2. Reward Hacking (Взлом функции вознаграждения)</h3>
        <div class="reward-hacking-card">
            <p><strong>LLM-контекст:</strong></p>
            <p>Модель находит «лазейки» для максимизации reward без реального решения задачи. Формально выполняет требования, но не по существу.</p>
            <p><strong>Пример:</strong> Модель делает ответ длиннее (больше reward за детальность), но не информативнее.</p>
            <p><strong>Педагогическая параллель:</strong></p>
            <ul>
                <li>«Gaming the system»: манипуляция с оценками</li>
                <li>Формальное выполнение задания (написал 250 слов, но не по теме)</li>
                <li>Списывание, использование переводчиков</li>
                <li>Заучивание «правильных» ответов без понимания</li>
            </ul>
            <p><strong>Как противодействовать:</strong></p>
            <ul>
                <li>Разнообразие критериев оценки</li>
                <li>Проверка процесса, а не только результата</li>
                <li>Устные защиты письменных работ</li>
            </ul>
        </div>
    </div>
    
    <div class="poor-calibration">
        <h3 class="poor-calibration-title">9.3. Poor Calibration (Плохая калибровка)</h3>
        <div class="poor-calibration-card">
            <p><strong>LLM-контекст:</strong></p>
            <p>Несоответствие между уверенностью модели и реальной точностью. Модель может быть очень уверена в неправильном ответе или неуверена в правильном.</p>
            <p><strong>Педагогическая параллель:</strong></p>
            <ul>
                <li><strong>Dunning-Kruger эффект:</strong> Новички переоценивают свои знания</li>
                <li><strong>Imposter syndrome:</strong> Продвинутые недооценивают</li>
                <li>Неумение адекватно оценить свой уровень</li>
                <li>Ложная уверенность или неоправданный страх</li>
            </ul>
            <p><strong>Как развивать калибровку:</strong></p>
            <ul>
                <li>Регулярная обратная связь</li>
                <li>Самооценка с последующей проверкой</li>
                <li>Рефлексия над ошибками</li>
            </ul>
        </div>
    </div>
    
    <div class="insufficient-evaluation">
        <h3 class="insufficient-evaluation-title">9.4. Insufficient Evaluation (Недостаточная оценка)</h3>
        <div class="insufficient-evaluation-card">
            <p><strong>LLM-контекст:</strong></p>
            <p>Тестирование модели на ограниченном наборе задач, не выявляющем скрытых проблем.</p>
            <p><strong>Педагогическая параллель:</strong></p>
            <ul>
                <li>Оценка только одного навыка (только грамматика, только говорение)</li>
                <li>Один финальный тест без промежуточной диагностики</li>
                <li>Отсутствие проверки в разных контекстах</li>
            </ul>
        </div>
    </div>
    
    <div class="table-kmp">
        <table class="table">
            <thead>
                <tr>
                    <th>Патология</th>
                    <th>Проблема</th>
                    <th>Педагогический симптом</th>
                </tr>
            </thead>
            <tr>
                <td>Over-optimization on Benchmarks</td>
                <td>Метрика вместо качества</td>
                <td>Teaching to the test</td>
            </tr>
            <tr>
                <td>Reward Hacking</td>
                <td>Лазейки в системе оценки</td>
                <td>Gaming, формальное выполнение</td>
            </tr>
            <tr>
                <td>Poor Calibration</td>
                <td>Неадекватная самооценка</td>
                <td>Dunning-Kruger, imposter syndrome</td>
            </tr>
            <tr>
                <td>Insufficient Evaluation</td>
                <td>Неполная картина</td>
                <td>Односторонний assessment</td>
            </tr>
        </table>
    </div>
</section>

<section id="pathology-system" class="section">
    <h2 class="section-title">10. Патологии обучения: Системные проблемы</h2>
    
    <div class="lack-robustness">
        <h3 class="lack-robustness-title">10.1. Lack of Robustness (Недостаток устойчивости)</h3>
        <div class="lack-robustness-card">
            <p><strong>LLM-контекст:</strong></p>
            <p>Модель легко «ломается» при небольших изменениях входа: опечатки, переформулировки, необычное форматирование.</p>
            <p><strong>Педагогическая параллель:</strong></p>
            <ul>
                <li>Потеря навыка в стрессовой ситуации</li>
                <li>Неспособность понять акцент, быструю речь, шум</li>
                <li>Ступор при незнакомой формулировке задания</li>
                <li>«Выученная беспомощность» при отклонении от шаблона</li>
            </ul>
            <p><strong>Как развивать устойчивость:</strong></p>
            <ul>
                <li>Практика в неидеальных условиях</li>
                <li>Exposure к разным акцентам, регистрам, скоростям</li>
                <li>Simulation стрессовых ситуаций</li>
            </ul>
        </div>
    </div>
    
    <div class="adversarial">
        <h3 class="adversarial-title">10.2. Adversarial Vulnerabilities (Уязвимость к атакам)</h3>
        <div class="adversarial-card">
            <p><strong>LLM-контекст:</strong></p>
            <p>Специально сконструированные входы могут «обмануть» модель, заставив её давать неправильные или вредные ответы.</p>
            <p><strong>Педагогическая параллель:</strong></p>
            <ul>
                <li>«Ловушки» и провокационные вопросы сбивают с толку</li>
                <li>Манипулятивные формулировки в заданиях</li>
                <li>Неспособность распознать trick questions</li>
            </ul>
            <p><strong>Как развивать устойчивость:</strong></p>
            <p>Парадоксально — <em>включать</em> adversarial examples в обучение, тренировать критическое восприятие.</p>
        </div>
    </div>
    
    <div class="over-scaling">
        <h3 class="over-scaling-title">10.3. Over-scaling (Избыточное масштабирование)</h3>
        <div class="over-scaling-card">
            <p><strong>LLM-контекст:</strong></p>
            <p>Вера, что увеличение модели решит все проблемы. Но bigger ≠ better всегда: растут затраты, а качественные улучшения не гарантированы.</p>
            <p><strong>Педагогическая параллель:</strong></p>
            <ul>
                <li>«Больше часов = лучше результат» (не всегда)</li>
                <li>Информационная перегрузка</li>
                <li>Интенсивы без времени на усвоение</li>
                <li>Quantity over quality</li>
            </ul>
            <p><strong>Принцип:</strong> Иногда меньше = лучше. Качество важнее количества.</p>
        </div>
    </div>
    
    <div class="negative-transfer">
        <h3 class="negative-transfer-title">10.4. Negative Transfer (Негативный перенос)</h3>
        <div class="negative-transfer-card">
            <p><strong>LLM-контекст:</strong></p>
            <p>Знания из одной области мешают, а не помогают в другой. Модель, обученная на формальном тексте, плохо справляется с разговорным.</p>
            <p><strong>Педагогическая параллель:</strong></p>
            <ul>
                <li><strong>L1 interference:</strong> Перенос структур родного языка в L2</li>
                <li><strong>L2 → L3 interference:</strong> Путаница между изученными языками</li>
                <li>Ложные друзья переводчика</li>
                <li>Применение правил одного языка к другому</li>
            </ul>
            <p><strong>Пример:</strong> Испаноговорящий студент: «I am agree» (Estoy de acuerdo).</p>
        </div>
    </div>
    <div class="kmp12"><strong>Важно:</strong> Системные проблемы часто незаметны при поверхностной оценке. Они проявляются только при столкновении с нестандартными ситуациями или при длительном использовании.</div>
</section>

<section id="4" class="section">
    <h2 class="section-title">11. Ограничения аналогий: Критический взгляд</h2>
    
    <div class="warning">
        <h3 class="warning-title">11.1. Предупреждение</h3>
        <div class="warning-card">
            <p><strong>Важнейший принцип:</strong> Параллели между обучением LLM и обучением человека — это <em>эвристический инструмент</em>, а не утверждение об идентичности механизмов.</p>
            <p><strong>Что параллели НЕ означают:</strong></p>
            <ul>
                <li>Мозг ≠ нейросеть (биология ≠ математика)</li>
                <li>Усвоение языка ≠ машинное обучение</li>
                <li>Человеческое понимание ≠ статистическая аппроксимация</li>
                <li>Педагогика ≠ инженерия данных</li>
            </ul>
        </div>
    </div>
    
    <div class="fundamental-differences">
        <h3 class="fundamental-differences-title">11.2. Фундаментальные различия</h3>
        <div class="fundamental-differences-card">
            <p><strong>Где аналогия ломается:</strong></p>
            <p><strong>1. Embodiment (Телесность)</strong></p>
            <ul>
                <li>Человек познаёт язык через тело, ощущения, действия</li>
                <li>LLM не имеет сенсомоторного опыта</li>
                <li>Grounding problem: связь слов с реальностью</li>
            </ul>
            <p><strong>2. Социальность</strong></p>
            <ul>
                <li>Язык усваивается в социальном взаимодействии</li>
                <li>LLM обучается на «мёртвых» текстах</li>
                <li>Прагматика, контекст, отношения — вне модели</li>
            </ul>
            <p><strong>3. Интенциональность</strong></p>
            <ul>
                <li>Человек говорит <em>о чём-то</em>, <em>для чего-то</em>, <em>кому-то</em></li>
                <li>LLM генерирует вероятные продолжения текста</li>
                <li>Цели, желания, убеждения — человеческие атрибуты</li>
            </ul>
            <p><strong>4. Развитие</strong></p>
            <ul>
                <li>Ребёнок развивается когнитивно, эмоционально, социально</li>
                <li>LLM после обучения — статична (веса не меняются)</li>
                <li>Возрастные особенности, сензитивные периоды — только у человека</li>
            </ul>
        </div>
    </div>
    
       
    <div class="valid-use">
        <h3 class="valid-use-title">11.3. Когда аналогия полезна</h3>
        <div class="valid-use-card">
            <p><strong>Правомерное использование параллелей:</strong></p>
            <ul>
                <li><strong>Эвристика:</strong> Метафора для объяснения сложных концепций</li>
                <li><strong>Рефлексия:</strong> Повод задуматься о педагогических практиках</li>
                <li><strong>Терминология:</strong> Общий язык для междисциплинарного диалога</li>
                <li><strong>Гипотезы:</strong> Источник идей для исследований (но не доказательство)</li>
            </ul>
            <p><strong>Неправомерное использование:</strong></p>
            <ul>
                <li>❌ «Раз LLM делает X, значит и учащиеся должны»</li>
                <li>❌ «Мозг — это просто биологическая нейросеть»</li>
                <li>❌ «Обучение языку сводится к оптимизации функции потерь»</li>
                <li>❌ Механический перенос ML-метрик на оценку людей</li>
            </ul>
        </div>
    </div>
    
    <div class="epistemological">
        <h3 class="epistemological-title">11.4. Эпистемологическое примечание</h3>
        <div class="epistemological-card">
            <p><strong>О природе моделей:</strong></p>
            <p><em>«Все модели неправильны, но некоторые полезны»</em> — Джордж Бокс</p>
            <p>И LLM, и педагогические теории — это модели реальности, а не сама реальность. Ценность модели — в её объяснительной и предсказательной силе, а не в буквальном соответствии действительности.</p>
            <p><strong>Продуктивная позиция:</strong></p>
            <ul>
                <li>Использовать параллели как источник инсайтов</li>
                <li>Сохранять критическую дистанцию</li>
                <li>Проверять идеи эмпирически, а не принимать на веру</li>
                <li>Помнить о контексте и ограничениях</li>
            </ul>
        </div>
    </div>
    <div class="kmp12"><strong>Важно:</strong> Критическое отношение к аналогиям — признак зрелого профессионала. Умение видеть и сходства, и различия — основа междисциплинарного мышления.</div>
</section>

<footer class="footer">
<div class="container">
<p>© 2026 | kmp | CC BY-NC-SA 4.0<br>
для всех</p>
</div>
</footer>
<div style="position: fixed; bottom: 10px; color: #777777; right: 30px; opacity: 0.3; font-size: 14px;">kmp+</div>
        <button class="back-to-top" id="backToTop" title="Наверх">↑</button>

    <script>
        // Функция для плавной прокрутки к разделу
        function scrollToSection(sectionId) {
            const section = document.getElementById(sectionId);
            let offsetTop = section.offsetTop - 20;
            
            // На мобильных учитываем высоту меню
            if (window.innerWidth <= 768) {
                offsetTop -= document.querySelector('.mobile-menu-container').offsetHeight;
            } else {
                offsetTop -= document.querySelector('.desktop-menu').offsetHeight;
            }
            
            window.scrollTo({
                top: offsetTop,
                behavior: 'smooth'
            });
            
            // Закрываем мобильное меню после клика
            closeMobileMenu();
        }

        // Переключение мобильного меню
        const hamburgerBtn = document.getElementById('hamburgerBtn');
        const mobileMenu = document.getElementById('mobileMenu');
        
        function toggleMobileMenu() {
            mobileMenu.classList.toggle('active');
            hamburgerBtn.textContent = mobileMenu.classList.contains('active') ? '✕' : '☰';
        }
        
        function closeMobileMenu() {
            mobileMenu.classList.remove('active');
            hamburgerBtn.textContent = '☰';
        }
        
        hamburgerBtn.addEventListener('click', toggleMobileMenu);
        
        // Закрытие меню при клике вне его
        document.addEventListener('click', function(event) {
            if (!mobileMenu.contains(event.target) && !hamburgerBtn.contains(event.target)) {
                closeMobileMenu();
            }
        });

        // Функция для переключения темы
        function toggleTheme() {
            const currentTheme = document.documentElement.getAttribute('data-theme');
            const newTheme = currentTheme === 'dark' ? 'light' : 'dark';
            
            document.documentElement.setAttribute('data-theme', newTheme);
            const themeIcon = newTheme === 'dark' ? '🌙' : '☀️';
            
            // Обновляем обе кнопки переключения темы
            document.getElementById('themeToggle').textContent = themeIcon;
            document.getElementById('desktopThemeToggle').textContent = themeIcon;
        }
        
        document.getElementById('themeToggle').addEventListener('click', toggleTheme);
        document.getElementById('desktopThemeToggle').addEventListener('click', toggleTheme);

        // Анимация появления секций при прокрутке
        document.addEventListener('DOMContentLoaded', function() {
            const sections = document.querySelectorAll('.section');
            
            const observerOptions = {
                root: null,
                rootMargin: '0px',
                threshold: 0.1
            };
            
            const observer = new IntersectionObserver(function(entries, observer) {
                entries.forEach(entry => {
                    if (entry.isIntersecting) {
                        entry.target.classList.add('fade-in');
                        observer.unobserve(entry.target);
                    }
                });
            }, observerOptions);
            
            sections.forEach(section => {
                section.classList.remove('fade-in');
                observer.observe(section);
            });
        });

        // Кнопка "Наверх"
        const backToTopBtn = document.getElementById('backToTop');
        
        window.addEventListener('scroll', function() {
            if (window.pageYOffset > 300) {
                backToTopBtn.classList.add('show');
            } else {
                backToTopBtn.classList.remove('show');
            }
        });
        
        backToTopBtn.addEventListener('click', function() {
            window.scrollTo({
                top: 0,
                behavior: 'smooth'
            });
        });

        // Преобразование существующих таблиц в адаптивные
        function makeTablesResponsive() {
            const tables = document.querySelectorAll('.table-kmp table:not(.responsive-table)');
            
            tables.forEach(table => {
                // Создаем адаптивную версию
                const responsiveTable = document.createElement('table');
                responsiveTable.className = 'responsive-table';
                const tbody = document.createElement('tbody');
                
                // Получаем заголовки
                const headers = [];
                table.querySelectorAll('thead th').forEach(th => {
                    headers.push(th.textContent.trim());
                });
                
                // Преобразуем строки
                table.querySelectorAll('tbody tr').forEach(row => {
                    const newRow = document.createElement('tr');
                    const cells = row.querySelectorAll('td');
                    
                    cells.forEach((cell, index) => {
                        const newCell = document.createElement('td');
                        newCell.textContent = cell.textContent;
                        newCell.setAttribute('data-label', headers[index] || '');
                        newRow.appendChild(newCell);
                    });
                    
                    tbody.appendChild(newRow);
                });
                
                responsiveTable.appendChild(tbody);
                
                // Добавляем после оригинальной таблицы
                table.parentNode.insertBefore(responsiveTable, table.nextSibling);
            });
        }
        
        // Вызываем при загрузке
        document.addEventListener('DOMContentLoaded', makeTablesResponsive);
        
        // Закрытие меню при изменении размера окна
        window.addEventListener('resize', function() {
            if (window.innerWidth > 768) {
                closeMobileMenu();
            }
        });
    </script>
</body>
</html>
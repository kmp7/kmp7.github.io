<!DOCTYPE html>
<html lang="ru">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>kmp+</title>
    <style>
        /* Основные стили */
        :root {
            --primary-color: #325980;
            --secondary-color: #4CAF50;
            --background-color: #f5f5f5;
            --content-bg: #ffffff;
            --text-color: #333333;
            --header-text-color: #ffffff;
            --menu-bg: #ffffff;
            --menu-shadow: 0 2px 4px rgba(0, 0, 0, 0.1);
            --border-radius: 8px;
			  --accent11: #4caf50;
		--accent12: #4cafff;
		--accent13: #ffaf50;
		--accent14: #821978;
        }

        /* Темная тема */
        [data-theme="dark"] {
            --primary-color: #3e76ad;
            --secondary-color: #388e3c;
            --background-color: #000000;
            --content-bg: #1e1e1e;
            --text-color: #e0e0e0;
            --header-text-color: #ffffff;
            --menu-bg: #000000;
            --menu-shadow: 0 2px 4px rgba(0, 0, 0, 0.3);
        }

        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
            transition: background-color 0.3s, color 0.3s;
        }

        body {
            font-family: 'Roboto', 'Arial', sans-serif;
            line-height: 1.6;
            color: var(--text-color);
            background-color: var(--background-color);
            padding-top: 2px;
        }

        .container {
            max-width: 1200px;
            margin: 0 auto;
            padding: 0 20px;
        }

        header {
            background-color: var(--primary-color);
            color: var(--header-text-color);
            padding: 20px 0;
            text-align: center;
            border-radius: var(--border-radius);
            margin-bottom: 2px;
        }

        h1 {
            font-size: 2.2rem;
            margin-bottom: 10px;
        }

        h2 {
            color: var(--primary-color);
            margin: 25px 0 15px;
            padding-bottom: 8px;
            border-bottom: 2px solid var(--secondary-color);
        }

        h3 {
            color: var(--primary-color);
            margin: 20px 0 10px;
        }

        p {
            margin-bottom: 15px;
        }

        /* Меню навигации */
        .menu {
            background-color: var(--menu-bg);
            padding: 15px 20px;
            border-radius: var(--border-radius);
            margin-bottom: 30px;
            box-shadow: var(--menu-shadow);
            display: flex;
            justify-content: center;
            align-items: center;
            flex-wrap: wrap;
            position: sticky;
            top: 0;
            z-index: 100;
        }

        .menu-buttons {
            display: flex;
            flex-wrap: wrap;
            gap: 10px;
        }
		
		
		.menu-buttons {
    display: flex;
    flex-wrap: wrap;
    gap: 10px;
    justify-content: center; /* Изменено на center */
}

        .menu-btn {
            background-color: var(--primary-color);
            color: white;
            border: none;
            padding: 8px 15px;
            border-radius: 4px;
            cursor: pointer;
            font-size: 0.9rem;
            transition: background-color 0.3s;
        }

        .menu-btn:hover {
            background-color: var(--secondary-color);
        }

        .theme-toggle {
            background: none;
            border: 10px solid transparent;
            font-size: 1.5rem;
            cursor: pointer;
            color: var(--primary-color);
        }

        /* Секции контента */
        .section {
            background-color: var(--content-bg);
            border-radius: var(--border-radius);
            padding: 25px;
            margin-bottom: 30px;
            box-shadow: 0 2px 8px rgba(0, 0, 0, 0.1);
        }

        /* Выделение важного */
        .important {
            background-color: rgba(76, 175, 80, 0.1);
            border-left: 4px solid var(--secondary-color);
            padding: 15px;
            margin: 15px 0;
            border-radius: 0 var(--border-radius) var(--border-radius) 0;
        }

        .note {
            background-color: rgba(50, 89, 128, 0.1);
            border-left: 4px solid var(--primary-color);
            padding: 15px;
            margin: 15px 0;
            border-radius: 0 var(--border-radius) var(--border-radius) 0;
        }

        /* Таблицы */
        table {
            width: 100%;
            border-collapse: collapse;
            margin: 20px 0;
        }

        th, td {
            padding: 12px 15px;
            border: 1px solid #ddd;
            text-align: left;
        }

        th {
            background-color: var(--primary-color);
            color: white;
        }

        tr:nth-child(even) {
            background-color: rgba(0, 0, 0, 0.03);
        }

        /* Списки */
        ul, ol {
            padding-left: 25px;
            margin-bottom: 15px;
        }

        li {
            margin-bottom: 8px;
        }

        /* Адаптивный дизайн */
        @media (max-width: 768px) {
            h1 {
                font-size: 1.8rem;
            }
            
            h2 {
                font-size: 1.5rem;
            }
            
            .menu {
                flex-direction: column;
                gap: 15px;
            }
            
            .menu-buttons {
                width: 100%;
                justify-content: center;
            }
            
            .theme-toggle {
                margin-top: 10px;
            }
            
            .section {
                padding: 15px;
            }
        }

        /* Анимации */
        @keyframes fadeIn {
            from { opacity: 0; }
            to { opacity: 1; }
        }

        .fade-in {
            animation: fadeIn 0.5s ease-in;
        }

        footer {
            text-align: center;
            padding: 20px 0;
            margin-top: 40px;
            font-size: 0.9rem;
        }
		
					.kmp11, .example {
      background: rgba(76, 175, 80, 0.1);
      border-left: 4px solid var(--accent11);
      padding: 10px 15px;
      margin: 15px 0;
      border-radius: 4px;
    }

		.kmp12, .example {
      background: rgba(95, 182, 237, 0.1);
      border-left: 4px solid var(--accent12);
      padding: 10px 15px;
      margin: 15px 0;
      border-radius: 4px;
    }
 
		.kmp13, .example {
      background: rgba(205, 170, 110, 0.1);
      border-left: 4px solid var(--accent13);
      padding: 10px 15px;
      margin: 15px 0;
      border-radius: 4px;
    }

		.kmp14, .example {
      background: rgba(205, 110, 200, 0.1);
      border-left: 4px solid var(--accent14);
      padding: 10px 15px;
      margin: 15px 0;
      border-radius: 4px;
    }
	
	
    </style>
</head>
<body>
    <div class="container">
        <header>
            <h1>Aha moment?</h1>
            <p>One-time training in HSS (Homo sapiens sapiens) and LLM (Large Language Models)</p>
        </header>

        <nav class="menu">
            <div class="menu-buttons">
				<button class="menu-btn" onclick="scrollToSection('0')">0</button>
                <button class="menu-btn" onclick="scrollToSection('1')">1</button>
                <button class="menu-btn" onclick="scrollToSection('2')">2</button>
                <button class="menu-btn" onclick="scrollToSection('3')">3</button>
                <button class="menu-btn" onclick="scrollToSection('4')">4</button>
				<button class="menu-btn" onclick="scrollToSection('5')">5</button>
				<button class="menu-btn" onclick="scrollToSection('6')">6</button>
				<button class="menu-btn" onclick="scrollToSection('7')">7</button>
                <button class="menu-btn" onclick="scrollToSection('8')">8</button>
                <button class="menu-btn" onclick="scrollToSection('9')">9</button>
                <button class="menu-btn" onclick="scrollToSection('10')">10</button>
                <button class="menu-btn" onclick="scrollToSection('11')">11</button>
				<button class="menu-btn" onclick="scrollToSection('12')">12</button>
				
				
				
                                    </div>
            <button class="theme-toggle" id="themeToggle" title="Переключить тему">☀️</button>
        </nav>



<section id="0" class="section">
            <h2 class="section-title"><a target="_blank"  href="https://www.nature.com/articles/s41467-026-68711-x" class="link-kmp1">Статья в Nature Communications (04-02-2026)</a></h2>
                    <div class="001">
                <h3 class="001-title">Neural and computational mechanisms underlying one-shot perceptual learning in humans</h3>
                       <div class="001-card">
                <p>Статья описывает нейронные и вычислительные механизмы one-shot perceptual learning — ситуации, когда один единственный опыт восприятия резко улучшает дальнейшее узнавание объекта. Это связывается с теми самыми «вспышками интуиции», когда размытое или двусмысленное изображение внезапно становится осмысленным и потом распознаётся уже почти автоматически.</p>
	<p>Авторы показывают, что при таком однократном обучении мозг обращается к уже имеющимся <strong>«приорам» — сохранённым зрительным шаблонам</strong> — и что эти приоры локализуются и активно используются в высокоуровневой зрительной коре (high-level visual cortex, HLVC). Для лингвистов это важно как пример быстрой перестройки (перцептивных) категорий: после одного «озарения» субъект как будто получает новый (перцептивный) «лексический элемент» для распознавания объекта.</p>
               

            <div class="001">
                <h3 class="001-title">Эксперимент с изображениями Mooney и роль приоров</h3>
                       <div class="001-card">
                <p>В работе использовались изображения типа Mooney — сильно обесцвеченные и размытые картинки животных и объектов, которые до «озарения» воспринимаются как хаотичные пятна, а после показа чёткой версии того же объекта начинают легко узнаватьcя даже в размытом виде. Участникам сначала предъявляли размытый вариант, потом чёткий, после чего их способность распознавать размытое изображение резко возрастала, что и фиксировалось как эффект однократного перцептивного обучения </p>
	<p>Авторы дополнительно варьировали размер, положение и ориентацию изображений, чтобы понять, насколько обобщённо кодируются приоры: изменение размера почти не влияло на эффект one-shot learning, тогда как поворот или сдвиг изображения частично снижали успешность узнавания . Это интерпретируется как свидетельство того, что приоры кодируют конкретные конфигурации признаков, а не абстрактные категориальные знания (например, не просто «собака вообще», а специфический паттерн контуров именно этой собаки).</p>
               
                    <ul>
                        <li>Размер: почти инвариантен относительно one-shot эффекта.</li>
                        <li>Позиция и ориентация: значимо влияют, уменьшая эффект обучения.</li>
                    </ul>
                   <div class="kmp12"><strong>Пояснение:</strong> Для лингвистики здесь важна аналогия с фонетическими или графическими шаблонами: мозг запоминает не только категорию, но и конкретный «шаблон сигнала» с определённым расположением элементов.</div>
                </div>
            </div>

            <div class="001">
                <h3 class="001-title">Нейронный уровень: HLVC, fMRI и iEEG</h3>
                       <div class="001-card">
                <p>Чтобы локализовать, где именно хранятся и активируются приоры, исследователи сочетали поведенческие данные с fMRI, классической ЭЭГ и интракраниальной iEEG. Анализ паттернов активности показал, что только известные схемы нейронного кодирования в высокоуровневой зрительной коре (HLVC) совпадают с теми свойствами приоров, которые были выявлены в поведенческом эксперименте (инвариантность к размеру и чувствительность к положению/ориентации).</p>
	<p>При использовании iEEG, когда электроды располагаются непосредственно на мозговой ткани у пациентов, проходящих нейрохирургическое лечение, HLVC демонстрировала наиболее ранние изменения силы нейронных сигналов в момент, когда происходило узнавание объекта с опорой на приор. Это позволяет рассматривать HLVC как ключевой узел, где «вес приора» накладывается на текущий сенсорный ввод, обеспечивая ту самую «интуитивную» вспышку узнавания.</p>
                                   <ul>
                        <li>fMRI: пространственная локализация совпадает с HLVC.</li>
                        <li>iEEG: ранние временные пики активности в HLVC при узнаваниях.</li>
                    </ul>
                   <div class="kmp12"><strong>Пояснение:</strong> В терминах обработки речи это можно сопоставить с быстрой активацией хранилища лексических приоров (словоформ, шаблонов фоносочетаний) при восприятии акустического сигнала.</div>
                </div>
            </div>

            <div class="001">
                <h3 class="001-title">One-shot learning, патология и «интуиция»</h3>
                       <div class="001-card">
                <p>Авторы напоминают, что в ряде неврологических и психических состояний (шизофрения и болезнь Паркинсона), механизмы однократного обучения и работы приоров могут быть нарушены: слишком сильные или неподходящие приоры «перекрывают» актуальный сенсорный вход, что может вести к галлюцинациям . На уровне теории это даёт «прямо тестируемую» модель того, как чрезмерно активные или неправильно калиброванные приоры вмешиваются в нормальное восприятие.</p>
	<p>Исследовательская группа также указывает, что те же механизмы, которые лежат в основе визуального one-shot узнавания, вероятно, участвуют в более абстрактных «ага-моментах» при понимании новых идей . Для когнитивной лингвистики это открывает перспективу рассматривать инсайт при усвоении новой грамматической конструкции или значения слова как частный случай применения приоров к новому языковому контексту .</p>
                                   <ul>
                        <li>Нарушение баланса приоров и сенсорного входа — возможный механизм галлюцинаций.</li>
                        <li>Инсайт в понимании идей и языковых структур может опираться на сходные принципы приор-управляемого распознавания.</li>
                    </ul>
                    <div class="kmp12"><strong>Пояснение:</strong> Для лингвистов здесь важна идея «перегруженных» приоров: аналогично можно представить гиперустойчивые стереотипы интерпретации высказываний, которые мешают адекватному пониманию новых языковых форм.</div>
                </div>
            </div>

            <div class="001">
                <h3 class="001-title">Вычислительная модель: vision transformer как аналог HLVC</h3>
                       <div class="001-card">
                <p>В завершение авторы строят вычислительную модель — vision transformer - архитектуру, которая обрабатывает изображение как набор «частей» и учится заполнять недостающую информацию на основе вероятностных зависимостей между ними. В модели реализовано явное разделение модулей: один модуль аккумулирует и хранит визуальные приоры (накопленную информацию об образцах), другой использует их для улучшенного распознавания новых входных изображений.</p>
	<p>После обучения на достаточно большом наборе изображений такая нейросеть демонстрировала способность к one-shot learning, сопоставимую с человеческой, и превосходила другие текущие AI-модели, в которых нет отдельного модуля приоров . Для авторов это аргумент в пользу того, что включение явного механизма работы с приорами в архитектуру ИИ приближает её к человеческим перцептивным стратегиям .</p>
            <ul>
                        <li>Выделенный модуль хранения приоров (аналог «зрительного лексикона»).</li>
                        <li>Модуль применения приоров к новому стимулу для однократного обучения.</li>
                    </ul>
                    <div class="kmp12"><strong>Пояснение:</strong> Для лингвистики это можно переформулировать как наличие отдельной подсистемы, которая хранит «прототипы» и паттерны, и подсистемы, которая динамически совмещает их с текущим входом — аналог сочетания перцептивного словаря и механизма онлайн-парсинга.</div>
                </div>
            </div>

            <div class="001">
                <h3 class="001-title">Аналогии между one-shot learning у человека и LLM</h3>
                       <div class="001-card">
                <p>Хотя механизмы работы мозга и LLM принципиально различны, авторы подчёркивают «конвергенцию» вычислительных идей: и в HLVC, и в современных архитектурах типа vision transformer важную роль играет использование накопленных приоров для быстрого распознавания новых объектов при минимуме примеров. В LLM это проявляется в так называемом in-context learning: модель, увидев всего один пример использования новой конструкции или обозначения в подсказке, уже может обобщать этот паттерн на последующие токены без дополнительного дообучения весов.</p>
	<p>На уровне аналогии можно сказать, что репрезентации, сформированные при предобучении LLM на больших корпусах, играют роль статистических приоров, а механизм внимания позволяет «подмешивать» эти приоры к новому входу так же, как HLVC подмешивает зрительные приоры к текущей сенсорной информации. При этом у человека one-shot learning, по-видимому, реально перестраивает состояние конкретных нейронных ансамблей, тогда как у LLM однократное обучение обычно реализуется за счёт временной конфигурации активаций в слоёной сети, а не устойчивой модификации параметров.</p>
                                  <ul>
                        <li>Использование накопленных приоров (опыта) для интерпретации нового стимула.</li>
                        <li>Способность обобщать из одного примера (Mooney-изображение / новый языковой паттерн в подсказке).</li>
                    </ul>
					
					<div class="table-kmp">		
<table class="table">
<thead><tr><th>Аспект</th><th>One-shot learning у человека (HLVC) / One-shot-like поведение у LLM</th></tr></thead>
 <tr><td>Источник приоров</td><td>Накопленные зрительные шаблоны, сформированные на основе многолетнего сенсорного опыта . / Статистические представления, выученные на больших корпусах текста и/или изображений.</td></tr>
 <tr><td>Тип эпизода one-shot</td><td>Однократный показ чёткого варианта изображения резко улучшает последующее узнавание его размытых вариантов . / Один пример в контексте подсказки задаёт новую инструкцию, формат, обозначение или структуру вывода.</td></tr>
 <tr><td>Механизм применения приора</td><td>HLVC модифицирует обработку текущего зрительного ввода, усиливая соответствие ранее сохранённым шаблонам . / Механизм внимания «сопоставляет» текущие токены с паттернами, закодированными в весах, подстраивая генерацию под контекст.</td></tr>
 <tr><td>Изменение параметров системы</td><td>Вероятна локальная пластичность: однократное обучение может менять синаптические связи в соответствующих сетях HLVC . / Как правило, веса модели не меняются; меняется только временная конфигурация активаций во время обработки конкретного запроса.</td></tr>
 <tr><td>Ограничения обобщения</td><td>Инвариантность к размеру, но чувствительность к позиции и ориентации изображения . / Обобщение обусловлено статистикой предобучения; модель может «переобобщать» или не уловить паттерн при слишком шумном или неоднозначном примере.</td></tr>
</table>
</div>
                    <div class="kmp12"><strong>Пояснение:</strong> Cходство здесь метафорическое и вычислительное: архитектура и биологическая природа систем принципиально различны, но идея «быстрого подключения приоров» из общего хранилища к конкретному эпизоду обучения оказывается полезной и в когнитивной нейронауке, и в проектировании LLM.</div>
                </div>
            </div>


</section>







<section id="1" class="section">
    <h2 class="section-title">One-shot learning: от мозга к LLM</h2>
    <div class="001">
        <h3 class="001-title">Общее определение One-shot learning</h3>
        <div class="001-card">
            <p>One-shot learning (обучение по одному примеру) — это способность системы (биологической или искусственной) извлечь из единственного предъявленного образца достаточно информации, чтобы успешно распознавать, классифицировать или воспроизводить аналогичные объекты и паттерны в дальнейшем.</p>
            <p>В статье Laamerad et al. (2026) в Nature Communications описан именно такой феномен в зрительном восприятии: человек видит размытое, двусмысленное изображение, не может его интерпретировать, затем ему показывают оригинал (чёткую версию того же объекта) — и после этого единственного «подсказочного» предъявления человек уже мгновенно распознаёт ранее непонятное изображение. Этот перцептивный сдвиг необратим: однажды «увидев» далматинца в пятнах, вы больше не можете «развидеть» его.</p>
            <p><strong>Ключевой механизм у человека:</strong></p>
            <ul>
                <li>Мозг использует накопленные <em>приоры</em> (priors) — сохранённые зрительные шаблоны, хранящиеся в высокоуровневой зрительной коре (HLVC).</li>
                <li>Единственное предъявление оригинала «активирует» нужный приор и связывает его с новым входным сигналом.</li>
                <li>После этого приор начинает автоматически «достраивать» неполную сенсорную информацию при каждом последующем предъявлении.</li>
            </ul>
            <div class="kmp12"><strong>Пояснение:</strong> Для лингвистов полезна прямая аналогия: когда студент впервые слышит незнакомую грамматическую конструкцию и не может её интерпретировать, а затем преподаватель один раз объясняет её структуру, студент «вдруг» начинает слышать и понимать эту конструкцию в потоке речи. Один пример создаёт новую перцептивную категорию.</div>
        </div>
    </div>
    <div class="001">
        <h3 class="001-title">One-shot learning в машинном обучении: общая рамка</h3>
        <div class="001-card">
            <p>В машинном обучении термин one-shot learning исторически обозначает задачу, в которой модель должна научиться распознавать новый класс объектов, получив лишь один обучающий пример этого класса. Классическая работа — статья Fei-Fei Li et al. (2006) «One-Shot Learning of Object Categories», где байесовская модель использовала накопленные знания о других категориях (приоры!), чтобы обобщать по одному примеру.</p>
            <p>В контексте больших языковых моделей (LLM) one-shot learning приобретает особый смысл. Здесь важно различать два принципиально разных режима:</p>
            <p><strong>Два режима one-shot learning у LLM:</strong></p>
            <ul>
                <li><strong>One-shot fine-tuning</strong> — модель дообучается (изменяются веса нейронной сети) на одном примере. Это редкий и обычно неэффективный подход, чреватый переобучением.</li>
                <li><strong>One-shot in-context learning (ICL)</strong> — модель получает один пример прямо в тексте запроса (prompt) и использует его для выполнения задачи <em>без какого-либо изменения своих весов</em>. Именно этот режим стал революционным открытием эпохи GPT-3 и последующих моделей.</li>
            </ul>
            <div class="kmp12"><strong>Пояснение:</strong> Когда в лингвистическом контексте говорят о «one-shot learning у LLM», почти всегда имеют в виду именно второй режим — in-context learning. Модель не «запоминает» пример навсегда; она временно использует его как ориентир внутри текущего контекстного окна.</div>
        </div>
    </div>
</section>

<section id="2" class="section">
    <h2 class="section-title">One-shot prompting: механика и место в спектре стратегий</h2>
    <div class="001">
        <h3 class="001-title">Спектр промптинга: zero-shot → one-shot → few-shot</h3>
        <div class="001-card">
            <p>Промптинг (prompting) — это способ взаимодействия с LLM, при котором пользователь формулирует задачу и, возможно, предоставляет примеры желаемого поведения прямо в тексте запроса. В зависимости от количества примеров различают три основных стратегии:</p>
            <p><strong>Zero-shot prompting</strong> — модель получает только инструкцию, без каких-либо примеров. Модель опирается исключительно на знания, усвоенные при предобучении.</p>
            <p><strong>One-shot prompting</strong> — модель получает ровно один пример пары «вход → выход» вместе с инструкцией, а затем новый вход, для которого нужно сгенерировать выход.</p>
            <p><strong>Few-shot prompting</strong> — модель получает несколько (обычно 2–10) примеров перед новым входом.</p>
        </div>
    </div>
    <div class="table-kmp">
        <table class="table">
            <thead>
                <tr>
                    <th>Стратегия</th>
                    <th>Количество примеров в prompt</th>
                    <th>Изменяются ли веса модели</th>
                    <th>На что опирается модель</th>
                    <th>Аналогия с восприятием человека (по статье Laamerad et al.)</th>
                </tr>
            </thead>
            <tr>
                <td><strong>Zero-shot</strong></td>
                <td>0</td>
                <td>Нет</td>
                <td>Только на приоры, накопленные при предобучении</td>
                <td>Попытка распознать размытое изображение без подсказки — только за счёт имеющихся зрительных шаблонов</td>
            </tr>
            <tr>
                <td><strong>One-shot</strong></td>
                <td>1</td>
                <td>Нет</td>
                <td>На приоры + один пример в контексте</td>
                <td>Однократное предъявление оригинала — «вспышка интуиции», активация нужного приора</td>
            </tr>
            <tr>
                <td><strong>Few-shot</strong></td>
                <td>2–10+</td>
                <td>Нет</td>
                <td>На приоры + несколько примеров в контексте</td>
                <td>Многократное предъявление вариаций — укрепление и уточнение активированного приора</td>
            </tr>
            <tr>
                <td><strong>Fine-tuning</strong></td>
                <td>Много (обучающий набор)</td>
                <td><strong>Да</strong></td>
                <td>Перестроенные веса (новые приоры)</td>
                <td>Долгосрочная перцептивная реорганизация — создание новых нейронных ансамблей</td>
            </tr>
        </table>
    </div>
    <div class="kmp14"><strong>Пояснение:</strong> Обратите внимание, что граница между one-shot и few-shot — количественная, а граница между in-context learning (все три первые строки) и fine-tuning — качественная: в первом случае «обучение» происходит внутри одного сеанса и не сохраняется, во втором — изменяется сама модель.</div>

    <div class="001">
        <h3 class="001-title">Анатомия one-shot prompt: структура и компоненты</h3>
        <div class="001-card">
            <p>One-shot prompt состоит из трёх обязательных компонентов и одного факультативного:</p>
            <ul>
                <li><strong>Инструкция (instruction)</strong> — описание задачи, которую модель должна выполнить.</li>
                <li><strong>Один пример (demonstration)</strong> — конкретная пара «вход → желаемый выход», которая иллюстрирует ожидаемое поведение.</li>
                <li><strong>Новый вход (query)</strong> — данные, к которым модель должна применить усвоенный паттерн.</li>
                <li><em>Факультативно: ограничения формата</em> — указания на длину, стиль, язык ответа и т.д.</li>
            </ul>
        </div>
    </div>
    <div class="001">
        <h3 class="001-title">Примеры one-shot prompting для лингвистических задач</h3>
        <div class="001-card">
            <p><strong>Пример 1. Морфологический разбор (глоссирование):</strong></p>
            <p><em>Инструкция:</em> «Выполни поморфемный разбор слова с лейпцигскими глоссами.»</p>
            <p><em>Пример:</em><br>
            Вход: <code>перечитывала</code><br>
            Выход: <code>пере-чит-ыва-л-а → RE-read-IPFV-PST-F.SG</code></p>
            <p><em>Запрос:</em><br>
            Вход: <code>переписывали</code></p>
            <p>Модель, получив один пример, «понимает» формат глоссирования, принцип членения, систему сокращений и применяет этот паттерн к новому слову.</p>
        </div>
        <div class="001-card">
            <p><strong>Пример 2. Определение коммуникативной стратегии:</strong></p>
            <p><em>Инструкция:</em> «Определи доминирующую речевую стратегию говорящего.»</p>
            <p><em>Пример:</em><br>
            Вход: «Ну, я не эксперт, конечно, но мне кажется, что, возможно, стоило бы рассмотреть и другие варианты…»<br>
            Выход: «Хеджирование (hedging) — снижение категоричности высказывания через маркеры эпистемической неуверенности и модальные конструкции.»</p>
            <p><em>Запрос:</em><br>
            Вход: «Послушайте, каждый нормальный человек понимает, что это единственно правильный подход.»</p>
        </div>
        <div class="001-card">
            <p><strong>Пример 3. Перевод с сохранением регистра:</strong></p>
            <p><em>Инструкция:</em> «Переведи фразу с английского на русский, сохраняя стилистический регистр оригинала.»</p>
            <p><em>Пример:</em><br>
            Вход: <code>The aforementioned provisions notwithstanding, the party shall retain the right to…</code><br>
            Выход: <code>Невзирая на вышеизложенные положения, сторона сохраняет за собой право…</code></p>
            <p><em>Запрос:</em><br>
            Вход: <code>Pursuant to the stipulations set forth herein, the licensee is hereby authorized to…</code></p>
            <div class="kmp12"><strong>Пояснение:</strong> Один пример задаёт модели не просто задачу перевода (это она «знает» из предобучения), а конкретный стилистический «приор» — канцелярский регистр с характерными клише русского юридического языка. Без примера (zero-shot) модель могла бы перевести нейтрально или даже разговорно.</div>
        </div>
    </div>
</section>

<section id="3" class="section">
    <h2 class="section-title">In-context learning: механизм «обучения без обучения»</h2>
    <div class="001">
        <h3 class="001-title">Что происходит внутри модели при one-shot prompting</h3>
        <div class="001-card">
            <p>In-context learning (ICL) — это способность LLM выполнять новые задачи на основе примеров, предоставленных непосредственно в промпте, без обновления параметров (весов) модели. Этот феномен был систематически описан в работе Brown et al. (2020) при представлении GPT-3.</p>
            <p>Когда модель обрабатывает one-shot prompt, происходит следующее:</p>
            <ul>
                <li><strong>Токенизация:</strong> весь prompt (инструкция + пример + запрос) разбивается на токены и представляется как единая последовательность.</li>
                <li><strong>Прямой проход (forward pass):</strong> последовательность проходит через все слои трансформера. Механизм внимания (attention) позволяет каждому токену «обращаться» ко всем предшествующим токенам.</li>
                <li><strong>Формирование контекстного представления:</strong> благодаря вниманию токены запроса получают доступ к информации из примера. Модель «замечает» структурные соответствия между входом и выходом в примере.</li>
                <li><strong>Генерация:</strong> модель порождает следующие токены, опираясь на выявленный паттерн и свои предобученные знания (приоры).</li>
            </ul>
            <div class="kmp12"><strong>Пояснение:</strong> Критически важно: при ICL ни один вес модели не изменяется. «Обучение» происходит исключительно за счёт того, что механизм внимания динамически перенастраивает поток информации в сети. Это аналогично тому, как в модели Laamerad et al. (2026) зрительные приоры не создаются заново при one-shot learning — они уже существуют, а единственный пример лишь «маршрутизирует» сенсорный вход к нужному приору.</div>
        </div>
    </div>
    <div class="001">
        <h3 class="001-title">Роль приоров предобучения в in-context learning</h3>
        <div class="001-card">
            <p>Почему один пример вообще может быть достаточен? Ответ — в приорах. При предобучении на огромных текстовых корпусах LLM формирует статистические закономерности, которые функционально эквивалентны приорам в байесовском смысле:</p>
            <p><strong>Типы приоров, усвоенных LLM при предобучении:</strong></p>
            <ul>
                <li><strong>Лингвистические приоры:</strong> грамматические правила, морфологические парадигмы, синтаксические конструкции, валентности глаголов, коллокации.</li>
                <li><strong>Дискурсивные приоры:</strong> типичные жанровые структуры (научная статья, деловое письмо, диалог), паттерны аргументации, конвенции цитирования.</li>
                <li><strong>Задачные приоры (task priors):</strong> структуры «вход → выход» для типичных NLP-задач (перевод, суммаризация, классификация, вопрос-ответ) — модель при предобучении видела миллионы пар такого рода.</li>
                <li><strong>Форматные приоры:</strong> понимание маркдауна, таблиц, нумерованных списков, JSON, XML и других форматов представления информации.</li>
            </ul>
            <p>One-shot пример в промпте выполняет функцию «ключа», который активирует релевантную комбинацию этих приоров. Один пример морфологического разбора активирует лингвистические приоры (знание морфологии), задачный приор (формат «слово → разбор»), и форматный приор (конвенции глоссирования).</p>
        </div>
    </div>
    <div class="kmp12"><strong>Важно:</strong> In-context learning работает именно потому, что модель уже «знает» огромное количество паттернов из предобучения. Один пример не «обучает» модель с нуля — он указывает модели, какой из множества уже известных ей паттернов следует применить. Это прямо параллельно выводу Laamerad et al.: one-shot perceptual learning возможно потому, что зрительные приоры уже сформированы в HLVC; один показ оригинала лишь «маршрутизирует» входной сигнал к правильному приору.</div>
</section>

<section id="4" class="section">
    <h2 class="section-title">Аналогия: one-shot learning у человека и у LLM</h2>
    <div class="001">
        <h3 class="001-title">Параллели в архитектуре</h3>
        <div class="001-card">
            <p>Авторы статьи в Nature Communications построили вычислительную модель на основе vision transformer, в которой явно выделены два модуля: модуль хранения приоров и модуль распознавания, использующий эти приоры. Эта архитектура обнаруживает структурное сходство с тем, как функционирует LLM при обработке промпта:</p>
        </div>
    </div>
    <div class="table-kmp">
        <table class="table">
            <thead>
                <tr>
                    <th>Компонент</th>
                    <th>Человеческий мозг (Laamerad et al., 2026)</th>
                    <th>Vision Transformer (модель авторов)</th>
                    <th>LLM при one-shot prompting</th>
                </tr>
            </thead>
            <tr>
                <td><strong>Хранилище приоров</strong></td>
                <td>Высокоуровневая зрительная кора (HLVC) — нейронные ансамбли, кодирующие объектные представления</td>
                <td>Отдельный модуль, аккумулирующий визуальные приоры из обучающей выборки</td>
                <td>Веса модели — параметры, фиксирующие статистические закономерности из обучающего корпуса</td>
            </tr>
            <tr>
                <td><strong>Текущий вход</strong></td>
                <td>Сенсорный сигнал от сетчатки (размытое, зашумлённое изображение)</td>
                <td>Новое изображение, разбитое на патчи (фрагменты)</td>
                <td>Текст промпта — последовательность токенов, включающая пример и запрос</td>
            </tr>
            <tr>
                <td><strong>Механизм «подмешивания» приоров</strong></td>
                <td>Нисходящие (top-down) сигналы от HLVC к нижним зрительным областям</td>
                <td>Механизм кросс-внимания между модулем приоров и модулем распознавания</td>
                <td>Механизм самовнимания (self-attention), связывающий токены запроса с токенами примера и с внутренними репрезентациями</td>
            </tr>
            <tr>
                <td><strong>«Ага-момент»</strong></td>
                <td>Внезапная перцептивная реорганизация — размытые пятна превращаются в узнаваемый объект</td>
                <td>Резкое повышение точности распознавания после одного предъявления оригинала</td>
                <td>Модель «подхватывает» паттерн из единственного примера и корректно генерирует ответ на новый вход</td>
            </tr>
            <tr>
                <td><strong>Устойчивость эффекта</strong></td>
                <td><strong>Высокая:</strong> эффект сохраняется надолго, возможно перестраиваются нейронные ансамбли</td>
                <td>Зависит от архитектуры модели и реализации</td>
                <td><strong>Низкая:</strong> эффект ограничен контекстным окном текущей сессии; при новом запросе «обучение» утрачивается</td>
            </tr>
        </table>
    </div>
    <div class="001">
        <h3 class="001-title">Параллели в процессе</h3>
        <div class="001-card">
            <p>Рассмотрим пошагово, как разворачивается one-shot learning в каждой из трёх систем на примере задачи распознавания/интерпретации:</p>
            <p><strong>Шаг 1. Предъявление неоднозначного стимула:</strong></p>
            <ul>
                <li><em>Человек:</em> видит размытое изображение далматинца — набор чёрно-белых пятен, не складывающихся в осмысленную фигуру.</li>
                <li><em>LLM (лингвистический аналог):</em> получает незнакомую аббревиатуру или окказионализм в тексте — не может определить значение из контекста.</li>
            </ul>
            <p><strong>Шаг 2. Предъявление одного примера (ключа):</strong></p>
            <ul>
                <li><em>Человек:</em> видит чёткую фотографию далматинца — приор «далматинец» активируется в HLVC.</li>
                <li><em>LLM:</em> получает в промпте один пример использования аббревиатуры с расшифровкой — нужный «задачный приор» активируется через механизм внимания.</li>
            </ul>
            <p><strong>Шаг 3. Повторное предъявление неоднозначного стимула:</strong></p>
            <ul>
                <li><em>Человек:</em> снова видит размытое изображение — теперь далматинец «выпрыгивает» из пятен мгновенно.</li>
                <li><em>LLM:</em> встречает ту же аббревиатуру в новом контексте далее в промпте — корректно интерпретирует её.</li>
            </ul>
        </div>
    </div>
    <div class="001">
        <h3 class="001-title">Аналогия «перцептивный словарь — языковая модель»</h3>
        <div class="001-card">
            <p>Авторы статьи отмечают, что после one-shot perceptual learning субъект как будто получает новый «перцептивный лексический элемент» для распознавания объекта. Эта метафора продуктивна для лингвистов:</p>
        </div>
    </div>
    <div class="table-kmp">
        <table class="table">
            <thead>
                <tr>
                    <th>Аспект</th>
                    <th>Перцептивный словарь (зрительная система)</th>
                    <th>Ментальный лексикон (человек-лингвист)</th>
                    <th>«Контекстный лексикон» LLM при one-shot ICL</th>
                </tr>
            </thead>
            <tr>
                <td><strong>Единица</strong></td>
                <td>Перцептивный шаблон объекта (далматинец, лицо, буква)</td>
                <td>Лексема с фонологической формой, значением, грамматическими свойствами</td>
                <td>Распределённое представление (embedding), активируемое в контексте</td>
            </tr>
            <tr>
                <td><strong>Способ пополнения</strong></td>
                <td>One-shot: одно предъявление оригинала создаёт или активирует шаблон</td>
                <td>Новое слово может быть усвоено за 1–3 предъявления в контексте (fast mapping)</td>
                <td>Один пример в промпте временно «создаёт» новую ассоциацию в контекстном окне</td>
            </tr>
            <tr>
                <td><strong>Долговечность</strong></td>
                <td>Долгосрочная — нейронная перестройка</td>
                <td>Варьируется — от мгновенного забывания до долгосрочного запоминания</td>
                <td>Эфемерная — только в пределах текущей сессии</td>
            </tr>
        </table>
    </div>
    <div class="kmp14"><strong>Пояснение:</strong> Феномен fast mapping в психолингвистике (Carey &amp; Bartlett, 1978) — способность детей усваивать новое слово после одного-двух предъявлений — является лингвистическим аналогом one-shot perceptual learning. В обоих случаях система (мозг ребёнка, зрительная кора взрослого) использует накопленные приоры (знание о категориальной структуре лексикона, знание о типичных зрительных объектах), чтобы мгновенно «встроить» новый элемент в существующую систему.</div>
</section>

<section id="5" class="section">
    <h2 class="section-title">Приоры в языке: от зрительных шаблонов к лингвистическим ожиданиям</h2>
    <div class="001">
        <h3 class="001-title">5.1. Что такое лингвистические приоры</h3>
        <div class="001-card">
            <p>Если в зрительном восприятии приоры — это усвоенные статистические закономерности о том, как обычно выглядят объекты (контуры, текстуры, формы), то в языке приоры — это усвоенные закономерности о том, как обычно устроены высказывания. Рассмотрим уровни лингвистических приоров у человека и их аналоги в LLM:</p>
            <p><strong>Фонологические / графемные приоры:</strong></p>
            <ul>
                <li><em>Человек:</em> ожидания относительно допустимых сочетаний фонем в данном языке (например, /str-/ возможно в начале английского слова, /ŋr-/ — нет).</li>
                <li><em>LLM:</em> статистические закономерности на уровне подсловных токенов (byte-pair encoding выучивает частотные символьные последовательности).</li>
            </ul>
            <p><strong>Морфологические приоры:</strong></p>
            <ul>
                <li><em>Человек:</em> знание продуктивных словообразовательных моделей (приставка <em>пере-</em> + глагол → значение повторного действия).</li>
                <li><em>LLM:</em> распределённые представления, кодирующие регулярные морфологические паттерны.</li>
            </ul>
            <p><strong>Синтаксические приоры:</strong></p>
            <ul>
                <li><em>Человек:</em> ожидания о порядке слов, управлении, согласовании (услышав <em>Студент, который...</em>, мы ждём сказуемое придаточного).</li>
                <li><em>LLM:</em> выученные вероятности продолжения последовательности, учитывающие синтаксическую структуру.</li>
            </ul>
            <p><strong>Семантические/прагматические приоры:</strong></p>
            <ul>
                <li><em>Человек:</em> знание о типичных сценариях, фреймах, пресуппозициях (услышав <em>ресторан</em>, мы активируем фрейм с ролями «официант», «меню», «счёт»).</li>
                <li><em>LLM:</em> коммутативные паттерны (какие слова обычно встречаются в каком контексте), кодируемые в весах.</li>
            </ul>
        </div>
    </div>
    <div class="001">
        <h3 class="001-title">«Перегруженные» приоры: когда ожидания мешают</h3>
        <div class="001-card">
            <p>Авторы статьи указывают, что нарушение баланса между приорами и сенсорным входом может приводить к галлюцинациям: если приоры чрезмерно сильны, мозг «видит» то, чего нет. Эта идея имеет прямые параллели и в лингвистике, и в поведении LLM:</p>
        </div>
    </div>
    <div class="table-kmp">
        <table class="table">
            <thead>
                <tr>
                    <th>Явление</th>
                    <th>Зрительное восприятие</th>
                    <th>Человеческое языковое восприятие</th>
                    <th>Поведение LLM</th>
                </tr>
            </thead>
            <tr>
                <td><strong>Норма: баланс приоров и входа</strong></td>
                <td>Приор «далматинец» помогает распознать собаку в пятнах</td>
                <td>Знание грамматики помогает интерпретировать зашумлённую речь</td>
                <td>Предобученные знания + пример в промпте → корректный ответ</td>
            </tr>
            <tr>
                <td><strong>Перегруженные приоры</strong></td>
                <td>Парейдолия — человек «видит» лицо в розетке или облаке</td>
                <td>Ложные друзья переводчика: студент «слышит» знакомое слово родного языка в иностранном и неверно интерпретирует</td>
                <td>Галлюцинации LLM: модель «достраивает» правдоподобный, но фактически ложный ответ на основе статистических приоров</td>
            </tr>
            <tr>
                <td><strong>Слабые приоры</strong></td>
                <td>Невозможность распознать объект в зашумлённом изображении</td>
                <td>Невозможность понять речь на незнакомом языке, несмотря на сохранный слух</td>
                <td>Модель, предобученная на малом корпусе, не может выполнить задачу даже с примерами</td>
            </tr>
        </table>
    </div>
    <div class="kmp12"><strong>Важно:</strong> Для будущих преподавателей иностранных языков идея «перегруженных приоров» практически значима. Когда студент упорно интерпретирует иноязычную конструкцию через призму родного языка (интерференция), это можно рассматривать как ситуацию, в которой слишком сильный приор L1 подавляет сенсорный вход L2. Преподавательская задача — помочь сформировать новый приор (перцептивную категорию L2), а не просто «подавить» старый.</div>
    <div class="001">
        <h3 class="001-title">Инсайт при усвоении языковых конструкций как one-shot learning</h3>
        <div class="001-card">
            <p>Авторы Nature Communications указывают, что механизмы визуального one-shot learning, вероятно, участвуют в более абстрактных «ага-моментах». Для лингвистов это наиболее интересный тезис. Рассмотрим примеры:</p>
            <p><strong>Пример 1. Усвоение эргативной конструкции:</strong></p>
            <p>Студент, привыкший к номинативно-аккузативной системе, долго не может «увидеть» логику эргативного маркирования. Затем преподаватель даёт один точный пример с минимальной парой — и студент переживает «ага-момент»: вся система «встаёт на место». Далее студент начинает правильно интерпретировать эргативные конструкции, которые раньше казались ему хаотичными.</p>
            <p><strong>Пример 2. «Щёлк» при понимании конструкции «чем…, тем…»:</strong></p>
            <p>Студент, изучающий русский как иностранный, многократно встречает конструкции типа «Чем быстрее, тем лучше», но не может вычленить паттерн. Затем один удачно подобранный пример с разбором («Чем [сравнит. степень], тем [сравнит. степень]» = 'The more X, the more Y') создаёт инсайт, после которого все подобные конструкции распознаются мгновенно.</p>
            <div class="kmp12"><strong>Пояснение:</strong> В обоих случаях мы видим ту же логику, что и в зрительном one-shot learning: (а) входной сигнал (иноязычная конструкция) не интерпретируется, потому что у студента нет подходящего приора; (б) один удачный пример активирует или создаёт нужный приор; (в) после этого все аналогичные конструкции распознаются «автоматически».</div>
        </div>
    </div>
</section>

<section id="6" class="section">
    <h2 class="section-title">Вычислительная модель: vision transformer и его аналоги в NLP</h2>
    <div class="001">
        <h3 class="001-title">Архитектура модели из статьи и её связь с LLM</h3>
        <div class="001-card">
            <p>Авторы Laamerad et al. (2026) построили модель на основе vision transformer (ViT). В основе ViT и языковых трансформеров лежит одна и та же архитектура — трансформер (Vaswani et al., 2017, «Attention Is All You Need»). Это не случайное совпадение: именно общность архитектуры делает аналогию между зрительным и языковым one-shot learning не просто метафорой, а технически обоснованным сопоставлением.</p>
            <p><strong>Ключевое нововведение авторов статьи:</strong></p>
            <ul>
                <li>В стандартном трансформере приоры «растворены» в весах — нет отдельного модуля, который бы их хранил и предъявлял.</li>
                <li>Авторы добавили явный модуль приоров (prior module), который аккумулирует информацию о типичных объектах и предоставляет её модулю распознавания.</li>
                <li>Такая архитектура с разделением «хранилища знаний» и «механизма применения знаний» превзошла стандартные модели в задачах one-shot learning.</li>
            </ul>
            <p><strong>Аналоги в NLP-архитектурах:</strong></p>
            <ul>
                <li><strong>Retrieval-Augmented Generation (RAG):</strong> LLM получает доступ к внешней базе знаний, из которой «извлекает» релевантные фрагменты перед генерацией. Это прямой аналог отдельного модуля приоров.</li>
                <li><strong>Memory-augmented transformers:</strong> архитектуры с внешней памятью (Memorizing Transformer, RETRO и др.), в которых модель обращается к хранилищу обработанных ранее фрагментов.</li>
                <li><strong>Системный промпт (system prompt):</strong> в прикладном плане системный промпт можно рассматривать как «вручную заданный модуль приоров» — он задаёт контекст, роль и ограничения, которые модулируют всю последующую обработку.</li>
            </ul>
        </div>
    </div>
    <div class="kmp14"><strong>Пояснение:</strong> Для лингвистов аналогия между модулем приоров и RAG-системой особенно наглядна. Представьте переводчика-человека, который, встречая незнакомый термин, обращается к специализированному словарю (внешний модуль приоров) и затем интегрирует найденное значение в свой перевод (механизм распознавания). RAG делает то же самое: LLM «обращается» к базе данных, извлекает релевантный фрагмент и использует его при генерации.</div>
    <div class="001">
        <h3 class="001-title">Конвергенция биологических и искусственных систем</h3>
        <div class="001-card">
            <p>Авторы статьи подчёркивают «конвергенцию» вычислительных принципов: и в HLVC, и в vision transformer ключевую роль играет использование накопленных приоров для быстрого распознавания при минимуме данных. Обобщая эту идею для лингвистического контекста, можно выделить общие принципы:</p>
            <p><strong>Принцип 1. Приор-управляемое распознавание (prior-guided recognition):</strong></p>
            <ul>
                <li>Любая система (мозг, ViT, LLM), обученная на достаточно большом и разнообразном опыте, формирует внутренние модели закономерностей.</li>
                <li>Эти модели используются для «достройки» неполного входа — будь то размытое изображение, зашумлённая речь или неоднозначное предложение.</li>
            </ul>
            <p><strong>Принцип 2. Композиционность приоров:</strong></p>
            <ul>
                <li>Сложные объекты распознаются как комбинации более простых усвоенных элементов.</li>
                <li>В ViT: объект — композиция патчей. В LLM: предложение — композиция токенов, связанных синтаксическими и семантическими отношениями. В мозге: зрительная сцена — иерархическая композиция от краёв и текстур до объектов и сцен.</li>
            </ul>
            <p><strong>Принцип 3. Минимальная достаточность ключа:</strong></p>
            <ul>
                <li>Если приоры достаточно богаты и хорошо организованы, для их активации достаточно минимального «ключа» — одного примера.</li>
                <li>Это и объясняет, почему one-shot learning возможен: один пример не содержит достаточно информации для обучения с нуля, но содержит достаточно для выбора между уже имеющимися приорами.</li>
            </ul>
        </div>
    </div>
</section>

<section id="7" class="section">
    <h2 class="section-title">Принципиальные различия: где аналогия заканчивается</h2>
    <div class="001">
        <h3 class="001-title">Таблица ключевых различий</h3>
        <div class="001-card">
            <p>При всей продуктивности аналогии между one-shot learning у человека и у LLM необходимо чётко осознавать границы этого сопоставления. Нижеследующая таблица суммирует принципиальные различия:</p>
        </div>
    </div>
    <div class="table-kmp">
        <table class="table">
            <thead>
                <tr>
                    <th>Параметр</th>
                    <th>Человек (one-shot perceptual learning)</th>
                    <th>LLM (one-shot in-context learning)</th>
                </tr>
            </thead>
            <tr>
                <td><strong>Сохранение результата</strong></td>
                <td>Долгосрочное — эффект сохраняется дни, недели, возможно пожизненно. Происходит реальная перестройка нейронных ансамблей</td>
                <td>Эфемерное — ограничено текущим контекстным окном (обычно тысячи–сотни тысяч токенов). При начале нового диалога «обучение» утрачивается полностью</td>
            </tr>
            <tr>
                <td><strong>Механизм закрепления</strong></td>
                <td>Синаптическая пластичность — реальное изменение силы связей между нейронами</td>
                <td>Временная конфигурация активаций в слоях трансформера — никакие параметры не модифицируются</td>
            </tr>
            <tr>
                <td><strong>Субъективное переживание</strong></td>
                <td>Яркий «ага-момент», часто сопровождаемый эмоциональной реакцией, ощущением внезапного понимания</td>
                <td>Отсутствует. У LLM нет субъективного опыта, сознания или эмоций. «Обучение» — чисто вычислительный процесс</td>
            </tr>
            <tr>
                <td><strong>Активная проверка гипотез</strong></td>
                <td>Человек может сознательно «примерять» разные интерпретации, задавать вопросы, искать подтверждения</td>
                <td>LLM пассивно обрабатывает вход слева направо (авторегрессия); не ставит гипотез и не ищет подтверждений в отсутствие специальных техник промптинга (chain-of-thought и т.д.)</td>
            </tr>
            <tr>
                <td><strong>Мультимодальность</strong></td>
                <td>Восприятие изначально мультимодально — зрительный инсайт может подкрепляться слуховой, тактильной, моторной информацией</td>
                <td>Стандартная LLM работает только с текстом (мультимодальные модели — исключение, и у них мультимодальность реализована иначе, чем у человека)</td>
            </tr>
            <tr>
                <td><strong>Телесность (embodiment)</strong></td>
                <td>Обучение включено в телесный опыт: перцептивные категории связаны с действиями, эмоциями, пространственной ориентацией</td>
                <td>LLM не имеет тела, не взаимодействует с физическим миром; её «знания» — статистические паттерны в текстах</td>
            </tr>
            <tr>
                <td><strong>Интенциональность</strong></td>
                <td>Человек учится, потому что ему нужно распознать объект, решить задачу, понять собеседника — обучение мотивировано</td>
                <td>LLM не имеет целей, потребностей и мотивации. Она минимизирует функцию потерь при обучении и генерирует наиболее вероятные продолжения при инференсе</td>
            </tr>
        </table>
    </div>
    <div class="kmp11"><strong>Примечание:</strong> Эти различия не обесценивают аналогию — они делают её более точной. Продуктивная аналогия должна указывать не только на сходства, но и на границы переноса. Как отмечают сами авторы статьи в Nature Communications, «конвергенция» вычислительных принципов между биологическими и искусственными системами не означает их тождественности.</div>
</section>

<section id="8" class="section">
    <h2 class="section-title">One-shot prompting для лингвистических задач</h2>
    <div class="001">
        <h3 class="001-title">Базовые принципы составления one-shot промптов</h3>
        <div class="001-card">
            <p>При составлении one-shot промптов для лингвистических задач следует помнить, что единственный пример должен быть максимально информативным — он должен одновременно задавать формат, демонстрировать уровень детализации и показывать тип рассуждения. Несколько практических принципов:</p>
            <p><strong>Принцип репрезентативности:</strong></p>
            <ul>
                <li>Пример должен быть достаточно типичным, чтобы модель могла обобщить паттерн, но достаточно содержательным, чтобы показать нетривиальные аспекты задачи.</li>
                <li><em>Плохой пример для задачи морфологического разбора:</em> слово «дом» (слишком простое, нет аффиксов).</li>
                <li><em>Хороший пример:</em> слово «перечитывала» (показывает префикс, корень, суффиксы, флексию).</li>
            </ul>
            <p><strong>Принцип форматной однозначности:</strong></p>
            <ul>
                <li>Формат ответа в примере должен быть настолько чётким, чтобы у модели не возникало неопределённости.</li>
                <li>Используйте разделители, метки, единообразные обозначения.</li>
            </ul>
            <p><strong>Принцип активации релевантного приора:</strong></p>
            <ul>
                <li>Пример должен «ключевать» именно тот тип лингвистического анализа, который вам нужен.</li>
                <li>Если вам нужен генеративный анализ — покажите пример с деревьями и трансформациями. Если функциональный — покажите пример с коммуникативными ролями.</li>
            </ul>
        </div>
    </div>
    <div class="001">
        <h3 class="001-title">Сравнение zero-shot и one-shot для лингвистических задач</h3>
        <div class="001-card">
            <p>Рассмотрим, как наличие или отсутствие примера влияет на качество выполнения лингвистической задачи моделью:</p>
            <p><strong>Задача: определить тип речевого акта по классификации Сёрля.</strong></p>
            <p><em>Zero-shot prompt:</em></p>
            <p>«Определи тип речевого акта по классификации Сёрля для высказывания: 'Не могли бы вы закрыть окно?'»</p>
            <p><em>Типичный ответ модели:</em> «Это вопрос» или «Это директивный речевой акт в форме вопроса». Ответ может быть правильным, но уровень детализации непредсказуем.</p>
            <p><em>One-shot prompt:</em></p>
            <p>«Определи тип речевого акта по классификации Сёрля. Формат ответа — по образцу.<br>
            Пример:<br>
            Высказывание: 'Обещаю вернуть книгу завтра.'<br>
            Локутивный акт: произнесение предложения с пропозицией «говорящий вернёт книгу завтра».<br>
            Иллокутивный акт: комиссив (обязательство говорящего совершить будущее действие).<br>
            Перлокутивный эффект: адресат формирует ожидание, что книга будет возвращена.<br>
            Косвенный речевой акт: нет.<br><br>
            Высказывание: 'Не могли бы вы закрыть окно?'»</p>
            <p><em>Ответ модели будет следовать заданной структуре</em>, включая все четыре компонента анализа. Один пример задал модели и терминологию, и формат, и глубину анализа.</p>
            <div class="kmp12"><strong>Пояснение:</strong> Это прямая демонстрация того, как one-shot пример активирует нужный набор приоров. Модель «знает» теорию речевых актов из предобучения (приор), но без примера не знает, в каком формате и с какой детализацией представить анализ. Один пример «маршрутизирует» модель к нужной конфигурации.</div>
        </div>
    </div>
    <div class="001">
        <h3 class="001-title">Когда one-shot недостаточно: переход к few-shot</h3>
        <div class="001-card">
            <p>One-shot prompting эффективен, когда задача относительно близка к тому, что модель «видела» при предобучении (т.е. приоры уже сформированы). Однако в ряде случаев одного примера недостаточно:</p>
            <p><strong>Ситуации, требующие few-shot:</strong></p>
            <ul>
                <li><strong>Нестандартная нотация:</strong> если вы используете собственную систему транскрипции или аннотации, одного примера может не хватить для демонстрации всех конвенций.</li>
                <li><strong>Контринтуитивные решения:</strong> если правильный ответ противоречит статистическому приору модели (например, нестандартная классификация или нетипичный анализ), нужно несколько примеров, чтобы «перебить» приор.</li>
                <li><strong>Многообразие паттернов:</strong> если задача предполагает разные типы ответов в зависимости от подтипа входа, один пример покажет только один подтип.</li>
                <li><strong>Малоресурсные языки:</strong> если модель мало видела примеров данного языка при предобучении, её приоры слабы, и нужно больше примеров в контексте.</li>
            </ul>
            <div class="kmp12"><strong>Пояснение:</strong> Аналогия с зрительным восприятием: если объект очень необычен и не похож ни на что из предыдущего опыта (слабые приоры), одного показа оригинала может оказаться недостаточно — нужно несколько предъявлений с разных ракурсов, чтобы сформировать новую перцептивную категорию.</div>
        </div>
    </div>
</section>

<section id="9" class="section">
    <h2 class="section-title">Галлюцинации и «перегруженные приоры»: параллели между мозгом и LLM</h2>
    <div class="001">
        <h3 class="001-title">Механизм галлюцинаций через призму приоров</h3>
        <div class="001-card">
            <p>Одно из наиболее значимых для когнитивной лингвистики положений статьи Laamerad et al. — гипотеза о том, что галлюцинации (у человека) возникают из-за дисбаланса между приорами и сенсорным входом: когда приоры чрезмерно доминируют, мозг «видит» паттерны, которых нет в реальности. Этот же принцип описывает важнейшую проблему LLM.</p>
            <p><strong>Галлюцинации LLM — это генерация текста, который выглядит правдоподобно (соответствует статистическим приорам модели), но является фактически ложным (не соответствует реальному «сенсорному входу» — фактам, данным, запросу пользователя).</strong></p>
            <p><strong>Примеры из лингвистической практики:</strong></p>
            <ul>
                <li>LLM уверенно приводит «цитату» из научной статьи, которой не существует — статистический приор формата «автор (год): цитата» перебивает отсутствие фактических данных.</li>
                <li>LLM «изобретает» этимологию слова, которая выглядит правдоподобно, но не соответствует реальной истории языка — приор о типичных этимологических связях доминирует.</li>
                <li>LLM неверно глоссирует морфему малоизученного языка, но делает это в идеальном Лейпцигском формате — форматный приор создаёт иллюзию компетентности.</li>
            </ul>
        </div>
    </div>
    <div class="001">
        <h3 class="001-title">Лингвистическая интерференция как «перегруженный приор»</h3>
        <div class="001-card">
            <p>Для будущих преподавателей иностранных языков особенно важна параллель между «перегруженными приорами» и межъязыковой интерференцией:</p>
            <p><strong>Фонологическая интерференция:</strong> русскоязычный студент «слышит» английский [θ] как [s] или [f], потому что приор фонологической системы L1 не содержит категории [θ] и «маршрутизирует» входной сигнал к ближайшему имеющемуся шаблону.</p>
            <p><strong>Грамматическая интерференция:</strong> студент упорно строит английские предложения с русским порядком слов — синтаксический приор L1 доминирует над слабым приором L2.</p>
            <p><strong>Лексическая интерференция:</strong> false friends (англ. <em>actually</em> ≠ рус. <em>актуально</em>) — фонологическое сходство активирует ложный семантический приор.</p>
            <p><strong>Прагматическая интерференция:</strong> студент переносит нормы вежливости родной культуры на иноязычное общение (например, избыточная прямота или, наоборот, чрезмерная косвенность).</p>
            <div class="kmp12"><strong>Пояснение:</strong> Во всех этих случаях проблема — не отсутствие приора, а доминирование неподходящего приора. Преподавательская стратегия, в свете модели Laamerad et al., — не просто корректировать ошибки, а создавать условия для one-shot (или few-shot) инсайта: подобрать такой пример, который «переключит» систему восприятия студента на нужный приор L2. Именно поэтому удачно подобранная минимальная пара может быть эффективнее многих часов механической тренировки.</div>
        </div>
    </div>
    <div class="kmp12"><strong>Важно:</strong> Аналогия между галлюцинациями LLM и межъязыковой интерференцией — это учебная аналогия, которая помогает понять общий принцип (доминирование приора над входом), но не претендует на тождественность механизмов. У студента есть сознание, мотивация, способность к рефлексии и метакогнитивному контролю; у LLM — нет.</div>
</section>

<section id="10" class="section">
    <h2 class="section-title">«Ага-момент» в усвоении языка и in-context learning: границы аналогии</h2>
    <div class="001">
        <h3 class="001-title">Инсайт как перестройка приоров vs. активация приоров</h3>
        <div class="001-card">
            <p>Статья Laamerad et al. различает два связанных, но не тождественных процесса:</p>
            <ul>
                <li><strong>Активация приора:</strong> нужный шаблон уже существует, один пример лишь «указывает» на него. Это ближе к тому, что происходит при one-shot ICL у LLM.</li>
                <li><strong>Создание / перестройка приора:</strong> входной сигнал настолько нов, что система должна сформировать новую перцептивную категорию. Это ближе к тому, что происходит при долгосрочном перцептивном обучении и при fine-tuning LLM.</li>
            </ul>
            <p>Человеческий one-shot perceptual learning, по-видимому, находится на границе между этими процессами: формально он похож на «активацию» (один пример!), но реально приводит к устойчивой перестройке нейронных ансамблей (что характерно для «создания»).</p>
            <p><strong>LLM при one-shot ICL</strong> выполняет только первый процесс — активацию. Она не может по-настоящему «создать» новый приор в ходе одного сеанса. Именно поэтому:</p>
            <ul>
                <li>Если задача близка к тому, что модель «видела» при предобучении — one-shot ICL работает блестяще.</li>
                <li>Если задача принципиально нова (например, работа с языком, который модель никогда не видела) — one-shot ICL может оказаться бесполезным, потому что активировать нечего.</li>
            </ul>
        </div>
    </div>
    <div class="001">
        <h3 class="001-title">Импликации для преподавания языков</h3>
        <div class="001-card">
            <p>Если обобщить выводы статьи и аналогию с LLM для педагогической практики, можно сформулировать несколько принципов:</p>
            <p><strong>1. Принцип «подготовленного приора»:</strong></p>
            <p>One-shot инсайт возможен только тогда, когда у студента уже есть достаточная база знаний (приоры), к которым можно «привязать» новую информацию. Прежде чем давать сложный пример, нужно убедиться, что фоновые знания студента позволяют этот пример интерпретировать.</p>
            <p><strong>2. Принцип «минимального ключа»:</strong></p>
            <p>Если приоры подготовлены, для инсайта достаточно одного точно подобранного примера. Перегрузка примерами может даже мешать, создавая «шум» и рассеивая внимание.</p>
            <p><strong>3. Принцип «контроля за приором»:</strong></p>
            <p>Преподаватель должен учитывать, какие приоры L1 могут «перехватить» интерпретацию, и заранее работать с ними — не подавляя, а перенаправляя.</p>
            <p><strong>4. Принцип «закрепления инсайта»:</strong></p>
            <p>В отличие от LLM, у человека one-shot learning может давать долгосрочный эффект — но только если за инсайтом следует практика. Инсайт «активирует» приор; практика «закрепляет» его в долгосрочной памяти.</p>
        </div>
    </div>
    <div class="kmp11"><strong>Примечание:</strong> Аналогия между обучением человека и поведением LLM — это эвристический инструмент, а не научная теория. Она полезна для понимания принципов (роль приоров, механизм активации, проблема дисбаланса), но не должна создавать иллюзию, что LLM «думает», «понимает» или «учится» в том же смысле, что человек.</div>
</section>

<section id="11" class="section">
    <h2 class="section-title">Сводная таблица: one-shot learning в трёх системах</h2>
    <div class="001">
        <h3 class="001-title">Итоговое сопоставление</h3>
        <div class="001-card">
            <p>В заключение сведём все ключевые аспекты в единую таблицу для удобства повторения и сопоставления:</p>
        </div>
    </div>
    <div class="table-kmp">
        <table class="table">
            <thead>
                <tr>
                    <th>Аспект</th>
                    <th>Зрительная система человека</th>
                    <th>Языковое усвоение человеком</th>
                    <th>LLM (one-shot ICL)</th>
                </tr>
            </thead>
            <tr>
                <td><strong>Приоры</strong></td>
                <td>Зрительные шаблоны в HLVC</td>
                <td>Грамматика L1/L2, лексикон, прагматические нормы</td>
                <td>Веса, усвоенные при предобучении на корпусе</td>
            </tr>
            <tr>
                <td><strong>Входной сигнал</strong></td>
                <td>Размытое/зашумлённое изображение</td>
                <td>Незнакомая конструкция, акцентная речь, новое слово</td>
                <td>Текст промпта (инструкция + пример + запрос)</td>
            </tr>
            <tr>
                <td><strong>«Ключ» (один пример)</strong></td>
                <td>Чёткое изображение оригинала</td>
                <td>Объяснение / удачный пример от преподавателя</td>
                <td>Одна пара «вход → выход» в промпте</td>
            </tr>
            <tr>
                <td><strong>Механизм интеграции</strong></td>
                <td>Нисходящие сигналы от HLVC к ранней зрительной коре</td>
                <td>Связывание нового с имеющимися схемами, аналогия, категоризация</td>
                <td>Механизм внимания (self-attention), связывающий токены примера и запроса</td>
            </tr>
            <tr>
                <td><strong>Результат</strong></td>
                <td>Мгновенное распознавание ранее невидимого объекта</td>
                <td>«Ага-момент» — новая конструкция «встаёт на место»</td>
                <td>Корректная генерация ответа по паттерну примера</td>
            </tr>
            <tr>
                <td><strong>Устойчивость</strong></td>
                <td>Долгосрочная (реальная нейронная перестройка)</td>
                <td>Вариативная (зависит от дальнейшей практики)</td>
                <td>Эфемерная (только в текущем контексте)</td>
            </tr>
            <tr>
                <td><strong>Ошибки при дисбалансе</strong></td>
                <td>Парейдолия, зрительные галлюцинации</td>
                <td>Интерференция L1, ложные друзья переводчика</td>
                <td>Галлюцинации LLM, фактические ошибки</td>
            </tr>
        </table>
    </div>
    <div class="kmp14"><strong>Пояснение:</strong> Эта таблица суммирует центральную идею учебного материала: one-shot learning во всех трёх системах опирается на общий вычислительный принцип — использование накопленных приоров для интерпретации нового входа по минимальному количеству примеров. Различаются субстрат (нейроны vs. параметры сети), устойчивость эффекта и наличие/отсутствие сознательного переживания, но базовая логика «приор + ключ → распознавание» едина.</div>
</section>

<section id="12" class="section">
    <h2 class="section-title">Глоссарий ключевых терминов</h2>
    <div class="001">
        <h3 class="001-title">Термины из статьи Laamerad et al. (2026)</h3>
        <div class="001-card">
            <p><strong>One-shot perceptual learning</strong> — способность человека резко улучшить распознавание объекта после единственного предъявления его чёткой версии.</p>
            <p><strong>Priors (приоры)</strong> — внутренние модели (ожидания), сформированные на основе предшествующего опыта и используемые для интерпретации нового входа. В байесовском смысле — априорные распределения вероятностей.</p>
            <p><strong>HLVC (High-Level Visual Cortex)</strong> — высокоуровневая зрительная кора, где локализуются приоры для распознавания объектов.</p>
            <p><strong>Vision Transformer (ViT)</strong> — архитектура нейронной сети, применяющая механизм трансформера к обработке изображений, разбитых на фрагменты (патчи).</p>
        </div>
    </div>
    <div class="001">
        <h3 class="001-title">Термины из области LLM и NLP</h3>
        <div class="001-card">
            <p><strong>In-context learning (ICL)</strong> — способность LLM выполнять задачи на основе примеров в промпте без изменения весов модели.</p>
            <p><strong>Zero-shot prompting</strong> — подача задачи модели без каких-либо примеров.</p>
            <p><strong>One-shot prompting</strong> — подача задачи модели с одним демонстрационным примером.</p>
            <p><strong>Few-shot prompting</strong> — подача задачи модели с несколькими (обычно 2–10) демонстрационными примерами.</p>
            <p><strong>Fine-tuning</strong> — дообучение модели на дополнительных данных с обновлением весов.</p>
            <p><strong>Self-attention (самовнимание)</strong> — механизм, позволяющий каждому элементу последовательности «обращаться» ко всем другим элементам для выявления релевантных связей.</p>
            <p><strong>Токен</strong> — минимальная единица текста, обрабатываемая моделью (может быть словом, частью слова или символом).</p>
            <p><strong>Контекстное окно</strong> — максимальная длина последовательности токенов, которую модель может обрабатывать одновременно.</p>
            <p><strong>Галлюцинации LLM</strong> — генерация правдоподобного, но фактически ложного текста.</p>
            <p><strong>RAG (Retrieval-Augmented Generation)</strong> — архитектура, в которой LLM дополнена модулем поиска по внешней базе знаний.</p>
        </div>
    </div>
    <div class="001">
        <h3 class="001-title">Термины из лингвистики и когнитивной науки</h3>
        <div class="001-card">
            <p><strong>Fast mapping</strong> — способность быстро (за 1–2 предъявления) устанавливать связь между новым словом и его референтом (Carey &amp; Bartlett, 1978).</p>
            <p><strong>Интерференция (межъязыковая)</strong> — влияние системы одного языка на производство и восприятие другого.</p>
            <p><strong>Минимальная пара</strong> — два языковых выражения, различающиеся одним элементом, используемые для демонстрации смыслоразличительной функции этого элемента.</p>
            <p><strong>Фрейм</strong> — структура знаний, связывающая типичные элементы ситуации (участников, действия, предметы).</p>
            <p><strong>Речевой акт</strong> — единица речевой коммуникации, рассматриваемая с точки зрения намерения говорящего и воздействия на адресата (классификация Дж. Сёрля).</p>
        </div>
    </div>
	 <h3 class="001-title">Дополнительное чтение:</h3>
	  <a target="_blank" href="https://www.nature.com/articles/s41467-026-68711-x" class="link-kmp1">Статья в Nature Communications: Neural and computational mechanisms underlying one-shot perceptual learning in humans</a><br>
    <a target="_blank" href="https://medicalxpress.com/news/2026-02-brain-mechanism-intuition.html" class="link-kmp1">Популярное изложение на MedicalXpress: New research uncovers brain mechanism behind intuition</a><br>
    <a target="_blank" href="https://arxiv.org/abs/2005.14165" class="link-kmp1">Brown et al. (2020). Language Models are Few-Shot Learners (GPT-3)</a><br>
    <a target="_blank" href="https://arxiv.org/abs/2301.00234" class="link-kmp1">Dong et al. (2023). A Survey on In-Context Learning</a>
</section>


<footer class="footer">
<div class="container">
<p>© 2026 | kmp | CC BY-NC-SA 4.0<br>
Разработано для студентов БрГУ имени А.С. Пушкина</p>
</div>
</footer>
<div style="position: fixed; bottom: 10px; color: #777777; right: 30px; opacity: 0.3; font-size: 14px;">kmp+</div>
    <script>
        // Функция для плавной прокрутки к разделу
        function scrollToSection(sectionId) {
            const section = document.getElementById(sectionId);
            const menuHeight = document.querySelector('.menu').offsetHeight;
            
            window.scrollTo({
                top: section.offsetTop - menuHeight - 20,
                behavior: 'smooth'
            });
        }

        // Функция для переключения темы
        document.getElementById('themeToggle').addEventListener('click', function() {
            const currentTheme = document.documentElement.getAttribute('data-theme');
            const newTheme = currentTheme === 'dark' ? 'light' : 'dark';
            
            document.documentElement.setAttribute('data-theme', newTheme);
            this.textContent = newTheme === 'dark' ? '🌙' : '☀️';
        });

        // Анимация появления секций при прокрутке
        document.addEventListener('DOMContentLoaded', function() {
            const sections = document.querySelectorAll('.section');
            
            const observerOptions = {
                root: null,
                rootMargin: '0px',
                threshold: 0.1
            };
            
            const observer = new IntersectionObserver(function(entries, observer) {
                entries.forEach(entry => {
                    if (entry.isIntersecting) {
                        entry.target.classList.add('fade-in');
                        observer.unobserve(entry.target);
                    }
                });
            }, observerOptions);
            
            sections.forEach(section => {
                section.classList.remove('fade-in');
                observer.observe(section);
            });
        });
    </script>
</body>
</html>
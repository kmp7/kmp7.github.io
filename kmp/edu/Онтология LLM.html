<!DOCTYPE html>
<html lang="ru">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>kmp+</title>
    <style>
        /* Основные стили */
        :root {
            --primary-color: #325980;
			--primary1-color: #3498db;
			--primary2-color: #8c130d;
            --secondary-color: #4CAF50;
			--secondary1-color: #d9ebfc;
            --background-color: #f5f5f5;
			--content-bg: #fffff;
			--text-color: #333333;
            --header-text-color: #ffffff;
            --menu-bg: #ffffff;
            --menu-shadow: 0 2px 4px rgba(0, 0, 0, 0.1);
            --border-radius: 8px;
            --warning-color: #e74c3c;
            --caution-color: #f39c12;
			--accent11: #4caf50;
			--accent12: #4cafff;
			--accent13: #ffaf50;
			--accent14: #821978;
			--card-bg: #fff;
			--card-shadow: rgba(0, 0, 0, 0.1);
			--link-bg: #3498db;
			--link-hover: #2980b9;
        }

        /* Темная тема */
        [data-theme="dark"] {
            --primary-color: #3e76ad;
			--primary1-color: #3498db;
			--primary2-color: #8c130d;
            --secondary-color: #388e3c;
			--secondary1-color: #093f73;
            --background-color: #121212;
            --content-bg: #1e1e1e;
			--text-color: #e0e0e0;
            --header-text-color: #ffffff;
            --menu-bg: #1e1e1e;
            --menu-shadow: 0 2px 4px rgba(0, 0, 0, 0.3);
			--warning-color: #e74c3c;
            --caution-color: #f39c12;
			--card-bg: #2d2d2d;
			--card-shadow: rgba(0, 0, 0, 0.3);
			--link-bg: #2980b9;
			--link-hover: #3498db;
			
			
        }

        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
            transition: background-color 0.3s, color 0.3s;
        }

        body {
            font-family: 'Roboto', 'Arial', sans-serif;
            line-height: 1.6;
            color: var(--text-color);
            background-color: var(--background-color);
            padding-top: 60px;
        }

        .container {
            max-width: 1200px;
            margin: 0 auto;
            padding: 0 20px;
        }

        header {
            background-color: var(--primary-color);
            color: var(--header-text-color);
            padding: 20px 0;
            text-align: center;
            border-radius: var(--border-radius);
            margin-bottom: 20px;
            background-image: linear-gradient(135deg, var(--primary-color) 0%, #2c3e50 100%);
        }

        h1 {
            font-size: 2.2rem;
            margin-bottom: 10px;
        }

        h2 {
            color: var(--primary-color);
            margin: 25px 0 15px;
            padding-bottom: 8px;
            border-bottom: 2px solid var(--secondary-color);
        }

        h3 {
            color: var(--primary-color);
            margin: 20px 0 10px;
        }

        p {
            margin-bottom: 15px;
        }

        /* Меню навигации */
        .menu {
            background-color: var(--menu-bg);
            padding: 15px 20px;
            border-radius: var(--border-radius);
            margin-bottom: 30px;
            box-shadow: var(--menu-shadow);
            display: flex;
            justify-content: center;
            align-items: center;
            flex-wrap: wrap;
            position: sticky;
            top: 0;
            z-index: 100;
        }

        .menu-buttons {
            display: flex;
            flex-wrap: wrap;
            gap: 10px;
            justify-content: center;
        }

        .menu-btn {
            background-color: var(--primary-color);
            color: white;
            border: none;
            padding: 8px 15px;
            border-radius: 4px;
            cursor: pointer;
            font-size: 0.9rem;
            transition: background-color 0.3s;
        }

        .menu-btn:hover {
            background-color: var(--secondary-color);
        }

        .theme-toggle {
            background: none;
            border: 10px solid transparent;
            font-size: 1.5rem;
            cursor: pointer;
            color: var(--primary-color);
        }

        /* Секции контента */
        .section {
            background-color: var(--content-bg);
            border-radius: var(--border-radius);
            padding: 25px;
            margin-bottom: 30px;
            box-shadow: 0 2px 8px rgba(0, 0, 0, 0.1);
        }

       
    
		
		/* Таблицы */
		.table {
            background-color: var(--content-bg);
            border-radius: 2px;
            box-shadow: 0 2px 2px rgba(0, 0, 0, 0.1);
            padding: 20px;
            margin-bottom: 20px; width: 100%;
            color: var(--text-color);
			border-collapse: collapse;
			width: 100%;
            margin: 20px 0;
			box-sizing: border-box; /* Добавлено */
        }
        
        /* Заголовки таблицы с цветным фоном */
        .table thead th {
            background-color: #3498db;
            color: white;
            padding: 12px 15px;
            text-align: left;
            font-weight: 600;
			box-sizing: border-box; /* Добавлено */
        }
        
        /* Ячейки таблицы */
        .table tbody td {
            padding: 12px 15px;
            border-bottom: 1px solid #e0e0e0;
			box-sizing: border-box; /* Добавлено */
        }
        
        /* Чередование цветов строк для лучшей читаемости */
.table tbody tr:nth-child(even) {
    background-color: var(--content-bg);
}

/* Эффект при наведении на строку */
.table tbody tr:hover {
    background-color: var(--secondary1-color);
}
	
        
        /* Списки */
        ul, ol {
            padding-left: 50px;
            margin-bottom: 15px;
        }

        li {
            margin-bottom: 8px;
			padding-left: 20px;
			        }

        

        /* Адаптивный дизайн */
        @media (max-width: 768px) {
            h1 {
                font-size: 1.8rem;
            }
            
            h2 {
                font-size: 1.5rem;
            }
            
            .menu {
                flex-direction: column;
                gap: 15px;
            }
            
            .menu-buttons {
                width: 100%;
                justify-content: center;
            }
            
            .theme-toggle {
                margin-top: 10px;
            }
            
            .section {
                padding: 15px;
            }
        }

        /* Анимации */
        @keyframes fadeIn {
            from { opacity: 0; }
            to { opacity: 1; }
        }

        .fade-in {
            animation: fadeIn 0.5s ease-in;
        }

        footer {
            text-align: center;
            padding: 20px 0;
            margin-top: 40px;
            font-size: 0.9rem;
            border-top: 1px solid #ddd;
        }

        /* Цитаты */
        blockquote {
            border-left: 4px solid var(--secondary-color);
            padding: 15px 20px;
            margin: 20px 0;
            background-color: rgba(76, 175, 80, 0.05);
            font-style: italic;
        }
		
		.btn {
            display: inline-block;
            background-color: var(--primary-color);
            color: white;
            padding: 8px 18px;
            border-radius: 10px;
            text-decoration: none;
            margin-top: 12px;
            transition: var(--transition);
        }
        
        .btn:hover {
            background-color: var(--secondary-color);
            text-decoration: none;
            transform: translateY(-2px);
        }
		
		.btn1 {
            display: inline-block;
            background-color: var(--primary1-color);
            color: white;
            padding: 8px 18px;
            border-radius: 10px;
            text-decoration: none;
            margin-top: 12px;
            transition: var(--transition);
        }
		
		.btn1:hover {
            background-color: var(--secondary-color);
            text-decoration: none;
            transform: translateY(-2px);
        }
		
		.btn2 {
            display: inline-block;
            background-color: var(--primary2-color);
            color: white;
            padding: 8px 18px;
            border-radius: 10px;
            text-decoration: none;
            margin-top: 12px;
            transition: var(--transition);
        }
		
		.btn2:hover {
            background-color: var(--secondary-color);
            text-decoration: none;
            transform: translateY(-2px);
        }
		
		.btn3 {
            display: inline-block;
            background-color: var(--secondary-color);
            color: white;
            padding: 8px 18px;
            border-radius: 10px;
            text-decoration: none;
            margin-top: 12px;
            transition: var(--transition);
        }
		
		.btn3:hover {
            background-color: var(--secondary-color);
            text-decoration: none;
            transform: translateY(-2px);
        }
		
		.tag {
    display: inline-block;
    background-color: var(--secondary-color);
    color: white;
    padding: 3px 8px;
    border-radius: 4px;
    font-size: 12px;
    margin-right: 5px;
    margin-bottom: 5px;
}

.tag2 {
    display: inline-block;
    background-color: #8c130d;
    color: white;
    padding: 3px 8px;
    border-radius: 4px;
    font-size: 12px;
    margin-right: 5px;
    margin-bottom: 5px;
}

        /* Кнопка "Наверх" */
        .back-to-top {
            position: fixed;
            bottom: 30px;
            right: 30px;
            background-color: var(--primary-color);
            color: white;
            width: 50px;
            height: 50px;
            border-radius: 50%;
            display: flex;
            justify-content: center;
            align-items: center;
            cursor: pointer;
            box-shadow: 0 2px 10px rgba(0,0,0,0.2);
            opacity: 0;
            transition: opacity 0.3s;
            z-index: 99;
        }

        .back-to-top.visible {
            opacity: 1;
        }
		
	
		.link-kmp1 {
            color: #fffee0; 
            background-color: #007bff;  /
            padding: 0.2em 0.3em; 
            margin: 0 -0.3em; 
            text-decoration: none; 
			border-radius: 5px; /* Добавление скругленных углов */
             transition: background-color 0.2s ease-in-out, color 0.2s ease-in-out;
        }
		
		        .link-kmp1:hover,
        .link-kmp1:focus {
            color: #ffffff; 
            background-color: #0bb313; 
            text-decoration: none; 
        }
		
		.kmp11, .example {
      background: rgba(76, 175, 80, 0.1);
      border-left: 4px solid var(--accent11);
      padding: 10px 15px;
      margin: 15px 0;
      border-radius: 4px;
    }

		.kmp12, .example {
      background: rgba(95, 182, 237, 0.1);
      border-left: 4px solid var(--accent12);
      padding: 10px 15px;
      margin: 15px 0;
      border-radius: 4px;
    }
 
		.kmp13, .example {
      background: rgba(205, 170, 110, 0.1);
      border-left: 4px solid var(--accent13);
      padding: 10px 15px;
      margin: 15px 0;
      border-radius: 4px;
    }

		.kmp14, .example {
      background: rgba(205, 110, 200, 0.1);
      border-left: 4px solid var(--accent14);
      padding: 10px 15px;
      margin: 15px 0;
      border-radius: 4px;
    }

    .gallery {
      display: grid;
      grid-template-columns: repeat(auto-fit, minmax(300px, 1fr));
      gap: 20px;
      max-width: 1200px;
      margin: 0 auto;
    }

    .card {
      background-color: var(--card-bg);
      border-radius: 8px;
      box-shadow: 0 4px 8px var(--card-shadow);
      padding: 20px;
      transition: transform 0.2s, box-shadow 0.2s;
    }

    .card:hover {
      transform: translateY(-5px);
      box-shadow: 0 6px 12px var(--card-shadow);
    }

    .card h3 {
      margin: 0 0 10px;
      color: var(--heading-color);
    }

    .card p {
      margin: 0 0 15px;
      font-size: 0.95em;
      line-height: 1.5;
      color: var(--paragraph-color);
    }

    .card a {
      display: block;
      width: 100%;
      padding: 8px;
      background-color: var(--link-bg);
      color: #fff;
      text-align: center;
      text-decoration: none;
      border-radius: 5px;
      font-size: 1em;
      transition: background-color 0.2s;
    }

    .card a:hover {
      background-color: var(--link-hover);
    }

    .theme-toggle {
      position: fixed;
      top: 20px;
      right: 20px;
      background: none;
      border: none;
      font-size: 1.5rem;
      cursor: pointer;
      color: var(--text-color);
      transition: transform 0.2s;
    }

    .theme-toggle:hover {
      transform: scale(1.1);
    }

    footer {
      text-align: center;
      padding: 2rem;
      color: var(--footer-color);
      font-size: 0.7rem;
    }

    @media (max-width: 600px) {
      .gallery {
        grid-template-columns: 1fr;
      }

      .card {
        padding: 15px;
      }
      
      .theme-toggle {
        top: 10px;
        right: 10px;
        font-size: 1.2rem;
      }
    }
    </style>
</head>
<body>
    <div class="container">
        <header>
            <h1>ИСКУССТВЕННЫЙ ИНТЕЛЛЕКТ</h1>
            <p>в профессиональной деятельности преподавателя и лингвиста</p>
        </header>

        <nav class="menu">
            <div class="menu-buttons">
                <button class="menu-btn" onclick="scrollToSection('introduction')">Введение</button>
				<button class="menu-btn" onclick="scrollToSection('transformative-influence')">Трансформации</button>
                <button class="menu-btn" onclick="scrollToSection('interaction-distribution')">Системность</button>
				<button class="menu-btn" onclick="scrollToSection('context-environment')">Среда</button>
				<button class="menu-btn" onclick="scrollToSection('psychological-cognitive')">Ответственность</button>
				<button class="menu-btn" onclick="scrollToSection('conclusion')">Заключение</button>
				<button class="menu-btn" onclick="scrollToSection('dict')">Термины</button>
				<button class="menu-btn" onclick="scrollToSection('resources')">Литература</button>
			</div>
            <button class="theme-toggle" id="themeToggle" title="Переключить тему">☀️</button>
        </nav>

<section id="llm-tech" class="section"> <h2 class="section-title">1. LLM как технология</h2> <div class="001"> <h3 class="001-title">Математический и архитектурный уровень</h3> <div class="001-card"> <h4>Статистическая модель языка на трансформерах</h4> <p>Большая языковая модель (LLM) — это архитектура на основе нейросетей, чаще всего трансформерного типа, обученная на масштабных корпусах текстов с целью предсказания следующего токена.</p> <p>В этом контексте LLM — это технология, инженерный артефакт, аналогичный «двигателю без автомобиля».</p> <p><strong>Список 1:</strong></p> <ul> <li>не обладает интерфейсом;</li> <li>не содержит поведенческих фильтров или инструкций;</li> <li>не направлена на решение конкретных прикладных задач.</li> </ul> <p><strong>Пояснение:</strong> Это уровень «сырой мощности» модели — инженерная основа, ещё не превращённая в продукт.</p> </div> </div> <div class="table-kmp"> <table class="table"> <thead><tr><th>Свойство</th><th>Значение</th></tr></thead> <tr><td>Архитектура</td><td>Трансформер</td></tr> <tr><td>Цель обучения</td><td>Предсказание следующего токена</td></tr> </table> </div> <div class="kmp14"><strong>Пояснение:</strong> На этом этапе LLM не знает «ничего о мире» — она лишь запоминает вероятностные закономерности.</div> </section>

<section id="llm-pretrain" class="section"> <h2 class="section-title">2. Предобученная модель (Pretrained LLM)</h2> <div class="001"> <h3 class="001-title">Полуфабрикат нейросетевой кухни</h3> <div class="001-card"> <h4>Что такое «предобученная»?</h4> <p>После этапа self-supervised обучения модель становится "обобщённым языковым существом", но не имеет встроенной задачи или голоса. Она не знает, как вести диалог, как слушать или отвечать. Она просто статистически предсказывает — и всё.</p> <p>Эта модель не обогащена человеческой обратной связью и не ориентирована на пользователя.</p> <p><strong>Список 1:</strong></p> <ul> <li>не умеет вести диалог;</li> <li>не имеет миссии или роли;</li> <li>может быть токсичной, неполезной или хаотичной.</li> </ul> <p><strong>Пояснение:</strong> Предобученная модель — это «набор потенциальностей», без поведенческой направленности.</p> </div> </div> <div class="table-kmp"> <table class="table"> <thead><tr><th>Фаза</th><th>Роль модели</th></tr></thead> <tr><td>Pretraining</td><td>Универсальный прогнозировщик токенов</td></tr> </table> </div> <div class="kmp12"><strong>Важно:</strong> На этом этапе LLM может казаться «умной», но она лишь воспроизводит статистику корпуса, а не «знает» или «понимает».</div> </section>

<section id="llm-finetune" class="section"> <h2 class="section-title">3. Донастроенная модель (Fine-tuned LLM)</h2> <div class="001"> <h3 class="001-title">Формирование роли, контекста и полезности</h3> <div class="001-card"> <h4>Что делает do-настройка?</h4> <p>Fine-tuning настраивает модель на выполнение конкретных задач: чат, программирование, классификация, генерация инструкций и т.п. Часто используется human feedback (RLHF) для придания модели «пользовательского голоса».</p> <p>На этом уровне модель получает «характер», начинает ориентироваться в ожиданиях пользователя.</p> <p><strong>Список 1:</strong></p> <ul> <li>чёткая задача и роль;</li> <li>подавление нежелательного поведения;</li> <li>поведенческая корректировка.</li> </ul> <p><strong>Пояснение:</strong> Это этап, где LLM становится продуктом для кого-то, а не просто математическим инструментом.</p> </div> </div> <div class="kmp12"><strong>Важно:</strong> Fine-tuned модель — это уже сервисная сущность, готовая к использованию разработчиками или конечными пользователями.</div> </section>

<section id="llm-configured" class="section"> <h2 class="section-title">4. LLM как сконфигурированный персонаж</h2> <div class="001"> <h3 class="001-title">Системные промпты, фильтры и личность</h3> <div class="001-card"> <h4>Образы моделей и их поведение</h4> <p>На этом уровне модель получает идентичность: через системный промпт, стилевые инструкции, ограничения, правила поведения. Инфраструктура определяет, как модель должна общаться, думать, шутить, избегать рисков и соответствовать ценностям компании или рынка.</p> <p>Пользователь уже воспринимает LLM как персонажа или собеседника — а не просто как алгоритм.</p> <p><strong>Список 1:</strong></p> <ul> <li>тон общения, стиль, эмпатия;</li> <li>этические фильтры и безопасность;</li> <li>ограничения на тип контента.</li> </ul> <p><strong>Пояснение:</strong> LLM на этом уровне — это «актёр», читающий сценарий системного промпта.</p> </div> </div> <div class="kmp11"><strong>Примечание:</strong> Именно системный промпт делает Copilot отличным от GPT или Claude, даже при схожем ядре модели.</div> </section>

<section id="llm-brand" class="section"> <h2 class="section-title">5. LLM как продукт или бренд</h2> <div class="001"> <h3 class="001-title">Когда одна модель выступает в разных ролях</h3> <div class="001-card"> <h4>GPT-4, GPT-4 Turbo, Copilot — это всё одно?</h4> <p>Иногда под разными именами скрывается одна и та же базовая модель. Однако различия в инфраструктуре, обновлениях, скорости, стайлинге и API делают это «одной моделью с разными лицами».</p> <p>На этом уровне LLM — не только технология, но и часть рыночной идентичности.</p> <p><strong>Список 1:</strong></p> <ul> <li>модели с одинаковым ядром под разными именами;</li> <li>различия в доступных функциях, фильтрах и интерфейсах;</li> <li>маркетинговая упаковка скрывает технику.</li> </ul> <p><strong>Пояснение:</strong> Это порождает у пользователей ощущение, что «разные продукты» дают разные интеллектуальные возможности, хотя основа может быть та же.</p> </div> </div> <div class="kmp13"><strong>Внимание:</strong> Не всегда то, что кажется новой моделью, на самом деле таковой является.</div> </section>

<section id="llm-service" class="section"> <h2 class="section-title">6. LLM как сервис и опыт</h2> <div class="001"> <h3 class="001-title">Когда исчезает технология, и остаётся только взаимодействие</h3> <div class="001-card"> <h4>Интеграция в продукты, приложения, повседневность</h4> <p>Пользователь взаимодействует не с моделью, а с <strong>сервисом</strong>: помощником в редакторе, в поиске, в машине, в смартфоне. Важна не LLM, а то, как она <em>ведёт себя</em>, что она <em>может</em>, и насколько хорошо это <em>встроено в контекст</em>.</p> <p>Происхождение модели может быть скрыто, интерфейс — полностью абстрагирован, поведение — сильно модифицировано под задачу.</p> <p><strong>Список 1:</strong></p> <ul> <li>интеграция в продукты и экосистемы;</li> <li>интерфейсы маскируют модель;</li> <li>пользователь видит поведение, а не архитектуру.</li> </ul> <p><strong>Пояснение:</strong> LLM становится не объектом, а переживанием — элементом UX-дизайна, адаптированным к контексту задачи.</p> </div> </div> <div class="kmp12"><strong>Важно:</strong> Для большинства пользователей вопрос «какая это модель?» теряет значение — на первый план выходит удобство, адаптивность и доверие к сервису.</div> </section>



<section id="llm-family" class="section">
    <h2 class="section-title">1. Семейство LLM: структура и функции</h2>

    <div class="001">
        <h3 class="001-title">Что такое семейство LLM?</h3>
        <div class="001-card">
            <h4>Базовая модель как отправная точка</h4>
            <p><strong>Семейство больших языковых моделей (LLM)</strong> представляет собой совокупность моделей, происходящих от одной базовой архитектуры и обучающего процесса. Базовая модель служит фундаментом и обладает широким спектром общих знаний о языке, синтаксисе и семантике.</p>
            <p>Эта модель проходит этап предобучения (pre-training) на огромных объемах текстовых данных, что позволяет ей формировать вероятностные связи между словами и строить осмысленные тексты на разных уровнях сложности.</p>

            <p><strong>Основные компоненты семейства LLM:</strong></p>
            <ul>
                <li>Базовая модель (Pre-trained Base Model)</li>
                <li>Дообученные (Fine-tuned) или инструктивно-настроенные модели</li>
                <li>Специализированные варианты (по предметным областям)</li>
                <li>Модели разного размера (параметров)</li>
            </ul>

            <p><strong>Пояснение:</strong> Главное, что объединяет все эти модели — их происхождение от одной базовой архитектуры и методология обучения. Различия возникают на этапах дообучения и адаптации к конкретным задачам.</p>
        </div>
    </div>

    <div class="table-kmp">
        <table class="table">
            <thead>
                <tr>
                    <th>Тип модели</th>
                    <th>Назначение</th>
                </tr>
            </thead>
            <tbody>
                <tr>
                    <td>Базовая модель</td>
                    <td>Фундаментальные навыки понимания и генерации текста</td>
                </tr>
                <tr>
                    <td>Инструктивно-настроенная модель</td>
                    <td>Выполнение команд и участие в диалоге</td>
                </tr>
                <tr>
                    <td>Специализированная модель</td>
                    <td>Работа в узкой предметной области (кодирование, математика, медицина)</td>
                </tr>
                <tr>
                    <td>Мультимодальная модель</td>
                    <td>Обработка и генерация нескольких типов данных (текст, изображение, звук)</td>
                </tr>
            </tbody>
        </table>
    </div>

    <div class="001">
        <h3 class="001-title">Виды моделей внутри семейства LLM</h3>
        <div class="001-card">
            <h4>Как создаются специализированные варианты</h4>
            <p>От базовой модели "отпочковываются" различные варианты, которые проходят дополнительное обучение или тонкую настройку (fine-tuning) для выполнения конкретных задач.</p>
            <p>Цели такого дообучения могут быть самыми разными — от следования инструкциям до решения специфических задач в определённых областях.</p>

            <p><strong>Примеры целевых направлений дообучения:</strong></p>
            <ul>
                <li><strong>Следование инструкциям:</strong> Обучение модели понимать и выполнять пользовательские запросы через пары «инструкция – ответ».</li>
                <li><strong>Диалоговые способности:</strong> Оптимизация для участия в многоэтапном диалоге, сохранения контекста, управления темой.</li>
                <li><strong>Специализация:</strong> Дообучение на узкоспециализированных корпусах (например, код, математические формулы, научные публикации).</li>
                <li><strong>Мультимодальность:</strong> Расширение возможностей модели за счёт работы с несколькими типами данных.</li>
            </ul>

            <p><strong>Пример:</strong> Модель Qwen-VL может работать не только с текстом, но и с изображениями, расширяя сферу её применения в образовании и профессиональной деятельности.</p>
        </div>
    </div>

    <div class="001">
        <h3 class="001-title">Размер модели и её возможности</h3>
        <div class="001-card">
            <h4>Почему важен параметрический масштаб?</h4>
            <p>Одним из ключевых факторов, влияющих на мощность и эффективность LLM, является количество её параметров. В рамках одного семейства обычно выпускаются модели разного размера — например, 7B, 13B, 70B (миллиардов параметров) и более.</p>
            <p>Меньшие модели требуют меньше вычислительных ресурсов и быстрее работают, тогда как крупные модели потенциально обладают большей выразительностью и способны решать более сложные задачи.</p>

            <p><strong>Примеры:</strong></p>
            <ul>
                <li>LLaMA-2-7B — компактная модель, подходящая для локального использования;</li>
                <li>LLaMA-2-70B — высокопроизводительная модель, ориентированная на сложные аналитические задачи;</li>
                <li>Qwen-7B и Qwen-110B — аналогичный подход в семействе Qwen.</li>
            </ul>

            <p><strong>Пояснение:</strong> Все модели в одном семействе используют одну и ту же основную архитектуру и принципы обучения, но отличаются масштабом и направленностью последующего обучения.</p>
        </div>
    </div>

    <div class="kmp11"><strong>Примечание:</strong> Базовая модель — это не просто начальный этап, а носитель всего культурного и языкового опыта, который будет использоваться при формировании специализированных версий.</div>
    <div class="kmp12"><strong>Важно:</strong> При выборе модели для педагогической практики необходимо учитывать баланс между мощностью, скоростью и доступностью ресурсов.</div>
    <div class="kmp13"><strong>Внимание:</strong> Не стоит недооценивать значение мультимодальных моделей в современном образовательном пространстве.</div>
    <div class="kmp14"><strong>Пояснение:</strong> Выбор модели зависит от целей: базовая модель подходит для исследования, а специализированные — для решения конкретных задач в реальной профессиональной деятельности.</div>
</section>





 <section id="llm-service" class="section"> <h2 class="section-title">7</h2> <div class="001"> <h3 class="001-title">Когда исчезает технология, и остаётся только взаимодействие</h3> 
  
<div class="001">
    <h3 class="001-title">1. Семейство GPT-4: Общего назначения и мультимодальность</h3>
    <div class="001-card">
        <h4>Флагманские модели для широкого круга задач</h4>
        <p>Это основное семейство моделей OpenAI, предназначенных для выполнения широкого спектра задач, от генерации текста до сложных рассуждений. Каждое поколение или версия в этом семействе привносит новые возможности и улучшения.</p>
        <p><strong>Модели семейства GPT-4:</strong></p>
        <ul>
            <li><strong>GPT-4:</strong> Это оригинальная (базовая) модель четвертого поколения. Она известна своими высокими способностями к рассуждению, пониманию языка и генерации связного текста. До появления GPT-4o она была флагманом OpenAI.</li>
            <li><strong>GPT-4o ("o" for "omni" – всеобъемлющий):</strong> Новейшая флагманская модель OpenAI. Ее главная особенность — **мультимодальность**, что означает способность воспринимать и генерировать информацию не только в виде текста, но и аудио, изображений и видео. GPT-4o превосходит GPT-4 и GPT-4 Turbo по скорости и стоимости, при этом сохраняя или даже улучшая производительность в текстовых задачах и значительно расширяя возможности работы с нетекстовыми данными. Это **новое поколение** по отношению к просто GPT-4.</li>
            <li><strong>GPT-4o mini:</strong> Это **уменьшенная, более быстрая и экономичная версия GPT-4o**. Она разработана для менее сложных задач, где критичны высокая скорость и низкая стоимость, но при этом сохраняет многие мультимодальные возможности GPT-4o. Можно сказать, это "младший брат" GPT-4o, дистиллированный из более крупной модели для большей эффективности.</li>
            <li><strong>GPT-4.1:</strong> Это **ещё одна ветка развития семейства GPT-4, выпущенная после GPT-4o**. Она представляет собой значительное улучшение по сравнению с GPT-4o в таких областях, как кодирование, следование сложным инструкциям и работа с очень длинными контекстами (до 1 миллиона токенов). GPT-4.1 ориентирована на более точное выполнение сложных задач, особенно полезных для разработчиков и создания интеллектуальных агентов. Включает версии GPT-4.1, GPT-4.1 mini и GPT-4.1 nano, каждая со своими оптимизациями по размеру, скорости и стоимости.</li>
        </ul>
    </div>
</div>

<div class="001">
    <h3 class="001-title">2. Серия "o" (o1, o3, o4-mini): Модели для рассуждений</h3>
    <div class="001-card">
        <h4>Специализация на логическом мышлении и решении сложных проблем</h4>
        <p>Это отдельное семейство моделей от OpenAI, которое фокусируется на **улучшенных способностях к логическому рассуждению, решению сложных задач, математике и кодированию**. Эти модели часто используют более длительный процесс "мышления" (chain-of-thought reasoning), что делает их медленнее, но значительно точнее в сложных логических задачах.</p>
        <p><strong>Модели серии "o":</strong></p>
        <ul>
            <li><strong>o1:</strong> Это была первая модель в серии "o" (возможно, ее внутреннее название было "Strawberry"). Она была представлена как модель, специально разработанная для решения сложных задач, требующих пошагового логического рассуждения, математики, кодирования и научных проблем. Ее цель — обеспечивать глубокий и точный анализ.</li>
            <li><strong>o3:</strong> Это более новое и мощное развитие серии "o", преемник o1. Она значительно улучшает возможности рассуждения по сравнению с предыдущими и даже некоторыми моделями GPT-4o, особенно в кодировании, математике, науке и визуальном восприятии. o3 также стремится быть более естественной и разговорной, при этом сохраняя высокую точность.</li>
            <li><strong>o4-mini:</strong> Это более легкая и оптимизированная по скорости и стоимости версия в серии "o" для рассуждений. Она пытается найти баланс между высокой способностью к логическому мышлению и большей эффективностью, делая ее подходящей для задач, где требуется пошаговый анализ без избыточной медлительности o3.</li>
        </ul>
    </div>
</div>

<div class="table-kmp">
    <table class="table">
        <thead>
            <tr>
                <th>Название модели</th>
                <th>Принадлежность / Семейство</th>
                <th>Ключевые особенности</th>
            </tr>
        </thead>
        <tbody>
            <tr>
                <td>GPT-4</td>
                <td>Основное семейство GPT-4</td>
                <td>Оригинальная мощная LLM общего назначения.</td>
            </tr>
            <tr>
                <td>GPT-4o</td>
                <td>Основное семейство GPT-4</td>
                <td>Новый флагман. **Мультимодальная** (текст, аудио, изображение, видео), быстрее, дешевле, чем GPT-4/Turbo.</td>
            </tr>
            <tr>
                <td>GPT-4o mini</td>
                <td>Основное семейство GPT-4</td>
                <td>Уменьшенная, более быстрая и дешевая версия GPT-4o для простых и средних задач. Также мультимодальна.</td>
            </tr>
            <tr>
                <td>GPT-4.1</td>
                <td>Основное семейство GPT-4</td>
                <td>Новейшая ветка GPT-4. Значительно улучшена в **кодировании**, следовании инструкциям, работе с **очень длинным контекстом** (до 1M токенов).</td>
            </tr>
            <tr>
                <td>o1</td>
                <td>Серия "o" (рассуждения)</td>
                <td>Первая модель, ориентированная на **пошаговое логическое рассуждение** (математика, код, наука).</td>
            </tr>
            <tr>
                <td>o3</td>
                <td>Серия "o" (рассуждения)</td>
                <td>Более мощная и усовершенствованная модель для **сложных рассуждений**, кодирования, математики и анализа изображений. Медленнее, но точнее в этих задачах.</td>
            </tr>
            <tr>
                <td>o4-mini</td>
                <td>Серия "o" (рассуждения)</td>
                <td>Более быстрая и экономичная версия в серии "o", балансирующая рассуждения и эффективность.</td>
            </tr>
        </tbody>
    </table>
</div>

<div class="kmp14"><strong>Пояснение:</strong> Хотя все эти модели созданы OpenAI, они представляют собой различные направления развития и оптимизации. Модели семейства GPT-4 ориентированы на общие и мультимодальные задачи, в то время как модели серии "o" сфокусированы на глубоких логических рассуждениях. Выбор модели зависит от конкретной задачи, которую вы хотите решить.</div>
</div> </section>



  <section id="llm-service" class="section"> <h2 class="section-title">8</h2> <div class="001"> <h3 class="001-title">Финансовая сторона</h3> 
  <div class="001-card">
        <h4>Финансовая сторона</h4>
Создание передовой базовой LLM с нуля (pre-training) — это чрезвычайно дорогостоящее и ресурсоемкое предприятие. Основные затраты на этом этапе связаны с:
Вычислительные ресурсы (Compute): Это самая большая статья расходов. Требуются десятки тысяч высокопроизводительных GPU (таких как NVIDIA H100 или A100), работающих непрерывно в течение многих месяцев. Стоимость аренды такого оборудования в облаке или покупки и обслуживания собственных суперкомпьютеров исчисляется десятками и сотнями миллионов долларов.
Данные: Сбор, очистка, разметка и подготовка гигантских объемов текстовых данных (терабайты и петабайты) для обучения. Это включает затраты на лицензирование данных, работу дата-инженеров и аннотаторов.
Персонал: Высококвалифицированные исследователи, инженеры по машинному обучению, инженеры по инфраструктуре, которые проектируют, обучают, тестируют и оптимизируют модель. Их зарплаты могут составлять значительную часть общих расходов. Например, Цукерберг предлагал сотрудникам OpenAI $100 миллионов за переход в Meta/
Об этом рассказал Сэм Альтман: https://www.youtube.com/watch?v=mZUG0pr5hBo. Некоторые перешли, в том числе Александр Колесников.
Энергопотребление и охлаждение: Работа тысяч GPU генерирует огромное количество тепла, требуя значительных затрат на электроэнергию и системы охлаждения.
Пояснение: Создание передовой базовой LLM — это задача, доступная лишь крупным технологическим гигантам или очень хорошо финансируемым стартапам из-за колоссальных капиталовложений в оборудование, данные и высококлассных специалистов.

Дообучение до конкретного варианта: значительно дешевле, но не бесплатно

        <p>Дообучение (fine-tuning) существующей базовой LLM для конкретного варианта (например, для следования инструкциям, для чата, для специализированной области) значительно, на порядки, дешевле, чем её создание с нуля. Однако это всё ещё требует определённых затрат, которые зависят от нескольких факторов:</p>
        <ul>
            <li><strong>Размер модели:</strong> Чем больше дообучаемая модель, тем дороже процесс.</li>
            <li><strong>Объем и качество данных для дообучения:</strong> Хотя объемы данных гораздо меньше, чем для предварительного обучения (тысячи или сотни тысяч примеров вместо триллионов токенов), их качество и специфичность критически важны. Подготовка таких данных также требует затрат.</li>
            <li><strong>Метод дообучения:</strong>
                <ul>
                    <li>**Полное дообучение (Full Fine-tuning):** Все параметры модели обновляются, что требует больше вычислительных ресурсов.</li>
                    <li>**Методы адаптации с низким рангом (LoRA, QLoRA и др.):** Эти методы обновляют лишь небольшое подмножество параметров, что значительно снижает вычислительные затраты и позволяет дообучать крупные модели даже на относительно скромном оборудовании (например, на одной или нескольких GPU).</li>
                    <li>**Обучение с подкреплением на основе обратной связи от человека (RLHF):** Требует участия людей-оценщиков, что также является статьей расходов.</li>
                </ul>
            </li>
            <li><strong>Длительность дообучения:</strong> Количество "эпох" или итераций обучения.</li>
            <li><strong>Вычислительные ресурсы:</strong> Хотя меньше, чем для pre-training, всё равно могут потребоваться мощные GPU.
                <br>
                <p><strong>Примеры оценок:</strong></p>
                <ul>
                    <li><strong>Дообучение Mistral 7B с использованием LoRA:</strong> Некоторые источники сообщают о стоимости **менее $10** за несколько часов обучения на одной средней GPU в облаке, исключая стоимость хранения данных.</li>
                    <li><strong>Дообучение GPT-3.5 через API OpenAI:</strong> Стоимость определяется количеством токенов, используемых для обучения и последующего использования. Например, обучение может стоить **$0.0080 за 1K токенов**, а использование - **$0.0030 за 1K входных токенов** и **$0.0060 за 1K выходных токенов**. Для большого объема данных это может составить сотни или тысячи долларов.</li>
                    <li><strong>Общие оценки:</strong> Варьируются от **нескольких долларов до тысяч долларов** в зависимости от размера модели, набора данных и продолжительности. Для крупных компаний с большим объемом данных и необходимостью частых итераций, эти расходы могут быть существенными, но все равно несравнимы с затратами на pre-training.</li>
                </ul>
            </li>
        </ul>
        <p><strong>Пояснение:</strong> Дообучение позволяет компаниям и исследователям, не обладающим бюджетами гигантов, специализировать существующие мощные модели под свои нужды, делая LLM более доступными для широкого круга применений.</p>
    </div>
</div>

<div class="table-kmp">
    <table class="table">
        <thead>
            <tr>
                <th>Параметр сравнения</th>
                <th>Создание базовой LLM (Pre-training)</th>
                <th>Дообучение существующей LLM (Fine-tuning)</th>
            </tr>
        </thead>
        <tbody>
            <tr>
                <td><strong>Масштаб затрат (гипотетически)</strong></td>
                <td>**От десятков миллионов до сотен миллионов (иногда миллиардов) долларов.**</td>
                <td>**От нескольких десятков/сотен долларов до тысяч (иногда десятков тысяч) долларов.**</td>
            </tr>
            <tr>
                <td><strong>Основные статьи расходов</strong></td>
                <td>Вычислительные ресурсы (тысячи GPU на месяцы), огромные объемы данных, высококвалифицированный персонал.</td>
                <td>Вычислительные ресурсы (гораздо меньше GPU, часы/дни), подготовка специализированных данных, инженерные усилия.</td>
            </tr>
            <tr>
                <td><strong>Типичные примеры</strong></td>
                <td>Создание GPT-4, Gemini Ultra, Llama 3 с нуля.</td>
                <td>Настройка Llama-2-Chat для конкретного стиля, дообучение модели для чат-бота поддержки клиентов.</td>
            </tr>
            <tr>
                <td><strong>Уровень сложности/доступности</strong></td>
                <td>Крайне высокая, доступно единицам компаний в мире.</td>
                <td>Значительно ниже, доступно многим компаниям и даже индивидуальным разработчикам (особенно с использованием открытых моделей и LoRA).</td>
            </tr>
        </tbody>
    </table>
</div>

<div class="kmp12"><strong>Важно:</strong> Соотношение стоимости между созданием базовой LLM и её дообучением часто составляет тысячи (даже десятки тысяч) к одному. Основная инвестиция делается в создание "интеллектуального ядра" (базовой модели), а её адаптация под конкретные задачи является относительно более доступным процессом, который и позволяет LLM находить столь широкое применение.</div>
</section>


<section id="llm-service" class="section"> 
<h2 class="section-title">Расходы на инференс (Inference Costs)</h2> 
<div class="001"> 

    <h3 class="001-title">1. Расходы на инференс</h3>
    <div class="001-card">
        <h4>Основная статья расходов для активных пользователей</h4>
        <p>Это, как правило, **самая большая и постоянно растущая статья расходов** для масштабного LLM-сервиса. Инференс — это процесс использования обученной модели для генерации ответов на запросы пользователей. Затраты зависят от:</p>
        <ul>
            <li><strong>Количества запросов:</strong> Миллионы пользователей генерируют миллиарды запросов в день/месяц.</li>
            <li><strong>Длины запроса и ответа (токены):</strong> Стоимость обычно рассчитывается за 1000 токенов (как входных, так и выходных). Чем длиннее диалоги, тем выше затраты.
                <br>
                <p><strong>Примеры оценок стоимости за 1000 токенов (на 2025 год, могут меняться):</strong></p>
                <ul>
                    <li>**GPT-4o:** Вход $0.005, выход $0.015 (за 1000 токенов).</li>
                    <li>**GPT-4o mini:** Вход $0.00015, выход $0.0006 (за 1000 токенов).</li>
                    <li>**Claude 3 Sonnet:** Вход $3.00, выход $15.00 (за 1 миллион токенов).</li>
                    <li>**Llama 3 70B (от облачных провайдеров):** Вход ~$0.20-0.30, выход ~$0.20-0.30 (за 1 миллион токенов).</li>
                </ul>
                <p>При **100 миллионах пользователей**, каждый из которых генерирует, скажем, 10-20 запросов в день по 500-1000 токенов (вход + выход), общая сумма токенов будет астрономической, и расходы на инференс могут легко превысить **десятки миллионов долларов в месяц**.</p>
            </li>
            <li><strong>Выбор модели:</strong> Использование более крупных и мощных моделей (например, GPT-4o, o3) значительно дороже, чем использование "мини" или open-source моделей (например, Llama 3 8B, Mistral 7B).</li>
            <li><strong>Инфраструктура для инференса:</strong> Для обслуживания миллионов параллельных запросов требуются огромные кластеры GPU, распределенные по дата-центрам по всему миру. Это аренда или покупка тысяч GPU (NVIDIA A100/H100), серверов, сетевого оборудования, систем охлаждения.</li>
            <li><strong>Оптимизация инференса:</strong> Постоянная работа над снижением задержек (latency) и повышением пропускной способности (throughput), включая квантование моделей, использование специализированного аппаратного обеспечения (например, LPU от Groq), кеширование ответов.</li>
        </ul>
    </div>
</div>

<div class="001">
    <h3 class="001-title">2. Инфраструктурные расходы</h3>
    <div class="001-card">
        <h4>Поддержание работоспособности и масштабирования</h4>
        <p>Помимо вычислительных ресурсов для самой модели, требуется обширная поддерживающая инфраструктура:</p>
        <ul>
            <li><strong>Серверы и сети:</strong> Для балансировки нагрузки, маршрутизации запросов, хранения данных.</li>
            <li><strong>Базы данных:</strong> Для хранения истории диалогов, пользовательских настроек, данных для дообучения и RAG (Retrieval Augmented Generation).</li>
            <li><strong>Системы мониторинга и логирования:</strong> Для отслеживания производительности, ошибок, использования ресурсов.</li>
            <li><strong>Распределенные системы хранения:</strong> Для больших объемов данных.</li>
            <li><strong>CDN (Content Delivery Networks):</strong> Для быстрой доставки контента пользователям по всему миру.</li>
            <li><strong>Затраты на "теплые" GPU:</strong> Часто для минимизации задержек приходится держать часть GPU в "теплом" или "горячем" состоянии, что означает оплату за них, даже когда они не используются на полную мощность.</li>
        </ul>
    </div>
</div>

<div class="001">
    <h3 class="001-title">3. Разработка и обслуживание платформы (Software Engineering)</h3>
    <div class="001-card">
        <h4>Команда, обеспечивающая функциональность</h4>
        <p>Это зарплаты большого числа высококвалифицированных специалистов:</p>
        <ul>
            <li><strong>ML Engineers (инженеры машинного обучения):</strong> Оптимизация моделей, развертывание, мониторинг.</li>
            <li><strong>Backend Developers:</strong> Разработка API, интеграция с базами данных и другими сервисами.</li>
            <li><strong>Frontend Developers:</strong> Создание и поддержка пользовательского интерфейса (чат, голосовой ввод, визуализации).</li>
            <li><strong>DevOps/SRE (Site Reliability Engineers):</strong> Автоматизация развертывания, управление инфраструктурой, обеспечение надежности и масштабируемости.</li>
            <li><strong>Data Scientists/Analysts:</strong> Анализ данных об использовании, выявление тенденций, оптимизация.</li>
            <li><strong>Research Scientists:</strong> Постоянные исследования и разработка новых функций и улучшений для модели.</li>
            <li><strong>Product Managers, UX/UI Designers:</strong> Управление продуктом, улучшение пользовательского опыта.</li>
        </ul>
        <p>Зарплаты такой команды могут составлять **миллионы долларов в месяц**.</p>
    </div>
</div>

<div class="001">
    <h3 class="001-title">4. Управление данными и дообучение</h3>
    <div class="001-card">
        <h4>Постоянное совершенствование модели</h4>
        <ul>
            <li><strong>Сбор и аннотирование данных:</strong> Постоянное расширение и улучшение наборов данных для дообучения модели, что часто требует ручного труда аннотаторов.</li>
            <li><strong>Регулярное дообучение (Fine-tuning):</strong> Модели требуют периодического дообучения на новых данных, чтобы оставаться актуальными, улучшать производительность и адаптироваться к изменениям в языке или поведении пользователей. Это может стоить от тысяч до десятков тысяч долларов за каждый раунд дообучения, но с учетом частых итераций на масштабе, это может быть значительной суммой.</li>
            <li><strong>Обновление и обслуживание RAG-систем:</strong> Для систем, использующих Retrieval Augmented Generation, требуется постоянное обновление баз знаний и поддержание их актуальности.</li>
        </ul>
    </div>
</div>

<div class="001">
    <h3 class="001-title">5. Безопасность и соответствие нормам</h3>
    <div class="001-card">
        <h4>Защита данных и пользователей</h4>
        <ul>
            <li><strong>Модерация контента:</strong> Автоматическая и ручная фильтрация потенциально вредоносного, токсичного или запрещенного контента в запросах и ответах. Это может включать использование отдельных LLM для модерации, что добавляет к инференс-расходам.</li>
            <li><strong>Защита данных:</strong> Обеспечение конфиденциальности и безопасности пользовательских данных, соответствие GDPR, CCPA и другим регулятивным требованиям.</li>
            <li><strong>Предотвращение злоупотреблений:</strong> Механизмы для выявления и блокировки спама, фишинга, генерации дезинформации.</li>
            <li><strong>Юридические расходы:</strong> Консультации по вопросам использования данных, этики ИИ, соответствия законодательству.</li>
        </ul>
    </div>
</div>

<div class="001">
    <h3 class="001-title">6. Маркетинг, продажи и поддержка клиентов</h3>
    <div class="001-card">
        <h4>Привлечение и удержание пользователей</h4>
        <ul>
            <li>Продвижение сервиса, привлечение новых пользователей.</li>
            <li>Команды поддержки, отвечающие на вопросы, решающие проблемы пользователей.</li>
        </ul>
    </div>
</div>

<div class="kmp12"><strong>Важно:</strong> Общая стоимость поддержки LLM-сервиса с десятками/сотнями миллионов пользователей — это сложная, многокомпонентная задача. Нет единой "фиксированной" цифры, но она однозначно измеряется **десятками и сотнями миллионов долларов ежегодно**. Компании, предоставляющие такие сервисы (как OpenAI, Google, Yandex), вкладывают огромные средства в постоянную оптимизацию, масштабирование и улучшение, чтобы сократить эти операционные расходы, но они всё равно остаются колоссальными. Экономика LLM-сервисов для массового пользователя — это тонкий баланс между ценой за токен, эффективностью инференса и пользовательским вовлечением.</div>
</div> </section>


		
	<footer class="footer">
<div class="container">
<p>© 2025 | Искусственный интеллект в профессиональной деятельности<br>
Разработано для студентов БрГУ имени А.С. Пушкина</p>
</div>
</footer>
<div style="position: fixed; bottom: 10px; right: 33px; opacity: 0.3; font-size: 14px;">kmp+</div>

        <div class="back-to-top" id="backToTop" onclick="window.scrollTo({top: 0, behavior: 'smooth'})">↑</div>
    </div>
	
        <script>
        // Функция для плавной прокрутки к разделу
        function scrollToSection(sectionId) {
            const section = document.getElementById(sectionId);
            const menuHeight = document.querySelector('.menu').offsetHeight;
            
            window.scrollTo({
                top: section.offsetTop - menuHeight - 20,
                behavior: 'smooth'
            });
        }

        // Функция для переключения темы
        document.getElementById('themeToggle').addEventListener('click', function() {
            const currentTheme = document.documentElement.getAttribute('data-theme');
            const newTheme = currentTheme === 'dark' ? 'light' : 'dark';
            
            document.documentElement.setAttribute('data-theme', newTheme);
            this.textContent = newTheme === 'dark' ? '🌙' : '☀️';
        });

        // Анимация появления секций при прокрутке
        document.addEventListener('DOMContentLoaded', function() {
            const sections = document.querySelectorAll('.section');
            
            const observerOptions = {
                root: null,
                rootMargin: '0px',
                threshold: 0.1
            };
            
            const observer = new IntersectionObserver(function(entries, observer) {
                entries.forEach(entry => {
                    if (entry.isIntersecting) {
                        entry.target.classList.add('fade-in');
                        observer.unobserve(entry.target);
                    }
                });
            }, observerOptions);
            
            sections.forEach(section => {
                section.classList.remove('fade-in');
                observer.observe(section);
            });
        });
		
		
		
    </script>
	
</body>
</html>
<!DOCTYPE html>
<html lang="ru">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>kmp+</title>
    <style>
        /* Основные стили */
        :root {
            --primary-color: #325980;
            --secondary-color: #4CAF50;
            --background-color: #f5f5f5;
            --content-bg: #ffffff;
            --text-color: #333333;
            --header-text-color: #ffffff;
            --menu-bg: #ffffff;
            --menu-shadow: 0 2px 4px rgba(0, 0, 0, 0.1);
            --border-radius: 8px;
			  --accent11: #4caf50;
		--accent12: #4cafff;
		--accent13: #ffaf50;
		--accent14: #821978;
        }

        /* Темная тема */
        [data-theme="dark"] {
            --primary-color: #3e76ad;
            --secondary-color: #388e3c;
            --background-color: #000000;
            --content-bg: #1e1e1e;
            --text-color: #e0e0e0;
            --header-text-color: #ffffff;
            --menu-bg: #000000;
            --menu-shadow: 0 2px 4px rgba(0, 0, 0, 0.3);
        }

        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
            transition: background-color 0.3s, color 0.3s;
        }

        body {
            font-family: 'Roboto', 'Arial', sans-serif;
            line-height: 1.6;
            color: var(--text-color);
            background-color: var(--background-color);
            padding-top: 2px;
        }

        .container {
            max-width: 1200px;
            margin: 0 auto;
            padding: 0 20px;
        }

        header {
            background-color: var(--primary-color);
            color: var(--header-text-color);
            padding: 20px 0;
            text-align: center;
            border-radius: var(--border-radius);
            margin-bottom: 2px;
        }

        h1 {
            font-size: 2.2rem;
            margin-bottom: 10px;
        }

        h2 {
            color: var(--primary-color);
            margin: 25px 0 15px;
            padding-bottom: 8px;
            border-bottom: 2px solid var(--secondary-color);
        }

        h3 {
            color: var(--primary-color);
            margin: 20px 0 10px;
        }

        p {
            margin-bottom: 15px;
        }

        /* Меню навигации */
        .menu {
            background-color: var(--menu-bg);
            padding: 15px 20px;
            border-radius: var(--border-radius);
            margin-bottom: 30px;
            box-shadow: var(--menu-shadow);
            display: flex;
            justify-content: center;
            align-items: center;
            flex-wrap: wrap;
            position: sticky;
            top: 0;
            z-index: 100;
        }

        .menu-buttons {
            display: flex;
            flex-wrap: wrap;
            gap: 10px;
        }
		
		
		.menu-buttons {
    display: flex;
    flex-wrap: wrap;
    gap: 10px;
    justify-content: center; /* Изменено на center */
}

        .menu-btn {
            background-color: var(--primary-color);
            color: white;
            border: none;
            padding: 8px 15px;
            border-radius: 4px;
            cursor: pointer;
            font-size: 0.9rem;
            transition: background-color 0.3s;
        }

        .menu-btn:hover {
            background-color: var(--secondary-color);
        }

        .theme-toggle {
            background: none;
            border: 10px solid transparent;
            font-size: 1.5rem;
            cursor: pointer;
            color: var(--primary-color);
        }

        /* Секции контента */
        .section {
            background-color: var(--content-bg);
            border-radius: var(--border-radius);
            padding: 25px;
            margin-bottom: 30px;
            box-shadow: 0 2px 8px rgba(0, 0, 0, 0.1);
        }

        /* Выделение важного */
        .important {
            background-color: rgba(76, 175, 80, 0.1);
            border-left: 4px solid var(--secondary-color);
            padding: 15px;
            margin: 15px 0;
            border-radius: 0 var(--border-radius) var(--border-radius) 0;
        }

        .note {
            background-color: rgba(50, 89, 128, 0.1);
            border-left: 4px solid var(--primary-color);
            padding: 15px;
            margin: 15px 0;
            border-radius: 0 var(--border-radius) var(--border-radius) 0;
        }

        /* Таблицы */
        table {
            width: 100%;
            border-collapse: collapse;
            margin: 20px 0;
        }

        th, td {
            padding: 12px 15px;
            border: 1px solid #ddd;
            text-align: left;
        }

        th {
            background-color: var(--primary-color);
            color: white;
        }

        tr:nth-child(even) {
            background-color: rgba(0, 0, 0, 0.03);
        }

        /* Списки */
        ul, ol {
            padding-left: 25px;
            margin-bottom: 15px;
        }

        li {
            margin-bottom: 8px;
        }

        /* Адаптивный дизайн */
        @media (max-width: 768px) {
            h1 {
                font-size: 1.8rem;
            }
            
            h2 {
                font-size: 1.5rem;
            }
            
            .menu {
                flex-direction: column;
                gap: 15px;
            }
            
            .menu-buttons {
                width: 100%;
                justify-content: center;
            }
            
            .theme-toggle {
                margin-top: 10px;
            }
            
            .section {
                padding: 15px;
            }
        }

        /* Анимации */
        @keyframes fadeIn {
            from { opacity: 0; }
            to { opacity: 1; }
        }

        .fade-in {
            animation: fadeIn 0.5s ease-in;
        }

        footer {
            text-align: center;
            padding: 20px 0;
            margin-top: 40px;
            font-size: 0.9rem;
        }
		
					.kmp11, .example {
      background: rgba(76, 175, 80, 0.1);
      border-left: 4px solid var(--accent11);
      padding: 10px 15px;
      margin: 15px 0;
      border-radius: 4px;
    }

		.kmp12, .example {
      background: rgba(95, 182, 237, 0.1);
      border-left: 4px solid var(--accent12);
      padding: 10px 15px;
      margin: 15px 0;
      border-radius: 4px;
    }
 
		.kmp13, .example {
      background: rgba(205, 170, 110, 0.1);
      border-left: 4px solid var(--accent13);
      padding: 10px 15px;
      margin: 15px 0;
      border-radius: 4px;
    }

		.kmp14, .example {
      background: rgba(205, 110, 200, 0.1);
      border-left: 4px solid var(--accent14);
      padding: 10px 15px;
      margin: 15px 0;
      border-radius: 4px;
    }
    </style>
</head>
<body>
    <div class="container">
        <header>
             <h1>History</h1>
            <p>цифровизации устной речи</p>
        </header>

        <nav class="menu">
            <div class="menu-buttons">
                <button class="menu-btn" onclick="scrollToSection('1')">Введение</button>
                <button class="menu-btn" onclick="scrollToSection('2')">Этап 1</button>
                <button class="menu-btn" onclick="scrollToSection('3')">Этап 2</button>
                <button class="menu-btn" onclick="scrollToSection('4')">Этап 3</button>
				<button class="menu-btn" onclick="scrollToSection('5')">Этап 4</button>
				<button class="menu-btn" onclick="scrollToSection('6')">Перспективы</button>
                                    </div>
            <button class="theme-toggle" id="themeToggle" title="Переключить тему">☀️</button>
        </nav>


<section id="1" class="section">
    <h2 class="section-title">Введение в цифровизацию речи</h2>
    <div class="001">
        <h3 class="001-title">Основные понятия и определения</h3>
        <div class="001-card">
            <p>Цифровизация речи — это процесс преобразования акустических речевых сигналов в цифровую форму для их обработки, хранения, передачи и воспроизведения с помощью компьютерных технологий. Этот процесс включает в себя не только техническое преобразование звуковых волн в последовательности чисел, но и создание систем, способных понимать, анализировать и генерировать человеческую речь.</p>
            <p>Цифровизация речи охватывает широкий спектр технологий и приложений, от простой записи голоса до сложных систем искусственного интеллекта, способных вести диалог с человеком.</p>
            <p><strong>Основные направления цифровизации речи:</strong></p>
            <ul>
                <li>Оцифровка и кодирование речевых сигналов</li>
                <li>Автоматическое распознавание речи (ASR)</li>
                <li>Синтез речи (TTS — Text-to-Speech)</li>
                <li>Обработка естественного языка (NLP)</li>
                <li>Анализ эмоций и интонаций</li>
                <li>Идентификация и верификация говорящего</li>
            </ul>
            <p><strong>Пояснение:</strong> Каждое из этих направлений имеет свою историю развития и специфические технологические решения.</p>
        </div>
    </div>
    <div class="002">
        <h3 class="002-title">Междисциплинарный характер области</h3>
        <div class="002-card">
            <h4>Науки и дисциплины</h4>
            <p>Цифровизация речи находится на пересечении множества научных дисциплин, каждая из которых вносит свой вклад в развитие технологий обработки речи.</p>
            <div class="table-kmp">
                <table class="table">
                    <thead>
                        <tr>
                            <th>Дисциплина</th>
                            <th>Вклад в цифровизацию речи</th>
                        </tr>
                    </thead>
                    <tr>
                        <td>Лингвистика</td>
                        <td>Теории языка, фонетика, фонология, синтаксис, семантика</td>
                    </tr>
                    <tr>
                        <td>Акустика</td>
                        <td>Физика звука, спектральный анализ, акустические модели</td>
                    </tr>
                    <tr>
                        <td>Информатика</td>
                        <td>Алгоритмы, структуры данных, машинное обучение</td>
                    </tr>
                    <tr>
                        <td>Математика</td>
                        <td>Статистика, теория вероятностей, цифровая обработка сигналов</td>
                    </tr>
                    <tr>
                        <td>Психология</td>
                        <td>Восприятие речи, когнитивные процессы, психоакустика</td>
                    </tr>
                </table>
            </div>
            <div class="kmp11"><strong>Примечание:</strong> Успешное развитие технологий цифровизации речи требует тесного сотрудничества специалистов из разных областей.</div>
        </div>
    </div>
</section>

<section id="2" class="section">
    <h2 class="section-title">Ранние этапы: от аналоговых к цифровым технологиям</h2>
    <div class="001">
        <h3 class="001-title">Первые попытки записи и передачи речи</h3>
        <div class="001-card">
            <h4>Доцифровая эпоха</h4>
            <p>История попыток зафиксировать и передать человеческую речь началась задолго до появления цифровых технологий. Первые эксперименты были связаны с механическими и аналоговыми устройствами, которые заложили основу для будущих цифровых систем.</p>
            <p><strong>Ключевые изобретения:</strong></p>
            <ul>
                <li>Фоноавтограф (1857) — Эдуард-Леон Скотт де Мартинвиль создал первое устройство для визуальной записи звуковых волн</li>
                <li>Фонограф (1877) — Томас Эдисон изобрел первое устройство для записи и воспроизведения звука</li>
                <li>Граммофон (1887) — Эмиль Берлинер усовершенствовал технологию, создав плоские диски</li>
                <li>Магнитофон (1935) — AEG представила первый практичный магнитофон, использующий магнитную ленту</li>
            </ul>
            <p><strong>Пояснение:</strong> Эти изобретения создали техническую базу для понимания природы звука и методов его фиксации.</p>
        </div>
        <div class="001-card">
            <h4>Роль телефонии и радиосвязи</h4>
            <p>Развитие телефонии и радиосвязи сыграло критическую роль в понимании процессов передачи речевых сигналов на расстояние. Александр Грэхем Белл, изобретя телефон в 1876 году, не только создал революционное устройство связи, но и заложил основы для изучения электрической передачи речи.</p>
            <p>Важные вехи в развитии телефонии включали создание автоматических телефонных станций, развитие теории передачи сигналов и появление первых электронных усилителей. Радиосвязь, в свою очередь, позволила передавать речь без проводов, что потребовало разработки новых методов модуляции и демодуляции сигналов.</p>
            <div class="kmp12"><strong>Важно:</strong> Именно в рамках развития телефонии были сформулированы первые математические модели речевых сигналов.</div>
        </div>
    </div>
    <div class="002">
        <h3 class="002-title">Появление первых компьютеров и цифровых сигналов</h3>
        <div class="002-card">
            <h4>Теоретические основы цифровизации</h4>
            <p>Переход от аналоговых к цифровым технологиям стал возможен благодаря фундаментальным открытиям в области теории информации и обработки сигналов. Клод Шеннон в 1948 году опубликовал работу "Математическая теория связи", которая заложила основы цифровой передачи информации.</p>
            <p><strong>Ключевые концепции:</strong></p>
            <ul>
                <li>Теорема Котельникова-Шеннона о дискретизации (1933/1949)</li>
                <li>Импульсно-кодовая модуляция (PCM) — Алек Ривз (1937)</li>
                <li>Квантование и кодирование аналоговых сигналов</li>
                <li>Двоичное представление информации</li>
            </ul>
            <p><strong>Пояснение:</strong> Теорема о дискретизации показала, что непрерывный сигнал может быть полностью восстановлен из его дискретных отсчетов, если частота дискретизации превышает удвоенную максимальную частоту в спектре сигнала.</p>
        </div>
        <div class="002-card">
            <h4>Ранние эксперименты с синтезом речи (1930–1960-е)</h4>
            <p>Первые попытки создать искусственную речь предпринимались еще в механическую эпоху, но настоящий прорыв произошел с появлением электронных устройств. В 1939 году на Всемирной выставке в Нью-Йорке компания Bell Labs продемонстрировала VODER (Voice Operating Demonstrator) — первый электронный синтезатор речи, управляемый оператором.</p>
            <p>В 1950-60-х годах появились первые компьютерные системы синтеза речи. В 1961 году физик Джон Ларри Келли-младший и инженер Луис Герстман использовали компьютер IBM 704 для синтеза песни "Daisy Bell" — это была первая песня, спетая компьютером.</p>
            <div class="kmp14"><strong>Пояснение:</strong> Эти ранние эксперименты, хотя и производили довольно примитивную речь, заложили основу для понимания акустических параметров, необходимых для синтеза понятной речи.</div>
        </div>
    </div>
</section>

<section id="3" class="section">
    <h2 class="section-title">1960–1980-е: Зарождение компьютерной лингвистики</h2>
    <div class="001">
        <h3 class="001-title">Первые системы распознавания и синтеза речи</h3>
        <div class="001-card">
            <h4>Пионерские проекты</h4>
            <p>1960-е годы ознаменовались появлением первых практических систем распознавания речи. В 1962 году IBM представила систему "Shoebox", которая могла распознавать 16 слов, произнесенных на английском языке, включая цифры от 0 до 9 и простые арифметические команды.</p>
            <p>Параллельно велись работы в СССР. В 1968 году в Институте кибернетики АН УССР под руководством академика В.М. Глушкова была создана система распознавания изолированных слов. В Японии компания NEC разработала систему распознавания гласных звуков.</p>
            <p><strong>Основные исследовательские центры:</strong></p>
            <ul>
                <li>Bell Labs (США) — фундаментальные исследования в области акустики речи</li>
                <li>MIT Lincoln Laboratory (США) — системы распознавания для военных применений</li>
                <li>Институт проблем передачи информации АН СССР — теоретические основы обработки речи</li>
                <li>Cambridge University (Великобритания) — исследования в области фонетики и акустики</li>
            </ul>
            <p><strong>Пояснение:</strong> Большинство ранних систем были ориентированы на распознавание изолированных слов одного диктора и требовали предварительного обучения.</p>
        </div>
        <div class="001-card">
            <h4>Роль военных и научных лабораторий</h4>
            <p>Значительная часть финансирования исследований в области обработки речи в этот период поступала от военных ведомств. В США агентство DARPA (Defense Advanced Research Projects Agency) запустило в 1971 году пятилетнюю программу Speech Understanding Research (SUR) с бюджетом 15 миллионов долларов.</p>
            <p>Целью программы было создание систем, способных понимать связную речь с словарем в 1000 слов. Хотя полностью достичь поставленных целей не удалось, программа привела к важным научным достижениям и созданию систем HARPY (Carnegie Mellon University) и HEARSAY-II, которые стали прототипами для будущих разработок.</p>
            <div class="kmp11"><strong>Примечание:</strong> Военный интерес к технологиям распознавания речи был связан с потребностью в системах голосового управления в условиях, когда руки оператора заняты.</div>
        </div>
    </div>
    <div class="002">
        <h3 class="002-title">Развитие алгоритмов</h3>
        <div class="002-card">
            <h4>Скрытые марковские модели (HMM)</h4>
            <p>Одним из ключевых прорывов в области распознавания речи стало применение скрытых марковских моделей. Хотя математическая теория была разработана Андреем Марковым еще в начале XX века, применение HMM для распознавания речи началось в 1970-х годах благодаря работам Леонарда Баума и его коллег в Institute for Defense Analyses.</p>
            <p>HMM позволили эффективно моделировать временную изменчивость речевых сигналов и стали доминирующим подходом в системах распознавания речи на несколько десятилетий. Основная идея заключается в представлении речи как последовательности скрытых состояний, каждое из которых генерирует наблюдаемые акустические признаки.</p>
            <div class="table-kmp">
                <table class="table">
                    <thead>
                        <tr>
                            <th>Компонент HMM</th>
                            <th>Описание</th>
                        </tr>
                    </thead>
                    <tr>
                        <td>Состояния</td>
                        <td>Скрытые состояния, соответствующие фонемам или их частям</td>
                    </tr>
                    <tr>
                        <td>Переходы</td>
                        <td>Вероятности перехода между состояниями</td>
                    </tr>
                    <tr>
                        <td>Эмиссии</td>
                        <td>Вероятности генерации акустических признаков в каждом состоянии</td>
                    </tr>
                    <tr>
                        <td>Начальные вероятности</td>
                        <td>Вероятности начала последовательности с определенного состояния</td>
                    </tr>
                </table>
            </div>
            <div class="kmp12"><strong>Важно:</strong> Алгоритм Витерби, разработанный в 1967 году, стал основным методом декодирования HMM в системах распознавания речи.</div>
        </div>
        <div class="002-card">
            <h4>Динамическое программирование и DTW</h4>
            <p>Другим важным алгоритмическим подходом стало динамическое программирование, в частности, алгоритм динамической трансформации времени (Dynamic Time Warping, DTW). Этот метод, предложенный в начале 1970-х годов, позволял сравнивать речевые образцы разной длительности путем нелинейного выравнивания временных последовательностей.</p>
            <p>DTW был особенно эффективен для систем распознавания изолированных слов и широко использовался в коммерческих системах 1980-х годов. Алгоритм находил оптимальное соответствие между эталонным и тестовым образцами речи, компенсируя различия в скорости произнесения.</p>
            <p><strong>Пояснение:</strong> Хотя DTW был вычислительно проще HMM, он требовал хранения большого количества эталонных образцов и плохо масштабировался для больших словарей.</p>
        </div>
    </div>
    <div class="003">
        <h3 class="003-title">Первые коммерческие приложения</h3>
        <div class="003-card">
            <h4>Системы для людей с ограниченными возможностями</h4>
            <p>Одними из первых практических применений технологий распознавания и синтеза речи стали системы помощи людям с ограниченными возможностями. В 1976 году Рэймонд Курцвейл представил Kurzweil Reading Machine — устройство, которое могло сканировать печатный текст и преобразовывать его в синтезированную речь для слепых и слабовидящих людей.</p>
            <p>В 1980-х годах появились первые системы голосового управления компьютером для людей с ограниченной подвижностью. Эти системы, хотя и имели ограниченный словарь и требовали тщательной настройки под конкретного пользователя, открыли новые возможности для интеграции людей с инвалидностью в цифровое общество.</p>
            <div class="kmp14"><strong>Пояснение:</strong> Высокая стоимость и ограниченные возможности ранних систем компенсировались их огромной ценностью для пользователей с особыми потребностями.</div>
        </div>
    </div>
</section>

<section id="4" class="section">
    <h2 class="section-title">1990–2000-е: Эпоха цифровых технологий</h2>
    <div class="001">
        <h3 class="001-title">Распознавание речи</h3>
        <div class="001-card">
            <h4>Появление массовых систем</h4>
            <p>1990-е годы ознаменовались переходом технологий распознавания речи из исследовательских лабораторий в массовый рынок. В 1990 году компания Dragon Systems выпустила Dragon Dictate — первую коммерческую систему распознавания речи для персональных компьютеров стоимостью $9000. Система могла распознавать до 30000 слов, но требовала паузы между словами.</p>
            <p>Настоящий прорыв произошел в 1997 году с выпуском Dragon NaturallySpeaking — первой системы непрерывного распознавания речи для массового рынка. IBM представила конкурирующий продукт ViaVoice, а Microsoft начала интегрировать технологии распознавания речи в Windows.</p>
            <p><strong>Ключевые характеристики систем 1990-х:</strong></p>
            <ul>
                <li>Словарь от 30000 до 60000 слов</li>
                <li>Точность распознавания 90-95% после обучения</li>
                <li>Поддержка непрерывной речи</li>
                <li>Адаптация к голосу пользователя</li>
                <li>Интеграция с офисными приложениями</li>
            </ul>
            <p><strong>Пояснение:</strong> Успех этих систем был обусловлен ростом вычислительной мощности персональных компьютеров и улучшением алгоритмов обработки.</p>
        </div>
        <div class="001-card">
            <h4>Влияние интернета и мультимедиа</h4>
            <p>Распространение интернета и мультимедийных технологий создало новые области применения для распознавания речи. Появились системы голосового поиска, автоматического создания субтитров для видео, голосовые интерфейсы для веб-сайтов. Компании начали использовать технологии распознавания речи в колл-центрах для автоматизации обслуживания клиентов.</p>
            <p>Важным фактором стало создание больших речевых баз данных, доступных через интернет. Проект Linguistic Data Consortium (LDC), основанный в 1992 году, начал собирать и распространять речевые корпуса для исследовательских целей, что ускорило развитие технологий.</p>
            <div class="kmp11"><strong>Примечание:</strong> Стандартизация форматов и протоколов (например, VoiceXML) способствовала интеграции речевых технологий в веб-приложения.</div>
        </div>
    </div>
    <div class="002">
        <h3 class="002-title">Синтез речи</h3>
        <div class="002-card">
            <h4>От роботообразного к естественному звучанию</h4>
            <p>В 1990-х годах произошел качественный скачок в технологиях синтеза речи. Ранние системы, основанные на формантном синтезе или простой конкатенации фонем, производили механическую, "роботообразную" речь. Новые подходы, основанные на конкатенации больших речевых единиц (дифонов, трифонов, слогов), позволили создавать более естественно звучащую речь.</p>
            <p>Компания AT&T разработала систему Festival, которая стала одной из первых открытых платформ для синтеза речи. Microsoft представила технологию SAPI (Speech Application Programming Interface), стандартизировавшую доступ к речевым технологиям в Windows.</p>
            <div class="table-kmp">
                <table class="table">
                    <thead>
                        <tr>
                            <th>Метод синтеза</th>
                            <th>Характеристики</th>
                        </tr>
                    </thead>
                    <tr>
                        <td>Формантный</td>
                        <td>Компактный, гибкий, но неестественное звучание</td>
                    </tr>
                    <tr>
                        <td>Конкатенативный</td>
                        <td>Естественное звучание, но требует больших баз данных</td>
                    </tr>
                    <tr>
                        <td>Параметрический</td>
                        <td>Баланс между качеством и размером системы</td>
                    </tr>
                </table>
            </div>
            <div class="kmp12"><strong>Важно:</strong> Переход к конкатенативному синтезу потребовал создания больших речевых баз данных с тщательной фонетической разметкой.</div>
        </div>
        <div class="002-card">
            <h4>Применение в GPS и колл-центрах</h4>
            <p>Массовое распространение GPS-навигаторов в конце 1990-х — начале 2000-х годов создало огромный рынок для технологий синтеза речи. Голосовые подсказки стали стандартной функцией навигационных систем, что потребовало разработки специализированных решений для синтеза названий улиц и географических объектов.</p>
            <p>В колл-центрах системы интерактивного голосового ответа (IVR) начали использовать синтез речи для динамического создания сообщений. Это позволило персонализировать обслуживание клиентов и снизить затраты на запись голосовых подсказок.</p>
            <p><strong>Пояснение:</strong> Для навигационных систем были разработаны специальные алгоритмы произношения названий улиц и числительных в различных контекстах.</p>
        </div>
    </div>
    <div class="003">
        <h3 class="003-title">Корпусная лингвистика</h3>
        <div class="003-card">
            <h4>Создание речевых корпусов</h4>
            <p>Развитие статистических методов в обработке речи потребовало создания больших аннотированных речевых корпусов. В 1990-х годах были созданы фундаментальные корпуса, которые до сих пор используются в исследованиях: TIMIT (фонетически сбалансированный корпус американского английского), Switchboard (телефонные разговоры), Wall Street Journal (чтение газетных текстов).</p>
            <p>Создание корпусов стало систематической деятельностью, включающей тщательное планирование, запись, транскрибирование и аннотацию речевых данных. Появились специализированные инструменты для работы с речевыми корпусами, такие как Praat и WaveSurfer.</p>
            <p><strong>Типы речевых корпусов:</strong></p>
            <ul>
                <li>Фонетические корпуса для изучения звуков речи</li>
                <li>Диалоговые корпуса для разработки разговорных систем</li>
                <li>Эмоциональные корпуса для анализа эмоций в речи</li>
                <li>Многоязычные корпуса для кросс-лингвистических исследований</li>
                <li>Спонтанная речь vs. читаемая речь</li>
            </ul>
            <div class="kmp14"><strong>Пояснение:</strong> Качество и размер речевых корпусов напрямую влияют на производительность систем распознавания и синтеза речи.</div>
        </div>
    </div>
</section>

<section id="5" class="section">
    <h2 class="section-title">2010-е: Эпоха глубокого обучения и нейросетей</h2>
    <div class="001">
        <h3 class="001-title">Прорыв в распознавании речи</h3>
        <div class="001-card">
            <h4>Революция глубокого обучения</h4>
            <p>2010-е годы ознаменовались революционным прорывом в области распознавания речи благодаря применению глубоких нейронных сетей. В 2011 году исследователи из Microsoft Research продемонстрировали, что глубокие нейронные сети (DNN) могут значительно превзойти традиционные GMM-HMM системы. Это привело к снижению частоты ошибок распознавания на 20-30%.</p>
            <p>Ключевым фактором успеха стало использование больших объемов данных и мощных графических процессоров (GPU) для обучения сетей. Появление новых архитектур, таких как рекуррентные нейронные сети (RNN) и сети с долгой краткосрочной памятью (LSTM), позволило лучше моделировать временные зависимости в речи.</p>
            <p><strong>Эволюция архитектур нейросетей:</strong></p>
            <ul>
                <li>DNN (2011) — первые глубокие сети для акустического моделирования</li>
                <li>RNN/LSTM (2013) — моделирование временных последовательностей</li>
                <li>CTC (2014) — end-to-end обучение без выравнивания</li>
                <li>Attention механизмы (2015) — фокусировка на важных частях входа</li>
                <li>Transformer (2017) — параллельная обработка последовательностей</li>
            </ul>
            <p><strong>Пояснение:</strong> Каждая новая архитектура решала специфические проблемы предыдущих подходов и улучшала качество распознавания.</p>
        </div>
        <div class="001-card">
            <h4>Голосовые ассистенты нового поколения</h4>
            <p>Применение глубокого обучения привело к появлению голосовых ассистентов нового поколения. Apple Siri (2011), Google Assistant (2016), Amazon Alexa (2014) и Microsoft Cortana (2014) стали массовыми продуктами, изменившими способ взаимодействия людей с технологиями.</p>
            <p>Эти системы объединили распознавание речи, обработку естественного языка и синтез речи в единые интеллектуальные интерфейсы. Они могли не только распознавать команды, но и вести диалог, учитывать контекст, персонализировать ответы.</p>
            <div class="table-kmp
                    <thead>
                        <tr>
                            <th>Ассистент</th>
                            <th>Особенности</th>
                        </tr>
                    </thead>
                    <tr>
                        <td>Siri</td>
                        <td>Интеграция с экосистемой Apple, естественный диалог</td>
                    </tr>
                    <tr>
                        <td>Google Assistant</td>
                        <td>Мощный поиск, контекстное понимание, мультиязычность</td>
                    </tr>
                    <tr>
                        <td>Alexa</td>
                        <td>Умный дом, навыки сторонних разработчиков</td>
                    </tr>
                    <tr>
                        <td>Cortana</td>
                        <td>Интеграция с Windows и Office, продуктивность</td>
                    </tr>
                </table>
            </div>
            <div class="kmp12"><strong>Важно:</strong> Успех голосовых ассистентов был обусловлен не только качеством распознавания, но и интеграцией с облачными сервисами и экосистемами устройств.</div>
        </div>
    </div>
    <div class="002">
        <h3 class="002-title">Синтез речи на основе нейросетей</h3>
        <div class="002-card">
            <h4>WaveNet и революция в качестве синтеза</h4>
            <p>В 2016 году компания DeepMind представила WaveNet — генеративную модель для синтеза речи, основанную на глубоких нейронных сетях. WaveNet генерировала речь непосредственно на уровне звуковых волн, предсказывая каждый следующий семпл аудиосигнала. Это позволило достичь беспрецедентного качества синтезированной речи, практически неотличимой от человеческой.</p>
            <p>Хотя первоначальная версия WaveNet была слишком медленной для практического применения, последующие оптимизации (Parallel WaveNet) сделали технологию пригодной для использования в реальном времени. Google интегрировал WaveNet в свой сервис Google Assistant, значительно улучшив качество синтезированной речи.</p>
            <p><strong>Пояснение:</strong> WaveNet использует причинно-следственные свертки и остаточные связи для моделирования долгосрочных зависимостей в аудиосигнале.</p>
        </div>
        <div class="002-card">
            <h4>Tacotron и end-to-end синтез</h4>
            <p>В 2017 году Google представил Tacotron — систему синтеза речи, которая напрямую преобразовывала текст в спектрограммы без необходимости в сложной лингвистической обработке. Tacotron 2, представленный в 2018 году, объединил seq2seq архитектуру с WaveNet вокодером, достигнув качества синтеза, сравнимого с профессиональными дикторами.</p>
            <p>Эти системы продемонстрировали преимущества end-to-end подхода, где единая нейронная сеть обучается преобразовывать текст в речь без явного моделирования промежуточных представлений. Это упростило разработку систем для новых языков и голосов.</p>
            <div class="kmp11"><strong>Примечание:</strong> End-to-end системы требуют больших объемов высококачественных данных для обучения, но производят более естественную речь.</div>
        </div>
        <div class="002-card">
            <h4>VITS и современные подходы</h4>
            <p>Variational Inference with adversarial learning for end-to-end Text-to-Speech (VITS), представленный в 2021 году, объединил преимущества различных подходов: вариационные автоэнкодеры, нормализующие потоки и состязательное обучение. VITS может генерировать высококачественную речь в реальном времени, что делает его практичным для широкого спектра приложений.</p>
            <p>Современные системы синтеза речи способны не только генерировать естественно звучащую речь, но и контролировать различные аспекты: эмоции, стиль произношения, скорость речи, интонацию. Это открывает новые возможности для создания выразительных голосовых интерфейсов.</p>
            <div class="kmp14"><strong>Пояснение:</strong> VITS и подобные системы представляют текущее состояние искусства в синтезе речи, достигая баланса между качеством и скоростью генерации.</div>
        </div>
    </div>
    <div class="003">
        <h3 class="003-title">Приложения в лингвистике</h3>
        <div class="003-card">
            <h4>Анализ диалектов и социолингвистика</h4>
            <p>Современные технологии обработки речи открыли новые возможности для лингвистических исследований. Автоматические системы анализа речи позволяют обрабатывать большие объемы данных для изучения диалектных вариаций, социолингвистических паттернов и языковых изменений.</p>
            <p>Исследователи используют нейросетевые модели для автоматической классификации диалектов, анализа фонетических вариаций, изучения просодических особенностей различных социальных групп. Это позволяет проводить масштабные исследования, которые были бы невозможны при ручной обработке данных.</p>
            <p><strong>Применения в социолингвистике:</strong></p>
            <ul>
                <li>Автоматическое определение региональных акцентов</li>
                <li>Анализ гендерных различий в речи</li>
                <li>Изучение возрастных изменений в произношении</li>
                <li>Исследование кодового переключения в билингвальной речи</li>
                <li>Отслеживание языковых изменений в реальном времени</li>
            </ul>
            <div class="kmp12"><strong>Важно:</strong> Использование автоматических методов требует тщательной валидации результатов и понимания ограничений технологий.</div>
        </div>
        <div class="003-card">
            <h4>Сохранение исчезающих языков</h4>
            <p>Технологии обработки речи играют критическую роль в документировании и сохранении исчезающих языков. Автоматические системы транскрипции и анализа помогают лингвистам быстрее обрабатывать полевые записи, создавать словари и грамматики.</p>
            <p>Проекты по созданию систем распознавания и синтеза речи для малоресурсных языков способствуют их ревитализации. Даже с ограниченными данными современные методы переноса обучения позволяют создавать базовые системы обработки речи, которые могут использоваться в образовательных целях.</p>
            <p><strong>Пояснение:</strong> Разработка технологий для исчезающих языков требует тесного сотрудничества между лингвистами, носителями языка и специалистами по обработке речи.</p>
        </div>
    </div>
</section>

<section id="6" class="section">
    <h2 class="section-title">Современные вызовы и достижения</h2>
    <div class="001">
        <h3 class="001-title">Мультимодальные системы</h3>
        <div class="001-card">
            <h4>Интеграция речи с другими модальностями</h4>
            <p>Современные системы искусственного интеллекта все чаще объединяют обработку речи с анализом других типов данных: видео, текста, жестов. Мультимодальные модели могут использовать визуальную информацию для улучшения распознавания речи в шумных условиях, анализировать эмоции по совокупности голоса и мимики, генерировать более точные субтитры с учетом контекста видео.</p>
            <p>Примером такой интеграции являются системы автоматического перевода в реальном времени, которые учитывают не только речь, но и визуальный контекст, жесты говорящего, презентационные материалы. Это позволяет создавать более точные и контекстуально релевантные переводы.</p>
            <p><strong>Области применения мультимодальных систем:</strong></p>
            <ul>
                <li>Видеоконференции с автоматическим переводом и субтитрами</li>
                <li>Виртуальные ассистенты, понимающие жесты и мимику</li>
                <li>Системы помощи людям с нарушениями слуха</li>
                <li>Анализ невербальной коммуникации в психологии</li>
                <li>Улучшенное распознавание речи по движениям губ</li>
            </ul>
            <p><strong>Пояснение:</strong> Мультимодальный подход позволяет системам лучше понимать намерения пользователя и контекст коммуникации.</p>
        </div>
        <div class="001-card">
            <h4>Архитектуры трансформеров в мультимодальных задачах</h4>
            <p>Архитектура трансформеров, изначально разработанная для обработки текста, показала выдающиеся результаты в мультимодальных задачах. Модели типа CLIP (Contrastive Language-Image Pre-training) и их аудио-версии научились связывать речь, текст и изображения в едином семантическом пространстве.</p>
            <p>Это привело к появлению систем, способных генерировать описания изображений по голосовым запросам, искать видео по речевому содержанию, создавать иллюстрации к аудиокнигам. Унифицированные представления различных модальностей открывают путь к более естественному человеко-машинному взаимодействию.</p>
            <div class="kmp11"><strong>Примечание:</strong> Обучение мультимодальных моделей требует огромных вычислительных ресурсов и тщательно подобранных датасетов.</div>
        </div>
    </div>
    <div class="002">
        <h3 class="002-title">Этика и безопасность</h3>
        <div class="002-card">
            <h4>Проблема Deepfake и синтетической речи</h4>
            <p>Развитие технологий синтеза речи привело к появлению возможности создавать убедительные подделки голоса любого человека. Технологии deepfake audio могут использоваться для мошенничества, дезинформации, кибербуллинга. В 2019 году был зафиксирован первый случай успешного мошенничества с использованием синтезированного голоса CEO компании, что привело к краже $243,000.</p>
            <p>В ответ на эти угрозы разрабатываются технологии детекции синтетической речи. Исследователи создают системы, способные определять артефакты, характерные для синтезированной речи, даже когда она звучит естественно для человеческого уха.</p>
            <div class="table-kmp">
                <table class="table">
                    <thead>
                        <tr>
                            <th>Риск</th>
                            <th>Меры противодействия</th>
                        </tr>
                    </thead>
                    <tr>
                        <td>Голосовое мошенничество</td>
                        <td>Многофакторная аутентификация, анализ поведенческих паттернов</td>
                    </tr>
                    <tr>
                        <td>Дезинформация</td>
                        <td>Системы верификации аудиоконтента, блокчейн для подтверждения подлинности</td>
                    </tr>
                    <tr>
                        <td>Нарушение приватности</td>
                        <td>Законодательное регулирование, технические средства защиты</td>
                    </tr>
                    <tr>
                        <td>Кража голосовой идентичности</td>
                        <td>Водяные знаки в синтетической речи, биометрическая защита</td>
                    </tr>
                </table>
            </div>
            <div class="kmp12"><strong>Важно:</strong> Развитие технологий синтеза речи должно сопровождаться разработкой этических стандартов и технических средств защиты.</div>
        </div>
        <div class="002-card">
            <h4>Защита данных и конфиденциальность</h4>
            <p>Голосовые ассистенты и системы распознавания речи собирают огромные объемы персональных данных. Записи голоса могут содержать чувствительную информацию: медицинские данные, финансовые сведения, личные разговоры. Утечки таких данных могут иметь серьезные последствия для пользователей.</p>
              </div>
    </div>
</section>
                
<section id="7" class="section">
  <h2 class="section-title">Будущее цифровизации речи</h2>

  <div class="001">
    <h3 class="001-title">Персонализация речевых технологий</h3>
    <div class="001-card">
      <h4>Что такое персонализация речи?</h4>
      <p>Персонализация речи — это адаптация речевых технологий под индивидуальные особенности пользователя: тембр голоса, скорость речи, лексикон, акцент и даже эмоциональную окраску. Современные системы распознавания и синтеза речи учатся "подстраиваться" под пользователя, улучшая точность и естественность взаимодействия.</p>
      <p><strong>Примеры персонализации:</strong></p>
      <ul>
        <li>Голосовые помощники, запоминающие предпочтения пользователя (например, Siri, Google Assistant).</li>
        <li>Адаптивные системы синтеза речи, имитирующие голос конкретного человека.</li>
        <li>Речевые интерфейсы для людей с особенностями речи (например, для людей с ДЦП или после инсульта).</li>
      </ul>
      <p><strong>Пояснение:</strong> Персонализация не только повышает удобство, но и расширяет доступность технологий для людей с ограниченными возможностями.</p>
    </div>
  </div>

  <div class="001">
    <h3 class="001-title">Адаптивные интерфейсы: как ИИ учится общаться</h3>
    <div class="001-card">
      <h4>Адаптивные интерфейсы и их роль</h4>
      <p>Адаптивные интерфейсы — это системы, которые изменяют свой способ взаимодействия с пользователем в зависимости от контекста, цели общения и даже эмоционального состояния. Например, голосовой помощник может переключаться с формального тона на дружеский, если пользователь расстроен.</p>
      <p><strong>Ключевые технологии:</strong></p>
      <ul>
        <li>Машинное обучение для анализа контекста диалога.</li>
        <li>Обработка естественного языка (NLP) для понимания намерений пользователя.</li>
        <li>Эмоциональный ИИ (Affective Computing) для распознавания эмоций по голосу.</li>
      </ul>
      <p><strong>Пояснение:</strong> Адаптивные интерфейсы делают общение с машинами более естественным и эффективным, сокращая разрыв между человеком и технологией.</p>
    </div>
  </div>

  <div class="001">
    <h3 class="001-title">Взаимодействие с ИИ: этика и перспективы</h3>
    <div class="001-card">
      <h4>Этические вызовы и возможности</h4>
      <p>Разработчики и лингвисты должны совместно работать над созданием этичных и безопасных речевых технологий.</p>
    </div>
  </div>

  <div class="table-kmp">
    <table class="table">
      <thead>
        <tr>
          <th>Технология</th>
          <th>Пример применения</th>
          <th>Перспективы развития</th>
        </tr>
      </thead>
      <tr>
        <td>Персонализация речи</td>
        <td>Голосовые помощники, адаптивные синтезаторы</td>
        <td>Индивидуальные голосовые профили для всех пользователей</td>
      </tr>
      <tr>
        <td>Адаптивные интерфейсы</td>
        <td>Чат-боты, голосовые меню</td>
        <td>Контекстно-зависимое общение с ИИ</td>
      </tr>
      <tr>
        <td>Эмоциональный ИИ</td>
        <td>Распознавание эмоций по голосу</td>
        <td>Эмпатичные виртуальные собеседники</td>
      </tr>
    </table>
  </div>

    <div class="kmp14"><strong>Важно:</strong> Для углубленного изучения рекомендуется обратиться к материала конференций по речевым технологиям, NLP и Affective Computing.</div>
  
</section>

			
<footer class="footer">
<div class="container">
<p>© 2025 | kmp | CC BY-NC-SA 4.0<br>
Разработано для студентов БрГУ имени А.С. Пушкина</p>
</div>
</footer>
<div style="position: fixed; bottom: 10px; color: #777777; right: 30px; opacity: 0.3; font-size: 14px;">kmp+</div>
    <script>
        // Функция для плавной прокрутки к sectionу
        function scrollToSection(sectionId) {
            const section = document.getElementById(sectionId);
            const menuHeight = document.querySelector('.menu').offsetHeight;
            
            window.scrollTo({
                top: section.offsetTop - menuHeight - 20,
                behavior: 'smooth'
            });
        }

        // Функция для переключения темы
        document.getElementById('themeToggle').addEventListener('click', function() {
            const currentTheme = document.documentElement.getAttribute('data-theme');
            const newTheme = currentTheme === 'dark' ? 'light' : 'dark';
            
            document.documentElement.setAttribute('data-theme', newTheme);
            this.textContent = newTheme === 'dark' ? '🌙' : '☀️';
        });

        // Анимация появления секций при прокрутке
        document.addEventListener('DOMContentLoaded', function() {
            const sections = document.querySelectorAll('.section');
            
            const observerOptions = {
                root: null,
                rootMargin: '0px',
                threshold: 0.1
            };
            
            const observer = new IntersectionObserver(function(entries, observer) {
                entries.forEach(entry => {
                    if (entry.isIntersecting) {
                        entry.target.classList.add('fade-in');
                        observer.unobserve(entry.target);
                    }
                });
            }, observerOptions);
            
            sections.forEach(section => {
                section.classList.remove('fade-in');
                observer.observe(section);
            });
        });
    </script>
</body>
</html>
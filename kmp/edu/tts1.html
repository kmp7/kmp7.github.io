<!DOCTYPE html>
<html lang="ru">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>kmp+</title>
    <style>
        /* Основные стили */
        :root {
            --primary-color: #325980;
            --secondary-color: #4CAF50;
            --background-color: #f5f5f5;
            --content-bg: #ffffff;
            --text-color: #333333;
            --header-text-color: #ffffff;
            --menu-bg: #ffffff;
            --menu-shadow: 0 2px 4px rgba(0, 0, 0, 0.1);
            --border-radius: 8px;
			  --accent11: #4caf50;
		--accent12: #4cafff;
		--accent13: #ffaf50;
		--accent14: #821978;
        }

        /* Темная тема */
        [data-theme="dark"] {
            --primary-color: #3e76ad;
            --secondary-color: #388e3c;
            --background-color: #000000;
            --content-bg: #1e1e1e;
            --text-color: #e0e0e0;
            --header-text-color: #ffffff;
            --menu-bg: #000000;
            --menu-shadow: 0 2px 4px rgba(0, 0, 0, 0.3);
        }

        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
            transition: background-color 0.3s, color 0.3s;
        }

        body {
            font-family: 'Roboto', 'Arial', sans-serif;
            line-height: 1.6;
            color: var(--text-color);
            background-color: var(--background-color);
            padding-top: 2px;
        }

        .container {
            max-width: 1200px;
            margin: 0 auto;
            padding: 0 20px;
        }

        header {
            background-color: var(--primary-color);
            color: var(--header-text-color);
            padding: 20px 0;
            text-align: center;
            border-radius: var(--border-radius);
            margin-bottom: 2px;
        }

        h1 {
            font-size: 2.2rem;
            margin-bottom: 10px;
        }

        h2 {
            color: var(--primary-color);
            margin: 25px 0 15px;
            padding-bottom: 8px;
            border-bottom: 2px solid var(--secondary-color);
        }

        h3 {
            color: var(--primary-color);
            margin: 20px 0 10px;
        }

        p {
            margin-bottom: 15px;
        }

        /* Меню навигации */
        .menu {
            background-color: var(--menu-bg);
            padding: 15px 20px;
            border-radius: var(--border-radius);
            margin-bottom: 30px;
            box-shadow: var(--menu-shadow);
            display: flex;
            justify-content: center;
            align-items: center;
            flex-wrap: wrap;
            position: sticky;
            top: 0;
            z-index: 100;
        }

        .menu-buttons {
            display: flex;
            flex-wrap: wrap;
            gap: 10px;
        }
		
		
		.menu-buttons {
    display: flex;
    flex-wrap: wrap;
    gap: 10px;
    justify-content: center; /* Изменено на center */
}

        .menu-btn {
            background-color: var(--primary-color);
            color: white;
            border: none;
            padding: 8px 15px;
            border-radius: 4px;
            cursor: pointer;
            font-size: 0.9rem;
            transition: background-color 0.3s;
        }

        .menu-btn:hover {
            background-color: var(--secondary-color);
        }

        .theme-toggle {
            background: none;
            border: 10px solid transparent;
            font-size: 1.5rem;
            cursor: pointer;
            color: var(--primary-color);
        }

        /* Секции контента */
        .section {
            background-color: var(--content-bg);
            border-radius: var(--border-radius);
            padding: 25px;
            margin-bottom: 30px;
            box-shadow: 0 2px 8px rgba(0, 0, 0, 0.1);
        }

        /* Выделение важного */
        .important {
            background-color: rgba(76, 175, 80, 0.1);
            border-left: 4px solid var(--secondary-color);
            padding: 15px;
            margin: 15px 0;
            border-radius: 0 var(--border-radius) var(--border-radius) 0;
        }

        .note {
            background-color: rgba(50, 89, 128, 0.1);
            border-left: 4px solid var(--primary-color);
            padding: 15px;
            margin: 15px 0;
            border-radius: 0 var(--border-radius) var(--border-radius) 0;
        }

        /* Таблицы */
        table {
            width: 100%;
            border-collapse: collapse;
            margin: 20px 0;
        }

        th, td {
            padding: 12px 15px;
            border: 1px solid #ddd;
            text-align: left;
        }

        th {
            background-color: var(--primary-color);
            color: white;
        }

        tr:nth-child(even) {
            background-color: rgba(0, 0, 0, 0.03);
        }

        /* Списки */
        ul, ol {
            padding-left: 25px;
            margin-bottom: 15px;
        }

        li {
            margin-bottom: 8px;
        }

        /* Адаптивный дизайн */
        @media (max-width: 768px) {
            h1 {
                font-size: 1.8rem;
            }
            
            h2 {
                font-size: 1.5rem;
            }
            
            .menu {
                flex-direction: column;
                gap: 15px;
            }
            
            .menu-buttons {
                width: 100%;
                justify-content: center;
            }
            
            .theme-toggle {
                margin-top: 10px;
            }
            
            .section {
                padding: 15px;
            }
        }

        /* Анимации */
        @keyframes fadeIn {
            from { opacity: 0; }
            to { opacity: 1; }
        }

        .fade-in {
            animation: fadeIn 0.5s ease-in;
        }

        footer {
            text-align: center;
            padding: 20px 0;
            margin-top: 40px;
            font-size: 0.9rem;
        }
		
					.kmp11, .example {
      background: rgba(76, 175, 80, 0.1);
      border-left: 4px solid var(--accent11);
      padding: 10px 15px;
      margin: 15px 0;
      border-radius: 4px;
    }

		.kmp12, .example {
      background: rgba(95, 182, 237, 0.1);
      border-left: 4px solid var(--accent12);
      padding: 10px 15px;
      margin: 15px 0;
      border-radius: 4px;
    }
 
		.kmp13, .example {
      background: rgba(205, 170, 110, 0.1);
      border-left: 4px solid var(--accent13);
      padding: 10px 15px;
      margin: 15px 0;
      border-radius: 4px;
    }

		.kmp14, .example {
      background: rgba(205, 110, 200, 0.1);
      border-left: 4px solid var(--accent14);
      padding: 10px 15px;
      margin: 15px 0;
      border-radius: 4px;
    }
	
	
    </style>
</head>
<body>
    <div class="container">
        <header>
            <h1>TTS (Text-to-speech)</h1>
            <p>Технологии синтеза устной речи (по письменному тексту)</p>
        </header>

        <nav class="menu">
            <div class="menu-buttons">
                <button class="menu-btn" onclick="scrollToSection('1')">Введение</button>
                <button class="menu-btn" onclick="scrollToSection('2')">История</button>
                <button class="menu-btn" onclick="scrollToSection('3')">Структура</button>
                <button class="menu-btn" onclick="scrollToSection('4')">Методы</button>
				<button class="menu-btn" onclick="scrollToSection('5')">Глоссарий</button>
			</div>
            <button class="theme-toggle" id="themeToggle" title="Переключить тему">☀️</button>
        </nav>


<section id="1" class="section"> <h2 class="section-title">Введение в синтез речи по тексту и его лингвистические основы</h2> <div class="001"> <h3 class="001-title">1.1. Основные понятия и определения</h3> <div class="001-card"> <h4>Что такое синтез речи</h4> <p>Синтез речи (Text-to-Speech, TTS) — это процесс автоматического преобразования письменного текста в устную речь с помощью компьютерных технологий. Данный процесс включает анализ текста, определение произношения, интонации и генерацию акустического сигнала.</p> <p>Синтез речи представляет собой междисциплинарную область, объединяющую достижения лингвистики, акустики, обработки сигналов и компьютерных наук.</p> </div> </div>
text

<div class="002">
    <h3 class="002-title">1.2. Лингвистические основы TTS</h3>
    <div class="002-card">
        <h4>Фонетические и фонологические аспекты</h4>
        <p><strong>Ключевые лингвистические компоненты:</strong></p>
        <ul>
            <li><strong>Международный фонетический алфавит (IPA)</strong> — универсальная система транскрипции звуков человеческой речи</li>
            <li><strong>Акустическая фонетика</strong> — изучение физических характеристик речевых звуков (частота, амплитуда, спектр)</li>
            <li><strong>Артикуляционная фонетика</strong> — описание механизмов производства звуков речевым аппаратом</li>
            <li><strong>Фонологические правила</strong> — закономерности звуковых изменений в потоке речи</li>
        </ul>
        
        <h4>Просодические характеристики</h4>
        <p><strong>Основные просодические параметры:</strong></p>
        <ul>
            <li><strong>Интонация</strong> — мелодический рисунок высказывания</li>
            <li><strong>Ритм</strong> — временная организация речи</li>
            <li><strong>Ударение</strong> — выделение слогов и слов</li>
            <li><strong>Темп</strong> — скорость произнесения</li>
            <li><strong>Паузация</strong> — распределение пауз в речевом потоке</li>
        </ul>
        <div class="kmp14"><strong>Пояснение:</strong> Просодия играет критическую роль в естественности синтезированной речи и передаче эмоциональной окраски высказывания.</div>
    </div>
</div>

<div class="003">
    <h3 class="003-title">1.3. Области применения TTS</h3>
    <div class="003-card">
        <h4>Современные приложения синтеза речи</h4>
        <p><strong>Основные сферы использования:</strong></p>
        <ul>
            <li><strong>Голосовые ассистенты</strong> — Siri, Alexa, Google Assistant</li>
            <li><strong>Доступность</strong> — программы чтения с экрана для слабовидящих</li>
            <li><strong>Образование</strong> — обучающие программы, изучение языков</li>
            <li><strong>Навигация</strong> — голосовые подсказки в GPS-системах</li>
            <li><strong>Телекоммуникации</strong> — IVR-системы, автоответчики</li>
            <li><strong>Мультимедиа</strong> — озвучивание книг, новостей, документов</li>
        </ul>
        <div class="kmp11"><strong>Примечание:</strong> Качество современных TTS-систем позволяет создавать речь, практически неотличимую от человеческой.</div>
    </div>
</div>
</section><section id="1" class="section"> <h2 class="section-title">Исторический обзор эволюции TTS-технологий</h2> <div class="001"> <h3 class="001-title">2.1. Ранние механические устройства</h3> <div class="001-card"> <h4>Период XVIII–XIX веков</h4> <p>Первые попытки создания "говорящих машин" были предприняты еще в XVIII веке. В 1769 году Вольфганг фон Кемпелен создал механическое устройство, имитирующее человеческий речевой тракт с помощью мехов, резонаторов и клапанов.</p> <p>В XIX веке Александр Грэхем Белл и его отец разработали "Visible Speech" — систему визуального представления звуков речи, что заложило основы для понимания акустических свойств речевых сигналов.</p> <div class="kmp14"><strong>Пояснение:</strong> Эти ранние эксперименты помогли понять основные принципы артикуляции и акустики речи.</div> </div> </div>
text

<div class="002">
    <h3 class="002-title">2.2. Эра электронного синтеза</h3>
    <div class="002-card">
        <h4>1930–1970-е годы</h4>
        <p><strong>Ключевые вехи развития:</strong></p>
        <ul>
            <li><strong>1939</strong> — VODER (Bell Labs) — первый электронный синтезатор речи</li>
            <li><strong>1950-е</strong> — разработка формантных синтезаторов</li>
            <li><strong>1961</strong> — компьютерная песня "Daisy Bell" (IBM 7094)</li>
            <li><strong>1968</strong> — первый полный параметрический синтезатор (Японская NTT)</li>
        </ul>
        
        <h4>Переход к цифровым системам (1970-е)</h4>
        <p>В 1970-х годах появились первые полностью цифровые системы синтеза речи, использующие правила преобразования текста в фонемы и акустические параметры. Системы Klatt (1980) и DECtalk стали стандартом для коммерческих приложений.</p>
    </div>
</div>

<div class="003">
    <h3 class="003-title">2.3. Статистические методы</h3>
    <div class="003-card">
        <h4>1990–2000-е годы</h4>
        <p>Переход от детерминированных правил к вероятностным моделям ознаменовал новую эру в синтезе речи. Скрытые марковские модели (HMM) позволили моделировать вариативность речи и создавать более естественное звучание.</p>
        <p><strong>Основные достижения периода:</strong></p>
        <ul>
            <li><strong>Unit selection synthesis</strong> — выбор оптимальных речевых сегментов из большой базы данных</li>
            <li><strong>HMM-based synthesis</strong> — статистическое моделирование акустических параметров</li>
            <li><strong>Corpus-based approaches</strong> — использование больших речевых корпусов</li>
        </ul>
    </div>
</div>

<div class="004">
    <h3 class="004-title">2.4. Нейросетевая революция</h3>
    <div class="004-card">
        <h4>2010-е годы</h4>
        <p>Внедрение глубоких нейронных сетей кардинально изменило качество синтеза речи. В 2016 году DeepMind представила WaveNet — первую end-to-end нейросетевую модель, генерирующую речь на уровне отдельных семплов.</p>
        <p><strong>Ключевые технологии:</strong></p>
        <ul>
            <li><strong>WaveNet (2016)</strong> — авторегрессионная модель для генерации аудио</li>
            <li><strong>Tacotron (2017)</strong> — seq2seq архитектура для TTS</li>
            <li><strong>WaveGlow (2018)</strong> — flow-based модель вокодера</li>
        </ul>
        <div class="kmp12"><strong>Важно:</strong> Нейросетевые методы позволили достичь качества синтеза, близкого к человеческой речи, но требуют значительных вычислительных ресурсов.</div>
    </div>
</div>
</section><section id="3" class="section"> <h2 class="section-title">Структура систем синтеза речи</h2> <div class="001"> <h3 class="001-title">3.1. Архитектура TTS-систем</h3> <div class="001-card"> <h4>Общая структура системы</h4> <p>Современная TTS-система состоит из двух основных блоков: фронт-энд (front-end) для обработки текста и бэк-энд (back-end) для генерации звука. Между ними находится промежуточное представление в виде лингвистических и акустических признаков.</p> <p><strong>Основные этапы обработки:</strong></p> <ul> <li><strong>Входной текст</strong> → Фронт-энд → <strong>Лингвистическое представление</strong></li> <li><strong>Лингвистическое представление</strong> → Акустическая модель → <strong>Акустические параметры</strong></li> <li><strong>Акустические параметры</strong> → Вокодер → <strong>Аудиосигнал</strong></li> </ul> </div> </div>
text

<div class="002">
    <h3 class="002-title">3.2. Фронт-энд обработка</h3>
    <div class="002-card">
        <h4>Текстовая нормализация</h4>
        <p>Процесс преобразования "сырого" текста в нормализованную форму, готовую для фонетического анализа.</p>
        <p><strong>Основные задачи нормализации:</strong></p>
        <ul>
            <li><strong>Расшифровка аббревиатур</strong> — NASA → "наса" или "эн-эй-эс-эй"</li>
            <li><strong>Обработка чисел</strong> — 2024 → "две тысячи двадцать четыре"</li>
            <li><strong>Интерпретация символов</strong> — $ → "доллар", % → "процент"</li>
            <li><strong>Обработка дат и времени</strong> — 15:30 → "пятнадцать тридцать"</li>
            <li><strong>Разрешение омографов</strong> — "зáмок" vs "замóк"</li>
        </ul>
        
        <h4>Графемно-фонемное преобразование (G2P)</h4>
        <p>Конверсия нормализованного текста в последовательность фонем — минимальных звуковых единиц языка.</p>
        <p><strong>Методы G2P преобразования:</strong></p>
        <ul>
            <li><strong>Словарный подход</strong> — использование фонетических словарей</li>
            <li><strong>Правиловый подход</strong> — применение лингвистических правил</li>
            <li><strong>Статистический подход</strong> — машинное обучение на размеченных данных</li>
            <li><strong>Гибридный подход</strong> — комбинация методов</li>
        </ul>
        <div class="kmp14"><strong>Пояснение:</strong> Для русского языка G2P относительно прямолинеен благодаря фонетическому принципу орфографии, но требует учета редукции гласных и ассимиляции согласных.</div>
    </div>
</div>

<div class="003">
    <h3 class="003-title">3.3. Просодическое моделирование</h3>
    <div class="003-card">
        <h4>Генерация просодических параметров</h4>
        <p>Просодическая модель определяет супрасегментные характеристики речи, которые накладываются на последовательность фонем.</p>
        <p><strong>Моделируемые параметры:</strong></p>
        <ul>
            <li><strong>F0 (основная частота)</strong> — контур интонации</li>
            <li><strong>Длительность</strong> — продолжительность фонем и пауз</li>
            <li><strong>Энергия</strong> — громкость и акцентуация</li>
            <li><strong>Спектральные характеристики</strong> — тембр и качество голоса</li>
        </ul>
        
        <h4>Лингвистический анализ для просодии</h4>
        <p><strong>Извлекаемые признаки:</strong></p>
        <ul>
            <li><strong>Синтаксическая структура</strong> — границы фраз и предложений</li>
            <li><strong>Часть речи (POS)</strong> — для определения ударных слов</li>
            <li><strong>Семантические роли</strong> — фокус и тема высказывания</li>
            <li><strong>Пунктуация</strong> — индикаторы пауз и интонации</li>
        </ul>
    </div>
</div>

<div class="004">
    <h3 class="004-title">3.4. Бэк-энд компоненты</h3>
    <div class="004-card">
        <h4>Акустическое моделирование</h4>
        <p>Преобразование лингвистических и просодических признаков в акустические параметры, представляющие речевой сигнал.</p>
        <p><strong>Типы акустических представлений:</strong></p>
        <ul>
            <li><strong>Мел-спектрограммы</strong> — частотно-временное представление</li>
            <li><strong>MFCC</strong> — мел-частотные кепстральные коэффициенты</li>
            <li><strong>F0 и апериодичность</strong> — для параметрических вокодеров</li>
            <li><strong>Линейные спектральные пары (LSP)</strong> — компактное представление спектра</li>
        </ul>
        
        <h4>Вокодер</h4>
        <p>Финальный компонент, преобразующий акустические параметры в аудиосигнал.</p>
        <p><strong>Типы вокодеров:</strong></p>
        <ul>
            <li><strong>Параметрические</strong> — STRAIGHT, WORLD</li>
            <li><strong>Нейросетевые</strong> — WaveNet, WaveGlow, HiFi-GAN</li>
            <li><strong>Гибридные</strong> — комбинация методов</li>
        </ul>
        <div class="kmp12"><strong>Важно:</strong> Качество вокодера критически влияет на естественность финального аудио.</div>
    </div>
</div>
</section><section id="4" class="section"> <h2 class="section-title">Традиционные методы синтеза речи</h2> <div class="001"> <h3 class="001-title">4.1. Конкатенативный синтез</h3> <div class="001-card"> <h4>Принцип работы</h4> <p>Конкатенативный синтез основан на соединении (конкатенации) предварительно записанных сегментов естественной речи. Качество синтеза напрямую зависит от размера и разнообразия речевой базы данных.</p> <p><strong>Типы речевых единиц:</strong></p> <ul> <li><strong>Дифоны</strong> — переходы между фонемами (наиболее распространены)</li> <li><strong>Трифоны</strong> — тройки фонем с учетом контекста</li> <li><strong>Полуслоги</strong> — от начала слога до центра гласного</li> <li><strong>Слоги</strong> — полные слоговые единицы</li> <li><strong>Слова и фразы</strong> — для ограниченного словаря</li> </ul>
text

        <h4>Unit Selection Synthesis</h4>
        <p>Продвинутая форма конкатенативного синтеза, где из большой базы данных выбираются оптимальные сегменты на основе множества критериев.</p>
        <p><strong>Критерии выбора единиц:</strong></p>
        <ul>
            <li><strong>Целевая стоимость (Target Cost)</strong> — соответствие лингвистическим требованиям</li>
            <li><strong>Стоимость соединения (Join Cost)</strong> — плавность стыков между единицами</li>
            <li><strong>Просодическое соответствие</strong> — F0, длительность, энергия</li>
            <li><strong>Спектральная непрерывность</strong> — минимизация артефактов</li>
        </ul>
        <div class="kmp14"><strong>Пояснение:</strong> Unit selection может давать очень естественную речь, но требует огромных баз данных (десятки часов записей) и плохо масштабируется на новые голоса.</div>
    </div>
</div>

<div class="002">
    <h3 class="002-title">4.2. Параметрический синтез</h3>
    <div class="002-card">
        <h4>Формантный синтез</h4>
        <p>Основан на моделировании резонансных частот речевого тракта (формант). Использует упрощенную модель производства речи через источник возбуждения и систему фильтров.</p>
        <p><strong>Управляемые параметры:</strong></p>
        <ul>
            <li><strong>F1, F2, F3</strong> — частоты первых трех формант</li>
            <li><strong>Амплитуды формант</strong> — A1, A2, A3</li>
            <li><strong>Ширина полос формант</strong> — B1, B2, B3</li>
            <li><strong>Основная частота (F0)</strong> — для вокализованных звуков</li>
            <li><strong>Параметры шума</strong> — для невокализованных звуков</li>
        </ul>
        
        <h4>Артикуляторный синтез</h4>
        <p>Моделирует физические процессы производства речи, включая движения артикуляторов (языка, губ, челюсти).</p>
        <p><strong>Моделируемые компоненты:</strong></p>
        <ul>
            <li><strong>Геометрия речевого тракта</strong> — форма и размеры полостей</li>
            <li><strong>Источники звука</strong> — голосовые связки, турбулентность</li>
            <li><strong>Аэродинамика</strong> — поток воздуха и давление</li>
            <li><strong>Акустическое распространение</strong> — резонансы и антирезонансы</li>
        </ul>
        <div class="kmp11"><strong>Примечание:</strong> Параметрический синтез дает полный контроль над характеристиками речи, но звучит менее естественно по сравнению с конкатенативными методами.</div>
    </div>
</div>

<div class="003">
    <h3 class="003-title">4.3. Статистический параметрический синтез</h3>
    <div class="003-card">
        <h4>HMM-based синтез</h4>
        <p>Использует скрытые марковские модели для статистического моделирования акустических параметров речи. Обучается на размеченном речевом корпусе.</p>
        <p><strong>Моделируемые потоки данных:</strong></p>
        <ul>
            <li><strong>Спектральные параметры</strong> — MFCC или LSP коэффициенты</li>
            <li><strong>F0 контур</strong> — логарифм основной частоты</li>
            <li><strong>Длительности</strong> — продолжительность состояний HMM</li>
            <li><strong>Апериодичность</strong> — соотношение шум/тон</li>
        </ul>
        
        <h4>Преимущества и ограничения HMM</h4>
        <p><strong>Преимущества:</strong></p>
        <ul>
            <li>Компактные модели (мегабайты vs гигабайты для unit selection)</li>
            <li>Легкая адаптация к новым голосам и стилям</li>
            <li>Стабильное качество синтеза</li>
            <li>Возможность интерполяции между голосами</li>
        </ul>
        <p><strong>Ограничения:</strong></p>
        <ul>
            <li>Сверхсглаженность (over-smoothing) спектральных параметров</li>
            <li>"Металлическое" звучание из-за упрощенного вокодера</li>
            <li>Потеря тонких деталей естественной речи</li>
        </ul>
        <div class="kmp12"><strong>Важно:</strong> HMM-синтез доминировал в коммерческих системах 2000-х годов благодаря хорошему балансу качества и вычислительной эффективности.</div>
    </div>
</div>

<div class="004">
    <h3 class="004-title">4.4. Гибридные подходы</h3>
    <div class="004-card">
        <h4>Комбинирование методов</h4>
        <p>Гибридные системы объединяют преимущества различных подходов для достижения лучшего качества синтеза.</p>
        <p><strong>Примеры гибридных архитектур:</strong></p>
        <ul>
            <li><strong>HMM + Unit Selection</strong> — статистический выбор оптимальных единиц</li>
            <li><strong>Parametric + Concatenative</strong> — параметрическая модификация записанных сегментов</li>
            <li><strong>Rule-based + Statistical</strong> — правила для редких случаев, статистика для основного потока</li>
        </ul>
        
        <h4>Лингвистические вызовы традиционных методов</h4>
        <p><strong>Основные проблемы:</strong></p>
        <ul>
            <li><strong>Коартикуляция</strong> — взаимное влияние соседних звуков</li>
            <li><strong>Просодическая вариативность</strong> — множество способов интонирования</li>
            <li><strong>Контекстная зависимость</strong> — изменение произношения в зависимости от окружения</li>
            <li><strong>Эмоциональная окраска</strong> — передача эмоций и настроения</li>
            <li><strong>Индивидуальные особенности</strong> — уникальность каждого голоса</li>
        </ul>
        <div class="kmp14"><strong>Пояснение:</strong> Именно сложность моделирования этих лингвистических явлений привела к переходу на нейросетевые методы, способные автоматически извлекать сложные закономерности из данных.</div>
    </div>
</div>
</section><section id="5" class="section"> <h2 class="section-title">Ключевые термины и определения</h2> <div class="001"> <h3 class="001-title">5.1. Основная терминология TTS</h3> <div class="table-kmp"> <table class="table"> <thead> <tr> <th>Английский термин</th> <th>Русский эквивалент</th> <th>Пояснение</th> </tr> </thead> <tbody> <tr> <td>Text-to-Speech (TTS)</td> <td>Синтез речи</td> <td>Преобразование письменного текста в устную речь</td> </tr> <tr> <td>Grapheme</td> <td>Графема</td> <td>Минимальная единица письменной речи (буква или символ)</td> </tr> <tr> <td>Phoneme</td> <td>Фонема</td> <td>Минимальная смыслоразличительная единица звучащей речи</td> </tr> <tr> <td>G2P (Grapheme-to-Phoneme)</td> <td>Графемно-фонемное преобразование</td> <td>Процесс конвертации букв в звуки</td> </tr> <tr> <td>Prosody</td> <td>Просодия</td> <td>Супрасегментные характеристики речи (интонация, ритм, ударение)</td> </tr> <tr> <td>F0 (Fundamental Frequency)</td> <td>Основная частота</td> <td>Частота колебаний голосовых связок, определяющая высоту тона</td> </tr> <tr> <td>Formant</td> <td>Форманта</td> <td>Резонансная частота речевого тракта</td> </tr> <tr> <td>Vocoder</td> <td>Вокодер</td> <td>Устройство или алгоритм синтеза речевого сигнала из параметров</td> </tr> </tbody> </table> </div> </div>
text

<div class="002">
    <h3 class="002-title">5.2. Термины акустического моделирования</h3>
    <div class="table-kmp">
        <table class="table">
            <thead>
                <tr>
                    <th>Английский термин</th>
                    <th>Русский эквивалент</th>
                    <th>Пояснение</th>
                </tr>
            </thead>
            <tbody>
                <tr>
                    <td>Mel-spectrogram</td>
                    <td>Мел-спектрограмма</td>
                    <td>Частотно-временное представление сигнала в мел-шкале</td>
                </tr>
                <tr>
                    <td>MFCC</td>
                    <td>Мел-частотные кепстральные коэффициенты</td>
                    <td>Компактное представление спектра для обработки речи</td>
                </tr>
                <tr>
                    <td>Spectral envelope</td>
                    <td>Спектральная огибающая</td>
                    <td>Контур, описывающий общую форму спектра</td>
                </tr>
                <tr>
                    <td>Pitch contour</td>
                    <td>Контур основного тона</td>
                    <td>Изменение F0 во времени</td>
                </tr>
                <tr>
                    <td>Duration modeling</td>
                    <td>Моделирование длительности</td>
                    <td>Предсказание продолжительности фонем и пауз</td>
                </tr>
                <tr>
                    <td>Coarticulation</td>
                    <td>Коартикуляция</td>
                    <td>Взаимное влияние соседних звуков при произнесении</td>
                </tr>
                <tr>
                    <td>Voice quality</td>
                    <td>Качество голоса</td>
                    <td>Тембральные характеристики, определяющие индивидуальность голоса</td>
                </tr>
            </tbody>
        </table>
    </div>
</div>

<div class="003">
    <h3 class="003-title">5.3. Методы и подходы</h3>
    <div class="table-kmp">
        <table class="table">
            <thead>
                <tr>
                    <th>Английский термин</th>
                    <th>Русский эквивалент</th>
                    <th>Пояснение</th>
                </tr>
            </thead>
            <tbody>
                <tr>
                    <td>Concatenative synthesis</td>
                    <td>Конкатенативный синтез</td>
                    <td>Соединение предварительно записанных речевых сегментов</td>
                </tr>
                <tr>
                    <td>Parametric synthesis</td>
                    <td>Параметрический синтез</td>
                    <td>Генерация речи через управление акустическими параметрами</td>
                </tr>
                <tr>
                    <td>Unit selection</td>
                    <td>Выбор единиц</td>
                    <td>Алгоритм оптимального выбора речевых сегментов из базы</td>
                </tr>
                <tr>
                    <td>HMM (Hidden Markov Model)</td>
                    <td>Скрытая марковская модель</td>
                    <td>Статистическая модель для последовательных данных</td>
                </tr>
                <tr>
                    <td>Diphone</td>
                    <td>Дифон</td>
                    <td>Речевая единица от центра одной фонемы до центра следующей</td>
                </tr>
                <tr>
                    <td>Speech corpus</td>
                    <td>Речевой корпус</td>
                    <td>Размеченная база данных речевых записей</td>
                </tr>
                <tr>
                    <td>Front-end / Back-end</td>
                    <td>Фронт-энд / Бэк-энд</td>
                    <td>Текстовая обработка / Акустическая генерация</td>
                </tr>
            </tbody>
        </table>
    </div>
</div>

<div class="004">
    <h3 class="004-title">5.4. Лингвистические термины</h3>
    <div class="table-kmp">
        <table class="table">
            <thead>
                <tr>
                    <th>Английский термин</th>
                    <th>Русский эквивалент</th>
                    <th>Пояснение</th>
                </tr>
            </thead>
            <tbody>
                <tr>
                    <td>IPA (International Phonetic Alphabet)</td>
                    <td>Международный фонетический алфавит</td>
                    <td>Универсальная система записи звуков человеческой речи</td>
                </tr>
                <tr>
                    <td>POS (Part-of-Speech)</td>
                    <td>Часть речи</td>
                    <td>Грамматическая категория слова</td>
                </tr>
                <tr>
                    <td>Stress pattern</td>
                    <td>Модель ударения</td>
                    <td>Распределение ударных и безударных слогов</td>
                </tr>
                <tr>
                    <td>Intonation pattern</td>
                    <td>Интонационная модель</td>
                    <td>Мелодический рисунок высказывания</td>
                </tr>
                <tr>
                    <td>Syllabification</td>
                    <td>Слогоделение</td>
                    <td>Разбиение слова на слоги</td>
                </tr>
                <tr>
                    <td>Homograph</td>
                    <td>Омограф</td>
                    <td>Слова с одинаковым написанием, но разным произношением</td>
                </tr>
                <tr>
                    <td>Text normalization</td>
                    <td>Нормализация текста</td>
                    <td>Преобразование текста в стандартную форму для обработки</td>
                </tr>
                <tr>
                    <td>Reduction</td>
                    <td>Редукция</td>
                    <td>Ослабление артикуляции безударных гласных</td>
                </tr>
            </tbody>
        </table>
    </div>
    <div class="kmp11"><strong>Примечание:</strong> Данный глоссарий включает основные термины, необходимые для понимания технологий синтеза речи. Для углубленного изучения рекомендуется обращаться к специализированным словарям по фонетике и обработке речи.</div>
</div>
</section>

	
<footer class="footer">
<div class="container">
<p>© 2025 | kmp | CC BY-NC-SA 4.0<br>
Разработано для студентов БрГУ имени А.С. Пушкина</p>
</div>
</footer>
<div style="position: fixed; bottom: 10px; color: #777777; right: 30px; opacity: 0.3; font-size: 14px;">kmp+</div>
    <script>
        // Функция для плавной прокрутки к разделу
        function scrollToSection(sectionId) {
            const section = document.getElementById(sectionId);
            const menuHeight = document.querySelector('.menu').offsetHeight;
            
            window.scrollTo({
                top: section.offsetTop - menuHeight - 20,
                behavior: 'smooth'
            });
        }

        // Функция для переключения темы
        document.getElementById('themeToggle').addEventListener('click', function() {
            const currentTheme = document.documentElement.getAttribute('data-theme');
            const newTheme = currentTheme === 'dark' ? 'light' : 'dark';
            
            document.documentElement.setAttribute('data-theme', newTheme);
            this.textContent = newTheme === 'dark' ? '🌙' : '☀️';
        });

        // Анимация появления секций при прокрутке
        document.addEventListener('DOMContentLoaded', function() {
            const sections = document.querySelectorAll('.section');
            
            const observerOptions = {
                root: null,
                rootMargin: '0px',
                threshold: 0.1
            };
            
            const observer = new IntersectionObserver(function(entries, observer) {
                entries.forEach(entry => {
                    if (entry.isIntersecting) {
                        entry.target.classList.add('fade-in');
                        observer.unobserve(entry.target);
                    }
                });
            }, observerOptions);
            
            sections.forEach(section => {
                section.classList.remove('fade-in');
                observer.observe(section);
            });
        });
    </script>
</body>
</html>
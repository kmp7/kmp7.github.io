<!DOCTYPE html>
<html lang="ru">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>kmp+</title>
    <style>
        /* Основные стили */
        :root {
            --primary-color: #325980;
            --secondary-color: #4CAF50;
            --background-color: #f5f5f5;
            --content-bg: #ffffff;
            --text-color: #333333;
            --header-text-color: #ffffff;
            --menu-bg: #ffffff;
            --menu-shadow: 0 2px 4px rgba(0, 0, 0, 0.1);
            --border-radius: 8px;
			  --accent11: #4caf50;
		--accent11: #4cafff;
		--accent12: #4cafff;
		--accent13: #ffaf50;
		--accent14: #821978;
        }

        /* Темная тема */
        [data-theme="dark"] {
            --primary-color: #3e76ad;
            --secondary-color: #388e3c;
            --background-color: #000000;
            --content-bg: #1e1e1e;
            --text-color: #e0e0e0;
            --header-text-color: #ffffff;
            --menu-bg: #000000;
            --menu-shadow: 0 2px 4px rgba(0, 0, 0, 0.3);
        }

        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
            transition: background-color 0.3s, color 0.3s;
        }

        body {
            font-family: 'Roboto', 'Arial', sans-serif;
            line-height: 1.6;
            color: var(--text-color);
            background-color: var(--background-color);
            padding-top: 2px;
        }

        .container {
            max-width: 1200px;
            margin: 0 auto;
            padding: 0 20px;
        }

        header {
            background-color: var(--primary-color);
            color: var(--header-text-color);
            padding: 20px 0;
            text-align: center;
            border-radius: var(--border-radius);
            margin-bottom: 2px;
        }

        h1 {
            font-size: 2.2rem;
            margin-bottom: 10px;
        }

        h2 {
            color: var(--primary-color);
            margin: 25px 0 15px;
            padding-bottom: 8px;
            border-bottom: 2px solid var(--secondary-color);
        }

        h3 {
            color: var(--primary-color);
            margin: 20px 0 10px;
        }

        p {
            margin-bottom: 15px;
        }

        /* Меню навигации */
        .menu {
            background-color: var(--menu-bg);
            padding: 15px 20px;
            border-radius: var(--border-radius);
            margin-bottom: 30px;
            box-shadow: var(--menu-shadow);
            display: flex;
            justify-content: center;
            align-items: center;
            flex-wrap: wrap;
            position: sticky;
            top: 0;
            z-index: 100;
        }

        .menu-buttons {
            display: flex;
            flex-wrap: wrap;
            gap: 10px;
        }
		
		
		.menu-buttons {
    display: flex;
    flex-wrap: wrap;
    gap: 10px;
    justify-content: center; /* Изменено на center */
}

        .menu-btn {
            background-color: var(--primary-color);
            color: white;
            border: none;
            padding: 8px 15px;
            border-radius: 4px;
            cursor: pointer;
            font-size: 0.9rem;
            transition: background-color 0.3s;
        }

        .menu-btn:hover {
            background-color: var(--secondary-color);
        }

        .theme-toggle {
            background: none;
            border: 10px solid transparent;
            font-size: 1.5rem;
            cursor: pointer;
            color: var(--primary-color);
        }

        /* Секции контента */
        .section {
            background-color: var(--content-bg);
            border-radius: var(--border-radius);
            padding: 25px;
            margin-bottom: 30px;
            box-shadow: 0 2px 8px rgba(0, 0, 0, 0.1);
        }

        /* Выделение важного */
        .important {
            background-color: rgba(76, 175, 80, 0.1);
            border-left: 4px solid var(--secondary-color);
            padding: 15px;
            margin: 15px 0;
            border-radius: 0 var(--border-radius) var(--border-radius) 0;
        }

        .note {
            background-color: rgba(50, 89, 128, 0.1);
            border-left: 4px solid var(--primary-color);
            padding: 15px;
            margin: 15px 0;
            border-radius: 0 var(--border-radius) var(--border-radius) 0;
        }

        /* Таблицы */
        table {
            width: 100%;
            border-collapse: collapse;
            margin: 20px 0;
        }

        th, td {
            padding: 12px 15px;
            border: 1px solid #ddd;
            text-align: left;
        }

        th {
            background-color: var(--primary-color);
            color: white;
        }

        tr:nth-child(even) {
            background-color: rgba(0, 0, 0, 0.03);
        }

        /* Списки */
        ul, ol {
            padding-left: 25px;
            margin-bottom: 15px;
        }

        li {
            margin-bottom: 8px;
        }

        /* Адаптивный дизайн */
        @media (max-width: 768px) {
            h1 {
                font-size: 1.8rem;
            }
            
            h2 {
                font-size: 1.5rem;
            }
            
            .menu {
                flex-direction: column;
                gap: 15px;
            }
            
            .menu-buttons {
                width: 100%;
                justify-content: center;
            }
            
            .theme-toggle {
                margin-top: 10px;
            }
            
            .section {
                padding: 15px;
            }
        }

        /* Анимации */
        @keyframes fadeIn {
            from { opacity: 0; }
            to { opacity: 1; }
        }

        .fade-in {
            animation: fadeIn 0.5s ease-in;
        }

        footer {
            text-align: center;
            padding: 20px 0;
            margin-top: 40px;
            font-size: 0.9rem;
        }
		
					.kmp11, .example {
      background: rgba(76, 175, 80, 0.1);
      border-left: 4px solid var(--accent11);
      padding: 10px 15px;
      margin: 15px 0;
      border-radius: 4px;
    }

		.kmp12, .example {
      background: rgba(95, 182, 237, 0.1);
      border-left: 4px solid var(--accent12);
      padding: 10px 15px;
      margin: 15px 0;
      border-radius: 4px;
    }
 
		.kmp13, .example {
      background: rgba(205, 170, 110, 0.1);
      border-left: 4px solid var(--accent13);
      padding: 10px 15px;
      margin: 15px 0;
      border-radius: 4px;
    }

		.kmp14, .example {
      background: rgba(205, 110, 200, 0.1);
      border-left: 4px solid var(--accent14);
      padding: 10px 15px;
      margin: 15px 0;
      border-radius: 4px;
    }
	.link-kmp1 {
            color: #fffee0; 
            background-color: #007bff;
            padding: 0em 0.3em; 
            margin: 0 0.5em; /* Добавляет 0.5em отступа справа и слева */
            text-decoration: none; 
            border-radius: 5px; 
            transition: background-color 0.2s ease-in-out, color 0.2s ease-in-out;
				}
		.link-kmp1:hover,
		.link-kmp1:focus {
           color: #ffffff; 
           background-color: #0bb313; 
           text-decoration: none; 
        }
	
	
    </style>
</head>
<body>
    <div class="container">
        <header>
            <h1>Генезис LLM</h1>
            <p>возникновение и развитие больших языковых моделей (лингвистический взгляд)</p>
        </header>

        <nav class="menu">
            <div class="menu-buttons">
				<button class="menu-btn" onclick="scrollToSection('1')">Ай да Пушкин!</button>
                <button class="menu-btn" onclick="scrollToSection('2')">Марков</button>
				<button class="menu-btn" onclick="scrollToSection('3')">Шеннон</button>
                <button class="menu-btn" onclick="scrollToSection('4')">Word2Vec</button>
				<button class="menu-btn" onclick="scrollToSection('5')">Трансформеры</button>
				<button class="menu-btn" onclick="scrollToSection('6')">LLM</button>
				<button class="menu-btn" onclick="scrollToSection('7')">Прогнозы</button>
								                                    </div>
            <button class="theme-toggle" id="themeToggle" title="Переключить тему">☀️</button>
        </nav>


<section id="1" class="section"> <h2 class="section-title">Поэтическое начало</h2> <div class="001"> <h3 class="001-title">Пушкин — наше всё! (Аполлон Григорьев, 1859)</h3> <div class="001-card"> 
<h4>Создание "Евгения Онегина"</h4>   <p>
        Александр Сергеевич Пушкин работал над своим знаменитым романом в стихах
        <strong>«Евгений Онегин»</strong> с <strong>8 мая 1823 года</strong> по
        <strong>19 октября 1831 года</strong>. По подсчётам самого поэта, создание произведения заняло
        <strong>7 лет 4 месяца 17 дней</strong>.
    </p>

    <h4>Хронология работы над романом</h4>
    <ul>
        <li>
            <strong>1823–1824 годы (Кишинёв, Одесса)</strong><br>
            Пушкин начал работу над первой главой в Кишинёве, где находился в ссылке. Осенью 1823 года первая глава была завершена. В 1824 году он приступил ко второй главе, но в июле был выслан в Михайловское.
        </li>
        <li>
            <strong>1824–1826 годы (Михайловское)</strong><br>
            В Михайловском Пушкин завершил вторую главу и написал третью. Здесь он также работал над другими произведениями, но «Онегин» оставался ключевым проектом.
        </li>
        <li>
            <strong>1826–1829 годы (Москва, Петербург)</strong><br>
            После возвращения из ссылки Пушкин продолжил работу: в 1826 году была написана четвёртая глава, в 1827 — пятая и шестая. Главы публиковались отдельными выпусками.
        </li>
        <li>
            <strong>1830–1831 годы (Болдино)</strong><br>
            Осенью 1830 года Пушкин уехал в Болдино, где завершил роман, написав седьмую и восьмую главы. <strong>19 октября 1831 года</strong> работа над произведением была окончательно завершена.
        </li>
    </ul>

    <h4>Подсчёты Пушкина</h4>
    <div class="highlight">
        <p>
            Пушкин указал, что работа заняла <strong>7 лет 4 месяца 17 дней</strong>. Если считать с 8 мая 1823 года по 19 октября 1831 года, то получается:
        </p>
        <ul>
            <li><strong>7 лет</strong> (1823–1830),</li>
            <li><strong>5 месяцев</strong> (май–октябрь),</li>
            <li><strong>11 дней</strong> (с 8 мая по 19 октября).</li>
        </ul>
        <p>
            Поэт вероятно учитывал перерывы и паузы в работе.
        </p>
    </div>

    <h4>Значение романа</h4>
    <p>
        «Евгений Онегин» стал первым русским романом в стихах и «энциклопедией русской жизни» XIX века. Пушкин мастерски отразил нравы, быт, язык и философию своей эпохи, создав произведение, которое остаётся актуальным и сегодня.
    </p></section>


<section id="2" class="section"> <h2 class="section-title">Предыстория: Цепи Маркова и анализ языка</h2> <div class="001"> <h3 class="001-title">Андрей Андреевич Марков</h3> <div class="001-card"> 
<h4>Первые шаги к моделированию языка</h4> <p>В начале XX века математик Андрей Андреевич Марков разработал концепцию цепей Маркова — вероятностных моделей, где будущее состояние зависит только от текущего. </p> <p>В 1913 году он применил эту модель к тексту «Евгения Онегина», анализируя последовательности гласных и согласных букв. Мврков выписал первые 20 000 букв книги в одну длинную строчку из букв, опустив все пробелы и знаки пунктуации. Затем он переставил эти буквы в 200 решёток (по 10х10 символов в каждой), и начал подсчитывать гласные звуки в каждой строке и столбце, записывая результаты.</p> 

<p><strong>Ключевые идеи:</strong></p> <ul> <li>Вероятностная природа языка</li> <li>Формализация текстовых последовательностей</li> </ul> <p><strong>Пояснение:</strong> Это стало основой для будущих языковых моделей, где предсказание следующего элемента зависит от предыдущих, в том числе LLM</p> </div> </div> <div class="table-kmp"> <table class="table"> <thead><tr><th>Год</th><th>Событие</th></tr></thead> <tr><td>1831</td><td>Завершение работы Пушкина А.С. над романом «Евгений Онегин» </td></tr><tr><td>1913</td><td>Анализ «Евгения Онегина» с помощью цепей Маркова</td></tr> </table> </div> <div class="kmp11"><strong>Примечание:</strong> Марков не занимался машинным обучением, но его идеи легли в его основу.</div> <div class="kmp12"><strong>Важно:</strong> Цепи Маркова — фундамент для n-грамм и нейросетевых моделей.</div> <div class="kmp14"><strong>Пояснение:</strong> Это первый случай применения математики к анализу естественного языка.</div> <a target="blank" href="https://ru.wikipedia.org/wiki/Цепь_Маркова" class="link-kmp1">Цепи Маркова</a>  <br> <a target="blank" href="http://books.e-heritage.ru/book/10086570" class="link-kmp1">«Пример статистического исследования над текстом “Евгения Онегина”...»</a></section>

<section id="3" class="section"> <h2 class="section-title">Информационная теория и n-граммы</h2> <div class="001"> <h3 class="001-title">Клод Шеннон и энтропия языка</h3> <div class="001-card"> <h4>Оценка предсказуемости текста</h4> <p>В 1948 году Клод Шеннон разработал теорию информации, включая понятие энтропии, применимое к языку.</p> <p>Он предложил n-граммовые модели, где вероятность слова зависит от предыдущих n слов.</p> <p><strong>Ключевые идеи:</strong></p> <ul> <li>Энтропия как мера неопределённости</li> <li>n-граммы как способ моделирования текста</li> </ul> <p><strong>Пояснение:</strong> Эти модели стали основой для ранних языковых алгоритмов и систем машинного перевода.</p> </div> </div> <div class="table-kmp"> <table class="table"> <thead><tr><th>Год</th><th>Событие</th></tr></thead> <tr><td>1948</td><td>Публикация теории информации Шеннона</td></tr> </table> </div> <div class="kmp11"><strong>Примечание:</strong> n-граммы используются до сих пор в простых языковых задачах.</div> <div class="kmp12"><strong>Важно:</strong> Шеннон показал, что язык можно анализировать статистически.</div> <div class="kmp14"><strong>Пояснение:</strong> Это был переход от символических к вероятностным моделям языка.</div> <a target="blank" href="https://people.math.harvard.edu/~ctm/home/text/others/shannon/entropy/entropy.pdf" class="link-kmp1">A Mathematical Theory of Communication</a> </section>

<section id="4" class="section"> <h2 class="section-title">Нейросети и семантика</h2> <div class="001"> <h3 class="001-title">Word embeddings и нейронные языковые модели</h3> <div class="001-card"> <h4>Переход от статистики к обучению</h4> <p>В 2000-х годах появились нейросетевые языковые модели, способные обучаться на больших корпусах текста.</p> <p>Векторные представления слов (word embeddings) позволили моделям понимать семантические связи между словами.</p> <p><strong>Ключевые идеи:</strong></p> <ul> <li>Нейросети для предсказания слов</li> <li>Семантические векторы слов</li> </ul> <p><strong>Пояснение:</strong> Это позволило моделям не просто запоминать, но и «понимать» смысл текста.</p> </div> </div> <div class="table-kmp"> <table class="table"> <thead><tr><th>Год</th><th>Событие</th></tr></thead> <tr><td>2003</td><td>Первая нейросетевая языковая модель (Бенжио и др.)</td></tr> <tr><td>2013</td><td>Word2Vec — векторные представления слов</td></tr> </table> </div> <div class="kmp11"><strong>Примечание:</strong> Word2Vec стал основой для многих NLP-приложений.</div> <div class="kmp12"><strong>Важно:</strong> Нейросети начали «учиться» языку, а не просто анализировать его.</div> <div class="kmp14"><strong>Пояснение:</strong> Это был качественный скачок в обработке естественного языка.</div> <a target="_blank" href="https://arxiv.org/pdf/1301.3781" class="link-kmp1"> Efficient Estimation of Word Representations in Vector Space</a> </section>

<section id="5" class="section"> <h2 class="section-title">Эпоха трансформеров</h2> <div class="001"> <h3 class="001-title">Attention is All You Need</h3> <div class="001-card"> <h4>Новая архитектура для понимания контекста</h4> <p>В 2017 году Google представил архитектуру Transformer, основанную на механизме внимания (attention).</p> <p>Это позволило моделям учитывать весь контекст предложения, а не только ближайшие слова.</p> <p><strong>Ключевые идеи:</strong></p> <ul> <li>Механизм внимания</li> <li>Параллельная обработка текста</li> </ul> <p><strong>Пояснение:</strong> Transformer стал основой для всех современных LLM: BERT, GPT, T5 и других.</p> </div> </div> <div class="table-kmp"> <table class="table"> <thead><tr><th>Год</th><th>Событие</th></tr></thead> <tr><td>2017</td><td>Публикация архитектуры Transformer</td></tr> <tr><td>2018</td><td>Появление BERT и GPT</td></tr> </table> </div> <div class="kmp11"><strong>Примечание:</strong> Attention позволяет моделям «фокусироваться» на важных частях текста.</div> <div class="kmp12"><strong>Важно:</strong> Transformer — архитектура, лежащая в основе всех современных LLM.</div> <div class="kmp14"><strong>Пояснение:</strong> Это позволило моделям понимать сложные зависимости в тексте.</div> <a target="_blank" href="https://arxiv.org/pdf/1706.03762" class="link-kmp1">Attention Is All You Need</a> </section>

<section id="6" class="section"> <h2 class="section-title">Эпоха больших языковых моделей</h2> <div class="001"> <h3 class="001-title">GPT и повседневное использование</h3> <div class="001-card"> <h4>Модели, которые умеют всё</h4> <p>С 2020 года появились модели, способные писать тексты, переводить, программировать и вести диалог — GPT-3, ChatGPT, Claude, Gemini и другие.</p> <p>Они обучены на огромных корпусах данных и способны адаптироваться к стилю и цели пользователя.</p> <p><strong>Ключевые идеи:</strong></p> <ul> <li>Масштаб и универсальность</li> <li>Интерактивность и персонализация</li> </ul> <p><strong>Пояснение:</strong> LLM стали инструментами для образования, творчества, бизнеса и науки.</p> </div> </div> <div class="table-kmp"> <table class="table"> <thead><tr><th>Год</th><th>Событие</th></tr></thead> <tr><td>2020</td><td>Выход GPT-3 — модели с 175 млрд параметров</td></tr> <tr><td>2022</td><td>Запуск ChatGPT — массовое внедрение LLM</td></tr> <tr><td>2023</td><td>Появление мультимодальных моделей (текст + изображение)</td></tr> </table> </div> <div class="kmp11"><strong>Примечание:</strong> Модели стали доступны широкой аудитории через веб-интерфейсы и API.</div> <div class="kmp12"><strong>Важно:</strong> LLM изменили подход к обучению, работе и коммуникации.</div> <div class="kmp14"><strong>Пояснение:</strong> Это не просто алгоритмы — это новые формы взаимодействия человека и машины.</div> <a target="_blank" href="https://openai.com/blog/chatgpt" class="link-kmp1">Introducing ChatGPT</a> </section>

<section id="7" class="section"> <h2 class="section-title">Будущее LLM: рассуждение, память, мультимодальность</h2> <div class="001"> <h3 class="001-title">Новые горизонты языковых моделей</h3> <div class="001-card"> <h4>Интеллект, адаптация и творчество</h4> <p>С 2024 года LLM начали использовать режимы рассуждения, память, обработку изображений и звука. Модели стали более контекстными и персонализированными.</p> <p>Они способны вести сложные диалоги, учитывать цели пользователя и даже адаптироваться к его стилю мышления.</p> <p><strong>Ключевые идеи:</strong></p> <ul> <li>Мультимодальность: текст, изображение, звук</li> <li>Режимы рассуждения и памяти</li> </ul> <p><strong>Пояснение:</strong> Модели становятся не просто инструментами, а полноценными цифровыми компаньонами.</p> </div> </div> <div class="table-kmp"> <table class="table"> <thead><tr><th>Год</th><th>Событие</th></tr></thead> <tr><td>2024</td><td>Внедрение памяти и персонализации в LLM</td></tr> <tr><td>2025</td><td>Развитие голосовых, агентских и визуальных интерфейсов</td></tr> </table> </div> <div class="kmp11"><strong>Примечание:</strong> Модели могут запоминать предпочтения пользователя и учитывать их в будущем.</div> <div class="kmp12"><strong>Важно:</strong> Это делает взаимодействие с ИИ более человечным и эффективным.</div> <div class="kmp14"><strong>Пояснение:</strong> Мы вступаем в эпоху когнитивного симбиоза человека и машины.</div> <a target="_blank" href="https://ai-2027.com/scenario.pdf" class="link-kmp1">AI 2027</a> </section>



<footer class="footer">
<div class="container">
<p>© 2025 | kmp | CC BY-NC-SA 4.0<br>
Разработано для студентов БрГУ имени А.С. Пушкина</p>
</div>
</footer>
<div style="position: fixed; bottom: 10px; color: #777777; right: 30px; opacity: 0.3; font-size: 14px;">kmp+</div>
    <script>
        // Функция для плавной прокрутки к разделу
        function scrollToSection(sectionId) {
            const section = document.getElementById(sectionId);
            const menuHeight = document.querySelector('.menu').offsetHeight;
            
            window.scrollTo({
                top: section.offsetTop - menuHeight - 20,
                behavior: 'smooth'
            });
        }

        // Функция для переключения темы
        document.getElementById('themeToggle').addEventListener('click', function() {
            const currentTheme = document.documentElement.getAttribute('data-theme');
            const newTheme = currentTheme === 'dark' ? 'light' : 'dark';
            
            document.documentElement.setAttribute('data-theme', newTheme);
            this.textContent = newTheme === 'dark' ? '🌙' : '☀️';
        });

        // Анимация появления секций при прокрутке
        document.addEventListener('DOMContentLoaded', function() {
            const sections = document.querySelectorAll('.section');
            
            const observerOptions = {
                root: null,
                rootMargin: '0px',
                threshold: 0.1
            };
            
            const observer = new IntersectionObserver(function(entries, observer) {
                entries.forEach(entry => {
                    if (entry.isIntersecting) {
                        entry.target.classList.add('fade-in');
                        observer.unobserve(entry.target);
                    }
                });
            }, observerOptions);
            
            sections.forEach(section => {
                section.classList.remove('fade-in');
                observer.observe(section);
            });
        });
    </script>
</body>
</html>